{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"1Btq_gJYDvbF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667891954403,"user_tz":-420,"elapsed":24812,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"d5cb48e7-1773-4201-c736-64f0c063f84c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"4FFCIImSEA7U"},"source":["# Library "]},{"cell_type":"code","execution_count":3,"metadata":{"id":"pRg188mWDjVm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667891964370,"user_tz":-420,"elapsed":3602,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"4aeb3d24-2c09-4c4c-9481-f96318fad212"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n"]}],"source":["pip install nltk"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"uRtCwIfpdrFU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667891967471,"user_tz":-420,"elapsed":3106,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"3b03f57d-22bc-4b63-8fcf-4e97e0d1c00e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting unidecode\n","  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 4.5 MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.3.6\n"]}],"source":["pip install unidecode"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6gUii2NRd-0e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667892044260,"user_tz":-420,"elapsed":76792,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"b28e119b-0fe2-4611-bff1-c247ee1cded9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.2.0+cu92\n","  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (663.1 MB)\n","\u001b[K     |████████████████████████████████| 663.1 MB 1.9 kB/s \n","\u001b[?25hCollecting torchvision==0.4.0+cu92\n","  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 35.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0+cu92) (1.21.6)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (1.15.0)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.2.0+cu92 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.2.0+cu92 which is incompatible.\n","fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.2.0+cu92 which is incompatible.\n","fastai 2.7.9 requires torchvision>=0.8.2, but you have torchvision 0.4.0+cu92 which is incompatible.\u001b[0m\n","Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"]}],"source":["pip install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"2iu8xDLq8tCo","executionInfo":{"status":"ok","timestamp":1667892044260,"user_tz":-420,"elapsed":4,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"outputs":[],"source":["# pip install pyvi"]},{"cell_type":"markdown","metadata":{"id":"sGGfwWO6DzLr"},"source":["# Pre-process"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13833,"status":"ok","timestamp":1667892118459,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"},"user_tz":-420},"id":"JlM0P6CBOJVB","outputId":"cbd0d576-188a-4a27-ad30-185f92d11b9d"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Preprocessing the dataset race...\n","1000\n","2000\n","{'answers': ['A', 'D', 'B', 'D', 'D', 'D'], 'options': [['Thiếu lễ độ với mẹ', 'Nói dối mẹ', 'Không thương mẹ', 'Giận dỗi mẹ'], ['Tức giận', 'Buồn bực', 'Đau xót', 'Cả A và C'], ['Nói trực tiếp trước mặt En-ri-cô', 'Viết thư cho En-ri-cô', 'Nhờ cô giáo nhắn nhủ En-ri-cô', 'Ngồi tâm sự với En-ri-cô'], ['Vì bố gợi lại những kỉ niệm giữa mẹ và En-ri-cô', 'Vì En-ri-cô sợ bố', 'Vì En-ri-cô thấy xấu hổ trước lời nói chân tình của bố', 'Cả A và C'], ['Người bố muốn con phải đọc kĩ, suy ngẫm, tự rút ra bài học cho bản thân', 'Cách giữ thể diện cho người bị phê bình', 'Thể hiện bố En-ri-cô là người tinh tế, tâm lí, sâu sắc', 'Cả 3 đáp án trên'], ['Sẵn sàng bỏ một năm hạnh phúc để tránh cho con một giờ đau khổ', 'Thức suốt đêm, cúi mình trên chiếc nôi trông chừng hơi thở hổn hển của con', 'Người mẹ có thể ăn xin để nuôi con, thậm chí có thể hi sinh cả tính mạng', 'Là người mẹ nhân hậu, bao dung, hết lòng yêu thương con']], 'questions': ['Nhân vật En-ri-cô mắc lỗi gì trước mẹ?', 'Thái độ của bố đối với En-ri-cô?', 'Bố En-ri-cô đã tìm cách nào để bày tỏ quan điểm của mình trước sự thiếu lễ độ của En-ri-cô?', 'Theo em, điều gì khiến En-ri-cô xúc động khi đọc thư của bố?', 'Tại sao bố En-ri-cô không nói trực tiếp với En-ri-cô lại viết thư?', 'Qua những chi tiết nói về mẹ En-ri-cô, em thấy mẹ En-ri-cô là người như thế nào?'], 'article': 'Thứ năm, ngày 10 tháng 11\\n\\nBố để ý là sáng nay, lúc cô giáo đến thăm, khi nói với mẹ, tôi có nhỡ thốt ra một lời thiếu lễ độ. Để cảnh cáo tôi, bố đã viết thư này. Đọc thư tôi xúc động vô cùng.\\n\\n“Trước mặt cô giáo, con đã thiếu lễ độ với mẹ. Việc như thế không bao giờ con được tái phạm nữa, En-ri-cô của bố ạ! Sự hỗn láo của con như một nhát dao đâm vào tim bố vậy! Bố nhớ, cách đây mấy năm, mẹ đã phải thức suốt đêm, cúi mình trên chiếc nôi trông chừng hơi thở hổn hển của con, quằn quại vì nỗi lo sợ khóc nức nở khi nghĩ rằng có thể mất con!.. Nhớ lại điều ấy, bố không thể nén được cơn tức giận đối với con. Hãy nghĩ xem, En-ri-cô à! Con mà lại xúc phạm đến mẹ con ư? Người mẹ sẵn sàng bỏ hết một năm hạnh phúc để tránh cho con một giờ đau đớn, người mẹ có thể đi ăn xin để nuôi con, có thể hi sinh tính mạng để cứu sống con!\\n\\nHãy nghĩ kĩ điều này, En-ri-cô ạ: Trong đời, con có thể trải qua những ngày buồn thảm, nhưng ngày buồn thảm nhất tất sẽ là ngày mà con mất mẹ.\\n\\nKhi đã khôn lớn, trưởng thành, khi các cuộc đấu tranh đã tôi luyện con thành người dũng cảm, có thể có lúc con sẽ mong ước thiết tha được nghe lại tiếng nói của mẹ, được mẹ dang tay ra đón vào lòng. Dù có lớn khôn, khoẻ mạnh thế nào đi chăng nữa, con sẽ vẫn tự thấy mình chỉ là một đứa trẻ tội nghiệp, yếu đuối và không được chở che. Con sẽ cay đắng khi nhớ lại những lúc đã làm cho mẹ đau lòng... Con sẽ không thể sống thanh thản, nếu đã làm cho mẹ buồn phiền. Dù có hối hận, có cầu xin linh hồn mẹ tha thứ... tất cả cũng chỉ vô ích mà thôi. Lương tâm con sẽ không một phút nào yên tĩnh. Hình ảnh dịu dàng và hiền hậu của mẹ sẽ làm tâm hồn con như bị khổ hình. En-ri-cô này! Con hãy nhớ rằng, tình yêu thương, kính trọng cha mẹ là tình cảm thiêng liêng hơn cả. Thật đáng xấu hổ và nhục nhã cho kẻ nào chà đạp lên tình thương yêu đó.\\n\\nTừ nay, không bao giờ con được thốt ra một lời nói nặng với mẹ. Con phải xin lỗi mẹ, không phải vì sợ bố, mà do sự thành khẩn trong lòng. Con hãy cầu xin mẹ hôn con, để cho chiếc hôn ấy xoá đi cái dấu vết vong ân bội nghĩa trên trán con.\\n\\nBố rất yêu con, En-ri-cô ạ, con là niềm hi vọng tha thiết nhất của đời bố, nhưng thà rằng bố không có con, còn hơn là thấy con bội bạc với mẹ. Thôi, trong một thời gian con đừng hôn bố: bố sẽ không thể vui lòng đáp lại cái hôn của con được.\\n\\nBố của con”', 'grade': '7', 'author': 'Edmondo De Amicis', 'files': 'drive/MyDrive/CODE/ViMMRC/raw_data_normalized/Lop_07/MCTest_7_Me toi_annotated.json', 'isProse': False, 'title': 'Mẹ tôi', 'types': ['Multi-sentence Reasoning', 'Single-sentence Reasoning', 'Multi-sentence Reasoning', 'Ambiguous Or Insufficient', 'Multi-sentence Reasoning']}\n","['Multi-sentence Reasoning', 'Single-sentence Reasoning', 'Multi-sentence Reasoning', 'Ambiguous Or Insufficient', 'Multi-sentence Reasoning']\n","3000\n","{'answers': ['C', 'A', 'B', 'C', 'A', 'B'], 'options': [['Một vị vua', 'Một vị tướng tài', 'Một nhà sư', 'Một đạo sĩ'], ['Đất nước vừa trải qua nạn binh đao.', 'Đất nước đang đứng trước họa xâm lăng.', 'Tình hình triều chính rối ren.', 'Đất nước đang nằm trong vòng đô hộ của giặc ngoại xâm.'], ['Sự đoàn kết', 'Sự bền chắc', 'Sự thịnh vượng', 'Sự sum vầy'], ['Đằng lạc', 'Nam thiên', 'Thái bình', 'Đao binh'], ['Sử dụng nhiều hình ảnh biểu tượng.', 'Sử dụng nhiều từ láy và phép nhân hóa.', 'Dùng nhiều điển tích, điển cố.', 'Tả cảnh ngụ tình.'], ['Thất ngôn tứ tuyệt', 'Ngũ ngôn tứ tuyệt', 'Thất ngôn bát cú', 'Ngũ ngôn bát cú']], 'questions': ['Pháp Thuận là ai?', 'Bài thơ \"Vận nước\" ra đời trong hoàn cảnh nào?', 'Hình ảnh so sánh \"Quốc tộ như đằng lạc\" (Vận nước như mây cuốn) nhằm diễn tả điều gì?', 'Từ nào được coi là điểm kết tụ cảm xúc của toàn bài thơ?', 'Nghệ thuật nổi bật của bài thơ là gì?', 'Thể thơ của bài thơ là gì?'], 'article': 'Đáp quốc vương quốc tộ chi vấn\\n\\nQuốc tộ như đằng lạc,\\nNam thiên lý thái bình.\\nVô vi cư điện các,\\nXứ xứ tức đao binh.\\n\\nDịch nghĩa\\n\\nVận nước như dây leo quấn quít,\\nTrời Nam mở ra nền thái bình.\\nHãy dùng phép Vô vi ở nơi cung đình,\\nThì mọi chốn đều dứt hết đao binh.\\n\\nDịch thơ (Đoàn Thăng)\\n\\nVận nước như mây quấn,\\nTrời Nam mở thái bình.\\nVô vi trên điện các,\\nChốn chốn dứt đao binh.\\n\\nDịch thơ (Nguyễn Tấn Hưng)\\n\\nChòng chành vận nước khó kham\\nLàm sao giữ được trời Nam thanh bình!\\nVô vi ngự tại cung đình\\nHỏi còn chinh chiến lửa binh chốn nào?', 'grade': '10', 'author': 'Pháp Thuận thiền sư', 'files': 'drive/MyDrive/CODE/ViMMRC/raw_data_normalized/Lop_10/MCTest_10_Van nuoc_annotated.json', 'isProse': True, 'title': 'Vận nước', 'types': ['Ambiguous Or Insufficient', 'Ambiguous Or Insufficient', 'Ambiguous Or Insufficient', 'Multi-sentence Reasoning', 'Multi-sentence Reasoning']}\n","['Ambiguous Or Insufficient', 'Ambiguous Or Insufficient', 'Ambiguous Or Insufficient', 'Multi-sentence Reasoning', 'Multi-sentence Reasoning']\n","1000\n"]}],"source":["# Original ViMMRC Preprocessing\n","#=========================================#\n","import glob\n","import os\n","import json\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","# from pyvi import ViTokenizer\n","\n","import nltk\n","nltk.download('punkt')\n","\n","def sent_word_tokenize(text):\n","    s = s.lower()\n","    s = str(s)\n","\n","    sents = sent_tokenize(s)\n","    words = [word_tokenize(s) for s in sents]\n","    return words\n","\n","def pre_process_per_sent(sent):\n","\n","    s = ' '.join([str(elem) for elem in sent]) \n","    s = s.lower()\n","    s = str(s) \n","    s = word_tokenize(s)  \n","    return s\n","\n","def pre_process_per_doc(text):\n","    result = []\n","    for sent in text:\n","        s = pre_process_per_sent(sent)\n","        \n","        result.append(s)\n","    return result\n","\n","def preprocess(task):\n","    print('Preprocessing the dataset ' + task + '...')\n","    dataset_names = ['train_race.json', 'dev_race.json', 'test_race.json']\n","    q_id = 0\n","    label_dict = {'A':0, 'B':1, 'C':2, 'D':3}\n","    for dataset_name in dataset_names:\n","        data_all = []\n","        path = os.path.join('drive/My Drive/CODE/ViMMRC/dataset/race_ver_2/', dataset_name)\n","        with open(path, 'r', encoding='utf-8') as fpr:\n","            data_raws = json.load(fpr)\n","            for data_raw in data_raws:\n","                artical = pre_process_per_doc([word_tokenize(s.strip()) for s in sent_tokenize(data_raw['article'])])\n","                    \n","                for i in range(len(data_raw['questions'])):\n","                    instance = {}\n","                    instance['article'] = artical\n","                    instance['question'] = pre_process_per_sent(data_raw['questions'][i].split(' '))\n","                    instance['ground_truth'] = label_dict[ data_raw['answers'][i] ]\n","                        \n","                    a = pre_process_per_sent(data_raw['options'][i][0].split(' '))\n","                    b = pre_process_per_sent(data_raw['options'][i][1].split(' '))\n","                    c = pre_process_per_sent(data_raw['options'][i][2].split(' '))\n","                    d = pre_process_per_sent(data_raw['options'][i][3].split(' '))\n","                        \n","                    instance['options'] = [a, b, c, d]\n","                        \n","                    \n","                    instance['q_id'] = q_id\n","\n","                    try:\n","                        \n","                        instance['types'] = data_raw['types'][i]\n","                    except Exception as e:\n","                        print(data_raw)\n","                        print(data_raw['types'])\n","                        # raise e\n","\n","                    \n","                    # instance['filename'] = filename\n","                        \n","                    q_id += 1\n","                    data_all.append(instance)\n","                    if len(data_all) % 1000==0:\n","                        print(len(data_all))\n","\n","        with open(os.path.join('drive/My Drive/CODE/ViMMRC/dataset/comatch', task, 'sequence', dataset_name), 'w', encoding='utf8') as fpw:\n","            json.dump(data_all, fpw, ensure_ascii=False)\n","\n","if __name__ == '__main__':\n","    preprocess('race')"]},{"cell_type":"markdown","metadata":{"id":"oRispG4UDkr5"},"source":["# Main "]},{"cell_type":"markdown","metadata":{"id":"AvX0LcGpDqR_"},"source":["## Train "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ko9HS-lqNkAM"},"outputs":[],"source":["# https://github.com/shuohangwang/comatch\n","\n","import argparse\n","import time\n","import math\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.optim as optim\n","\n","import json\n","import os\n","import glob\n","\n","path_dataset = 'drive/My Drive/CODE/ViMMRC/dataset/comatch'\n","\n","# parser = argparse.ArgumentParser(description='Multiple Choice Reading Comprehension')\n","# parser.add_argument('--task', type=str, default='race',\n","#                     help='task name')\n","# parser.add_argument('--model', type=str, default='CoMatch',\n","#                     help='model name')\n","# parser.add_argument('--emb_dim', type=int, default=300,\n","#                     help='size of word embeddings')\n","# parser.add_argument('--mem_dim', type=int, default=150,\n","#                     help='hidden memory size')\n","# parser.add_argument('--lr', type=float, default=0.002,\n","#                     help='initial learning rate')\n","# parser.add_argument('--epochs', type=int, default=30,\n","#                     help='upper epoch limit')\n","# parser.add_argument('--batch_size', type=int, default=10, metavar='N',\n","#                     help='batch size')\n","# parser.add_argument('--dropoutP', type=float, default=0.2,\n","#                     help='dropout ratio')\n","# parser.add_argument('--seed', type=int, default=1111,\n","#                     help='random seed')\n","# parser.add_argument('--cuda', action='store_true',\n","#                     help='use CUDA')\n","# parser.add_argument('--interval', type=int, default=200, metavar='N',\n","#                     help='report interval')\n","# parser.add_argument('--exp_idx', type=str,  default='1',\n","#                     help='experiment index')\n","# parser.add_argument('--log', type=str,  default='nothing',\n","#                     help='take note')\n","# args = parser.parse_args()\n","\n","args = {\n","    'task': 'race',\n","    'model': \"CoMatch\",\n","    'emb_dim': 1024,\n","    'mem_dim': 150,\n","    'lr': 0.002,\n","    'epochs': 30,\n","    'batch_size': 8,\n","    'dropoutP': 0.2,\n","    'seed': 1111,\n","    'cuda': True,\n","    'interval': 200,\n","    'exp_idx': '1',\n","    'log': 'nothing',\n","    'embedding': \"drive/My Drive/CODE/ViMMRC/ELMO_ner.vec\"\n","}\n","\n","\n","def accuracy(ground_truth, prediction):\n","    assert(len(ground_truth) == len(prediction))\n","    accuracy = float( (ground_truth==prediction).float().mean(0) )\n","    return accuracy\n","\n","def evaluation(model, optimizer, criterion, corpus, cuda, batch_size, dataset='dev'):\n","    model.eval()\n","    labels_all = []\n","    pred_all = []\n","    total_loss = 0\n","    count = 0\n","    while True:\n","        data = corpus.get_batch(batch_size, dataset)\n","        output = model(data)\n","        _, pred = output.max(1)\n","        pred_all.append(pred.cpu())\n","        labels_all.append(data[3])\n","        labels = data[3].cuda() if cuda else data[3]\n","        loss = criterion(output, labels)\n","\n","        loss = loss.detach()\n","        total_loss += float(loss * output.size(0))\n","        count += output.size(0)\n","\n","        if corpus.start_id[dataset] >= len(corpus.data_all[dataset]): break\n","\n","\n","    loss = total_loss / count\n","    score = accuracy( torch.cat(labels_all), torch.cat(pred_all) )\n","\n","    model.train()\n","    return score\n","\n","def masked_softmax(vector, seq_lens):\n","    mask = vector.new(vector.size()).zero_()\n","    for i in range(seq_lens.size(0)):\n","        mask[i,:,:seq_lens[i]] = 1\n","    mask = Variable(mask, requires_grad=False)\n","\n","    if mask is None:\n","        result = torch.nn.functional.softmax(vector, dim=-1)\n","    else:\n","        result = torch.nn.functional.softmax(vector * mask, dim=-1)\n","        result = result * mask\n","        result = result / (result.sum(dim=-1, keepdim=True) + 1e-13)\n","    return result\n","\n","class MatchNet(nn.Module):\n","    def __init__(self, mem_dim, dropoutP):\n","        super(MatchNet, self).__init__()\n","        self.map_linear = nn.Linear(2*mem_dim, 2*mem_dim)\n","        self.trans_linear = nn.Linear(mem_dim, mem_dim)\n","        self.drop_module = nn.Dropout(dropoutP)\n","\n","    def forward(self, inputs):\n","        proj_p, proj_q, seq_len = inputs\n","        trans_q = self.trans_linear(proj_q)\n","        att_weights = proj_p.bmm( torch.transpose(proj_q, 1, 2) )\n","        att_norm = masked_softmax(att_weights, seq_len)\n","\n","        att_vec = att_norm.bmm(proj_q)\n","        elem_min = att_vec - proj_p\n","        elem_mul = att_vec * proj_p\n","        all_con = torch.cat([elem_min,elem_mul], 2)\n","        output = nn.ReLU()(self.map_linear(all_con))\n","        return output\n","\n","class MaskLSTM(nn.Module):\n","    def __init__(self, in_dim, out_dim, layers=1, batch_first=True, bidirectional=True, dropoutP = 0.3):\n","        super(MaskLSTM, self).__init__()\n","        self.lstm_module = nn.LSTM(in_dim, out_dim, layers, batch_first=batch_first, bidirectional=bidirectional, dropout=dropoutP)\n","        self.drop_module = nn.Dropout(dropoutP)\n","\n","    def forward(self, inputs):\n","        input, seq_lens = inputs\n","        mask_in = input.new(input.size()).zero_()\n","        for i in range(seq_lens.size(0)):\n","            mask_in[i,:seq_lens[i]] = 1\n","        mask_in = Variable(mask_in, requires_grad=False)\n","\n","        input_drop = self.drop_module(input*mask_in)\n","\n","        H, _ = self.lstm_module(input_drop)\n","\n","        mask = H.new(H.size()).zero_()\n","        for i in range(seq_lens.size(0)):\n","            mask[i,:seq_lens[i]] = 1\n","        mask = Variable(mask, requires_grad=False)\n","\n","        output = H * mask\n","\n","        return output\n","\n","class CoMatch(nn.Module):\n","    def __init__(self, corpus, args):\n","        super(CoMatch, self).__init__()\n","        self.emb_dim = args['emb_dim']\n","        self.mem_dim = args['mem_dim']\n","        self.dropoutP = args['dropoutP']\n","        self.cuda_bool = args['cuda']\n","\n","        self.embs = nn.Embedding(len(corpus.dictionary), self.emb_dim)\n","        self.embs.weight.data.copy_(corpus.dictionary.embs)\n","        self.embs.weight.requires_grad = False\n","\n","        self.encoder = MaskLSTM(self.emb_dim, self.mem_dim, dropoutP=self.dropoutP)\n","        self.l_encoder = MaskLSTM(self.mem_dim*8, self.mem_dim, dropoutP=self.dropoutP)\n","        self.h_encoder = MaskLSTM(self.mem_dim*2, self.mem_dim, dropoutP=0)\n","\n","        self.match_module = MatchNet(self.mem_dim*2, self.dropoutP)\n","        self.rank_module = nn.Linear(self.mem_dim*2, 1)\n","\n","        self.drop_module = nn.Dropout(self.dropoutP)\n","\n","    def forward(self, inputs):\n","        documents, questions, options, _ = inputs\n","        d_word, d_h_len, d_l_len = documents\n","        o_word, o_h_len, o_l_len = options\n","        q_word, q_len = questions\n","\n","        if self.cuda_bool: d_word, d_h_len, d_l_len, o_word, o_h_len, o_l_len, q_word, q_len = d_word.cuda(), d_h_len.cuda(), d_l_len.cuda(), o_word.cuda(), o_h_len.cuda(), o_l_len.cuda(), q_word.cuda(), q_len.cuda()\n","        d_embs = self.drop_module( Variable(self.embs(d_word), requires_grad=False) )\n","        o_embs = self.drop_module( Variable(self.embs(o_word), requires_grad=False) )\n","        q_embs = self.drop_module( Variable(self.embs(q_word), requires_grad=False) )\n","\n","        d_hidden = self.encoder([d_embs.view(d_embs.size(0)*d_embs.size(1), d_embs.size(2), self.emb_dim), d_l_len.view(-1)] )\n","        o_hidden = self.encoder([o_embs.view(o_embs.size(0)*o_embs.size(1), o_embs.size(2), self.emb_dim), o_l_len.view(-1)])\n","        q_hidden = self.encoder([q_embs, q_len])\n","\n","        d_hidden_3d = d_hidden.view(d_embs.size(0), d_embs.size(1) * d_embs.size(2), d_hidden.size(-1))\n","        d_hidden_3d_repeat = d_hidden_3d.repeat(1, o_embs.size(1), 1).view(d_hidden_3d.size(0)*o_embs.size(1), d_hidden_3d.size(1), d_hidden_3d.size(2))\n","\n","\n","        do_match = self.match_module([d_hidden_3d_repeat, o_hidden, o_l_len.view(-1)])\n","        dq_match = self.match_module([d_hidden_3d, q_hidden, q_len])\n","\n","        dq_match_repeat = dq_match.repeat(1, o_embs.size(1), 1).view(dq_match.size(0)*o_embs.size(1), dq_match.size(1), dq_match.size(2))\n","\n","        co_match= torch.cat([do_match, dq_match_repeat], -1)\n","\n","        co_match_hier = co_match.view(d_embs.size(0)*o_embs.size(1)*d_embs.size(1), d_embs.size(2), -1)\n","\n","        l_hidden = self.l_encoder([co_match_hier, d_l_len.repeat(1, o_embs.size(1)).view(-1)])\n","        l_hidden_pool, _ = l_hidden.max(1)\n","\n","        h_hidden = self.h_encoder([l_hidden_pool.view(d_embs.size(0)*o_embs.size(1), d_embs.size(1), -1), d_h_len.view(-1, 1).repeat(1, o_embs.size(1)).view(-1)])\n","        h_hidden_pool, _ = h_hidden.max(1)\n","\n","        o_rep = h_hidden_pool.view(d_embs.size(0), o_embs.size(1), -1)\n","        output = torch.nn.functional.log_softmax( self.rank_module(o_rep).squeeze(2) )\n","\n","        return output\n","\n","def prep_glove():\n","    vocab = {}\n","    ivocab = []\n","    tensors = []\n","    with open(args['embedding'], 'r', encoding='utf8') as f:\n","        for line in f:\n","            vals = line.rstrip().split(' ')\n","            if len(vals) != (args['emb_dim'] + 1):\n","                print(line)\n","                continue\n","            assert(len(vals) == (args['emb_dim'] + 1))\n","            word = vals[0]\n","            vec = torch.FloatTensor([ float(v) for v in vals[1:] ])\n","            vocab[word] = len(ivocab)\n","            ivocab.append(word)\n","            tensors.append(vec)\n","            assert (vec.size(0) == args['emb_dim'])\n","    assert len(tensors) == len(ivocab)\n","    tensors = torch.cat(tensors).view(len(ivocab), args['emb_dim'])\n","    with open('drive/My Drive/CODE/ViMMRC/dataset/race/embeddings.pt', 'wb') as fpw:\n","        torch.save([tensors, vocab, ivocab], fpw)\n","\n","\n","class Dictionary(object):\n","    def __init__(self, task):\n","        self.task = task\n","        filename = os.path.join(path_dataset, self.task, 'word2idx.pt')\n","\n","        if os.path.exists(filename):\n","            self.word2idx = torch.load(os.path.join(path_dataset, self.task, 'word2idx.pt'))\n","            self.idx2word = torch.load(os.path.join(path_dataset, self.task, 'idx2word.pt'))\n","            self.word2idx_count = torch.load(os.path.join(path_dataset, self.task, 'word2idx_count.pt'))\n","        else:\n","            self.word2idx = {'<<padding>>':0, '<<unk>>':1}\n","            self.word2idx_count = {'<<padding>>':0, '<<unk>>':0}\n","\n","            self.idx2word = ['<<padding>>', '<<unk>>']\n","\n","            self.build_dict('train')\n","            self.build_dict('dev')\n","            if self.task != 'squad':\n","                self.build_dict('test')\n","\n","            torch.save(self.word2idx, os.path.join(path_dataset, self.task, 'word2idx.pt'))\n","            torch.save(self.idx2word, os.path.join(path_dataset, self.task, 'idx2word.pt'))\n","            torch.save(self.word2idx_count, os.path.join(path_dataset, self.task, 'word2idx_count.pt'))\n","\n","        filename_emb = os.path.join(path_dataset, task, 'embeddings.pt')\n","        print(filename_emb)\n","        if os.path.exists(filename_emb):\n","            self.embs = torch.load(filename_emb)\n","        else:\n","            self.embs = self.build_emb()\n","\n","        print (\"vocabulary size: \" + str(len(self.idx2word)))\n","\n","    def add_word(self, word):\n","        if word not in self.word2idx:\n","            self.word2idx[word] = len(self.idx2word)\n","            self.idx2word.append(word)\n","\n","            self.word2idx_count[word] = 1\n","        else:\n","            self.word2idx_count[word] += 1\n","\n","        return self.word2idx[word]\n","\n","    def build_dict(self, dataset):\n","        filename = os.path.join(path_dataset, self.task, 'sequence', dataset+ '_race' + '.json')\n","\n","        if self.task == 'race':\n","            with open(filename, 'r', encoding='utf-8') as fpr:\n","                data_all = json.load(fpr)\n","                for instance in data_all:\n","                    words = instance['question']\n","                    for option in instance['options']: words += option\n","                    for sent in instance['article']: words += sent\n","                    for word in words: self.add_word(word)\n","        else:\n","            assert False, 'the task ' + self.task + ' is not supported!'\n","\n","    def build_emb(self, all_vacob=False, filter=False, threshold=10):\n","        word2idx = torch.load(os.path.join(path_dataset, self.task, 'word2idx.pt'))\n","        idx2word = torch.load(os.path.join(path_dataset, self.task, 'idx2word.pt'))\n","        emb = torch.FloatTensor(len(idx2word), args['emb_dim']).zero_()\n","        print (\"Loading Glove ...\")\n","        print (\"Raw vacabulary size: \" + str(len(idx2word)) )\n","\n","        if not os.path.exists('drive/My Drive/CODE/ViMMRC/dataset/race/embeddings.pt'): \n","            prep_glove()\n","        glove_tensors, glove_vocab, glove_ivocab = torch.load('drive/My Drive/CODE/ViMMRC/dataset/race/embeddings.pt')\n","\n","        if not all_vacob:\n","            self.word2idx = {'<<padding>>':0, '<<unk>>':1}\n","            self.idx2word = ['<<padding>>', '<<unk>>']\n","        count = 0\n","        for w_id, word in enumerate(idx2word):\n","            if word in glove_vocab:\n","                id = self.add_word(word)\n","                emb[id] = glove_tensors[glove_vocab[word]]\n","                count += 1\n","        emb = emb[:len(self.idx2word)]\n","\n","        print(\"Number of words not appear in glove: \" + str(len(idx2word)-count) )\n","        print (\"Vocabulary size: \" + str(len(self.idx2word)))\n","        torch.save(emb, os.path.join(path_dataset, self.task, 'embeddings.pt'))\n","        torch.save(self.word2idx, os.path.join(path_dataset, self.task, 'word2idx.pt'))\n","        torch.save(self.idx2word, os.path.join(path_dataset, self.task, 'idx2word.pt'))\n","\n","        return emb\n","\n","    def filter(self, threshold=10):\n","        for word, count in self.word2idx_count.items():\n","            if count > threshold and word not in self.word2idx:\n","                self.word2idx[word] = len(self.idx2word)\n","                self.idx2word.append(word)\n","\n","    def __len__(self):\n","        return len(self.idx2word)\n","\n","\n","class Corpus(object):\n","    def __init__(self, task):\n","        self.task = task\n","        self.dictionary = Dictionary(task)\n","\n","        self.data_all, self.start_id, self.indices = {}, {}, {}\n","        setnames = ['train', 'dev', 'test']\n","        for setname in setnames:\n","            self.data_all[setname] = self.load_data(os.path.join(path_dataset, self.task, 'sequence', setname) + '_race.json')\n","            print(setname, len(self.data_all[setname]))\n","            self.start_id[setname] = 0\n","            self.indices[setname] = torch.randperm(len(self.data_all[setname])) if setname == 'train' else torch.range(0, len(self.data_all[setname])-1)\n","\n","    def seq2tensor(self, words):\n","        seq_tensor = torch.LongTensor(len(words))\n","        for id, word in enumerate(words):\n","            seq_tensor[id] = self.dictionary.word2idx[word] if word in self.dictionary.word2idx else 1\n","        return seq_tensor\n","\n","    def load_data(self, filename):\n","        with open(filename, 'r', encoding='utf-8') as fpr:\n","            data = json.load(fpr)\n","        return data\n","\n","    def get_batch(self, batch_size, setname):\n","        if self.start_id[setname] >= len(self.data_all[setname]):\n","            self.start_id[setname] = 0\n","            if setname == 'train': self.indices[setname] = torch.randperm(len(self.data_all[setname]))\n","\n","        end_id = self.start_id[setname] + batch_size if self.start_id[setname] + batch_size < len(self.data_all[setname]) else len(self.data_all[setname])\n","        documents, questions, options, labels = [], [], [], []\n","        for i in range(self.start_id[setname], end_id):\n","            instance_id = int(self.indices[setname][i])\n","\n","            instance = self.data_all[setname][instance_id]\n","\n","            questions.append(instance['question'])\n","            options.append(instance['options'])\n","            documents.append(instance['article'])\n","            labels.append(instance['ground_truth'])\n","\n","        self.start_id[setname] += batch_size\n","\n","        questions = self.seq2tensor(questions)\n","        documents = self.seq2Htensor(documents)\n","        options = self.seq2Htensor(options)\n","        labels = torch.LongTensor(labels)\n","        return [documents, questions, options, labels]\n","\n","    def seq2tensor(self, sents, sent_len_bound=50):\n","        sent_len_max = max([len(s) for s in sents])\n","        sent_len_max = min(sent_len_max, sent_len_bound)\n","\n","        sent_tensor = torch.LongTensor(len(sents), sent_len_max).zero_()\n","\n","        sent_len = torch.LongTensor(len(sents)).zero_()\n","        for s_id, sent in enumerate(sents):\n","            sent_len[s_id] = len(sent)\n","            for w_id, word in enumerate(sent):\n","                if w_id >= sent_len_max: break\n","                sent_tensor[s_id][w_id] = self.dictionary.word2idx.get(word, 1)\n","        return [sent_tensor, sent_len]\n","\n","    def seq2Htensor(self, docs, sent_num_bound=50, sent_len_bound=50):\n","        sent_num_max = max([len(s) for s in docs])\n","        sent_num_max = min(sent_num_max, sent_num_bound)\n","        sent_len_max = max([len(w) for s in docs for w in s ])\n","        sent_len_max = min(sent_len_max, sent_len_bound)\n","\n","        sent_tensor = torch.LongTensor(len(docs), sent_num_max, sent_len_max).zero_()\n","        sent_len = torch.LongTensor(len(docs), sent_num_max).zero_()\n","        doc_len = torch.LongTensor(len(docs)).zero_()\n","        for d_id, doc in enumerate(docs):\n","            doc_len[d_id] = len(doc)\n","            for s_id, sent in enumerate(doc):\n","                if s_id >= sent_num_max: break\n","                sent_len[d_id][s_id] = len(sent)\n","                for w_id, word in enumerate(sent):\n","                    if w_id >= sent_len_max: break\n","                    sent_tensor[d_id][s_id][w_id] = self.dictionary.word2idx.get(word, 1)\n","        return [sent_tensor, doc_len, sent_len]\n","\n","\n","if __name__ == '__main__':\n","    torch.manual_seed(args['seed'])\n","    if torch.cuda.is_available():\n","        if not args['cuda']:\n","            print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n","        else:\n","            torch.cuda.manual_seed(args['seed'])\n","\n","    corpus = Corpus(args['task'])\n","    model = eval(args['model'])(corpus, args)\n","    model.train()\n","    criterion = nn.NLLLoss()\n","\n","    parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    optimizer = optim.Adamax(parameters, lr=args['lr'])\n","\n","\n","    if args['cuda']:\n","        model.cuda()\n","        criterion.cuda()\n","\n","    start_time = time.time()\n","    total_loss = 0\n","    interval = args['interval']\n","    save_interval = len(corpus.data_all['train']) \n","\n","    best_dev_score = -99999\n","    # iterations = args['epochs']*len(corpus.data_all['train']) // args['batch_size']\n","    iterations = 3500\n","\n","    print('max iterations: '+ str(iterations))\n","    for iter in range(iterations):\n","        optimizer.zero_grad()\n","        data = corpus.get_batch(args['batch_size'], 'train')\n","        output = model(data)\n","        labels = data[3].cuda() if args['cuda'] else data[3]\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        total_loss += float(loss.data)\n","\n","        if iter % interval == 0:\n","            cur_loss = total_loss / interval if iter!=0 else total_loss\n","            elapsed = time.time() - start_time\n","            print('| iterations {:3d} | start_id {:3d} | ms/batch {:5.2f} | loss {:5.3f}'.format(\n","            iter, corpus.start_id['train'], elapsed * 1000 / interval, cur_loss))\n","            total_loss = 0\n","            start_time = time.time()\n","\n","        if iter % save_interval == 0:\n","\n","            torch.save([model, optimizer, criterion], 'drive/My Drive/CODE/ViMMRC/model/comatch/'+args['task']+'_save.pt')\n","            score = evaluation(model, optimizer, criterion, corpus, args['cuda'], args['batch_size'])\n","            print('DEV accuracy: ' + str(score))\n","\n","            with open('drive/My Drive/CODE/ViMMRC/model/comatch/'+args['task']+'_record.txt', 'a', encoding='utf-8') as fpw:\n","                if iter == 0: fpw.write(str(args) + '\\n')\n","                fpw.write(str(iter) + ':\\tDEV accuracy:\\t' + str(score) + '\\n')\n","\n","            if score > best_dev_score:\n","                best_dev_score = score\n","                torch.save([model, optimizer, criterion], 'drive/My Drive/CODE/ViMMRC/model/comatch/'+args['task']+'_save_best.pt')\n","\n","        if (iter+1) % (len(corpus.data_all['train']) // args['batch_size']) == 0:\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] *= 0.95\n","\n","\n","    model, optimizer, criterion = torch.load('drive/My Drive/CODE/ViMMRC/model/comatch/'+args['task']+'_save_best.pt')\n","    score = evaluation(model, optimizer, criterion, corpus, args['cuda'], args['batch_size'], dataset='test')\n","    with open('drive/My Drive/CODE/ViMMRC/model/comatch/'+args['task']+'_record.txt', 'a', encoding='utf-8') as fpw:\n","        fpw.write('TEST accuracy:\\t' + str(score) + '\\n')\n","    print('TEST accuracy: ' + str(score))"]},{"cell_type":"markdown","metadata":{"id":"NWbi-4T-Dt3h"},"source":["## Test "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ZfVC7kVD2r8"},"outputs":[],"source":["# TEST section\n","\n","import argparse\n","import time\n","import math\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.optim as optim\n","\n","import json\n","import os\n","import glob\n","\n","path_dataset = 'drive/My Drive/CODE/MMRC/dataset/comtach'\n","\n","args = {\n","    'task': 'race',\n","    'model': \"CoMatch\",\n","    'emb_dim': 2392,\n","    'mem_dim': 150,\n","    'lr': 0.002,\n","    'epochs': 30,\n","    'batch_size': 8,\n","    'dropoutP': 0.2,\n","    'seed': 1111,\n","    'cuda': False,\n","    'interval': 200,\n","    'exp_idx': '1',\n","    'log': 'nothing',\n","    'embedding': \"drive/My Drive/CODE/ViMMRC/ELMO_ner.vec\",\n","    \"result_file\": \"drive/My Drive/CODE/ViMMRC/dataset/comatch/result_ELMO.json\",\n","    \"model_dir\": \"drive/My Drive/CODE/ViMMRC/models/comatch/\",\n","    \"save_test\": False,\n","    \"dataset\": \"test\"\n","}\n","\n","\n","def accuracy(ground_truth, prediction):\n","    assert(len(ground_truth) == len(prediction))\n","    accuracy = float( (ground_truth==prediction).float().mean(0) )\n","    return accuracy\n","\n","# show result for each sentnce in test\n","def get_result(corpus, label, prediction, dataset):\n","    data = corpus.get_dataset(dataset)\n","\n","    label = label.tolist()\n","    prediction = prediction.tolist()\n","\n","    q_ids = []\n","    files_ids = []\n","    types = []\n","    for d in data:\n","        q_ids.append(d['q_id'])\n","        files_ids.append(d['filename'])\n","        types.append(d['types'])\n","\n","    result = []\n","    for i in range(0, len(q_ids)):\n","        result.append({\n","            \"qid\": q_ids[i],\n","            \"label\": label[i],\n","            \"prediction\": prediction[i],\n","            \"files_ids\": files_ids[i],\n","            \"types\": types[i]\n","        })\n","    \n","    with open(args['result_file'], \"w\") as f:\n","        f.write(json.dumps(result))\n","\n","\n","def evaluation(model, optimizer, criterion, corpus, cuda, batch_size, dataset='dev'):\n","    model.eval()\n","    labels_all = []\n","    pred_all = []\n","    q_id = []\n","    total_loss = 0\n","    count = 0\n","    while True:\n","        data = corpus.get_batch(batch_size, dataset)\n","        output = model(data)\n","        _, pred = output.max(1)\n","        pred_all.append(pred.cpu())\n","        labels_all.append(data[3])\n","        labels = data[3].cuda() if cuda else data[3]\n","        loss = criterion(output, labels)\n","\n","        loss = loss.detach()\n","        total_loss += float(loss * output.size(0))\n","        count += output.size(0)\n","\n","        if corpus.start_id[dataset] >= len(corpus.data_all[dataset]): break\n","\n","    loss = total_loss / count\n","    score = accuracy( torch.cat(labels_all), torch.cat(pred_all) )\n","\n","    if args['save_test']:\n","        get_result(corpus, torch.cat(labels_all), torch.cat(pred_all), dataset)\n","\n","    model.train()\n","    return score\n","\n","def masked_softmax(vector, seq_lens):\n","    mask = vector.new(vector.size()).zero_()\n","    for i in range(seq_lens.size(0)):\n","        mask[i,:,:seq_lens[i]] = 1\n","    mask = Variable(mask, requires_grad=False)\n","\n","    if mask is None:\n","        result = torch.nn.functional.softmax(vector, dim=-1)\n","    else:\n","        result = torch.nn.functional.softmax(vector * mask, dim=-1)\n","        result = result * mask\n","        result = result / (result.sum(dim=-1, keepdim=True) + 1e-13)\n","    return result\n","\n","class MatchNet(nn.Module):\n","    def __init__(self, mem_dim, dropoutP):\n","        super(MatchNet, self).__init__()\n","        self.map_linear = nn.Linear(2*mem_dim, 2*mem_dim)\n","        self.trans_linear = nn.Linear(mem_dim, mem_dim)\n","        self.drop_module = nn.Dropout(dropoutP)\n","\n","    def forward(self, inputs):\n","        proj_p, proj_q, seq_len = inputs\n","        trans_q = self.trans_linear(proj_q)\n","        att_weights = proj_p.bmm( torch.transpose(proj_q, 1, 2) )\n","        att_norm = masked_softmax(att_weights, seq_len)\n","\n","        att_vec = att_norm.bmm(proj_q)\n","        elem_min = att_vec - proj_p\n","        elem_mul = att_vec * proj_p\n","        all_con = torch.cat([elem_min,elem_mul], 2)\n","        output = nn.ReLU()(self.map_linear(all_con))\n","        return output\n","\n","class MaskLSTM(nn.Module):\n","    def __init__(self, in_dim, out_dim, layers=1, batch_first=True, bidirectional=True, dropoutP = 0.3):\n","        super(MaskLSTM, self).__init__()\n","        self.lstm_module = nn.LSTM(in_dim, out_dim, layers, batch_first=batch_first, bidirectional=bidirectional, dropout=dropoutP)\n","        self.drop_module = nn.Dropout(dropoutP)\n","\n","    def forward(self, inputs):\n","        input, seq_lens = inputs\n","        mask_in = input.new(input.size()).zero_()\n","        for i in range(seq_lens.size(0)):\n","            mask_in[i,:seq_lens[i]] = 1\n","        mask_in = Variable(mask_in, requires_grad=False)\n","\n","        input_drop = self.drop_module(input*mask_in)\n","\n","        H, _ = self.lstm_module(input_drop)\n","\n","        mask = H.new(H.size()).zero_()\n","        for i in range(seq_lens.size(0)):\n","            mask[i,:seq_lens[i]] = 1\n","        mask = Variable(mask, requires_grad=False)\n","\n","        output = H * mask\n","\n","        return output\n","\n","class CoMatch(nn.Module):\n","    def __init__(self, corpus, args):\n","        super(CoMatch, self).__init__()\n","        self.emb_dim = args['emb_dim']\n","        self.mem_dim = args['mem_dim']\n","        self.dropoutP = args['dropoutP']\n","        self.cuda_bool = args['cuda']\n","\n","        self.embs = nn.Embedding(len(corpus.dictionary), self.emb_dim)\n","        self.embs.weight.data.copy_(corpus.dictionary.embs)\n","        self.embs.weight.requires_grad = False\n","\n","        self.encoder = MaskLSTM(self.emb_dim, self.mem_dim, dropoutP=self.dropoutP)\n","        self.l_encoder = MaskLSTM(self.mem_dim*8, self.mem_dim, dropoutP=self.dropoutP)\n","        self.h_encoder = MaskLSTM(self.mem_dim*2, self.mem_dim, dropoutP=0)\n","\n","        self.match_module = MatchNet(self.mem_dim*2, self.dropoutP)\n","        self.rank_module = nn.Linear(self.mem_dim*2, 1)\n","\n","        self.drop_module = nn.Dropout(self.dropoutP)\n","\n","    def forward(self, inputs):\n","        documents, questions, options, _ = inputs\n","        d_word, d_h_len, d_l_len = documents\n","        o_word, o_h_len, o_l_len = options\n","        q_word, q_len = questions\n","\n","        if self.cuda_bool: d_word, d_h_len, d_l_len, o_word, o_h_len, o_l_len, q_word, q_len = d_word.cuda(), d_h_len.cuda(), d_l_len.cuda(), o_word.cuda(), o_h_len.cuda(), o_l_len.cuda(), q_word.cuda(), q_len.cuda()\n","        d_embs = self.drop_module( Variable(self.embs(d_word), requires_grad=False) )\n","        o_embs = self.drop_module( Variable(self.embs(o_word), requires_grad=False) )\n","        q_embs = self.drop_module( Variable(self.embs(q_word), requires_grad=False) )\n","\n","        d_hidden = self.encoder([d_embs.view(d_embs.size(0)*d_embs.size(1), d_embs.size(2), self.emb_dim), d_l_len.view(-1)] )\n","        o_hidden = self.encoder([o_embs.view(o_embs.size(0)*o_embs.size(1), o_embs.size(2), self.emb_dim), o_l_len.view(-1)])\n","        q_hidden = self.encoder([q_embs, q_len])\n","\n","        d_hidden_3d = d_hidden.view(d_embs.size(0), d_embs.size(1) * d_embs.size(2), d_hidden.size(-1))\n","        d_hidden_3d_repeat = d_hidden_3d.repeat(1, o_embs.size(1), 1).view(d_hidden_3d.size(0)*o_embs.size(1), d_hidden_3d.size(1), d_hidden_3d.size(2))\n","\n","\n","        do_match = self.match_module([d_hidden_3d_repeat, o_hidden, o_l_len.view(-1)])\n","        dq_match = self.match_module([d_hidden_3d, q_hidden, q_len])\n","\n","        dq_match_repeat = dq_match.repeat(1, o_embs.size(1), 1).view(dq_match.size(0)*o_embs.size(1), dq_match.size(1), dq_match.size(2))\n","\n","        co_match= torch.cat([do_match, dq_match_repeat], -1)\n","\n","        co_match_hier = co_match.view(d_embs.size(0)*o_embs.size(1)*d_embs.size(1), d_embs.size(2), -1)\n","\n","        l_hidden = self.l_encoder([co_match_hier, d_l_len.repeat(1, o_embs.size(1)).view(-1)])\n","        l_hidden_pool, _ = l_hidden.max(1)\n","\n","        h_hidden = self.h_encoder([l_hidden_pool.view(d_embs.size(0)*o_embs.size(1), d_embs.size(1), -1), d_h_len.view(-1, 1).repeat(1, o_embs.size(1)).view(-1)])\n","        h_hidden_pool, _ = h_hidden.max(1)\n","\n","        o_rep = h_hidden_pool.view(d_embs.size(0), o_embs.size(1), -1)\n","        output = torch.nn.functional.log_softmax( self.rank_module(o_rep).squeeze(2) )\n","\n","        return output\n","\n","def prep_glove():\n","    vocab = {}\n","    ivocab = []\n","    tensors = []\n","    with open(args['embedding'], 'r', encoding='utf8') as f:\n","        for line in f:\n","            vals = line.rstrip().split(' ')\n","            if len(vals) != (args['emb_dim'] + 1):\n","                print(line)\n","                continue\n","            assert(len(vals) == (args['emb_dim'] + 1))\n","            word = vals[0]\n","            vec = torch.FloatTensor([ float(v) for v in vals[1:] ])\n","            vocab[word] = len(ivocab)\n","            ivocab.append(word)\n","            tensors.append(vec)\n","            assert (vec.size(0) == args['emb_dim'])\n","    assert len(tensors) == len(ivocab)\n","    tensors = torch.cat(tensors).view(len(ivocab), args['emb_dim'])\n","    with open('drive/My Drive/CODE/MMRC/dataset/race/embeddings.pt', 'wb') as fpw:\n","        torch.save([tensors, vocab, ivocab], fpw)\n","\n","\n","class Dictionary(object):\n","    def __init__(self, task):\n","        self.task = task\n","        filename = os.path.join(path_dataset, self.task, 'word2idx.pt')\n","\n","        if os.path.exists(filename):\n","            self.word2idx = torch.load(os.path.join(path_dataset, self.task, 'word2idx.pt'))\n","            self.idx2word = torch.load(os.path.join(path_dataset, self.task, 'idx2word.pt'))\n","            self.word2idx_count = torch.load(os.path.join(path_dataset, self.task, 'word2idx_count.pt'))\n","        else:\n","            self.word2idx = {'<<padding>>':0, '<<unk>>':1}\n","            self.word2idx_count = {'<<padding>>':0, '<<unk>>':0}\n","\n","            self.idx2word = ['<<padding>>', '<<unk>>']\n","\n","            self.build_dict('train_race')\n","            self.build_dict('dev_race')\n","            if self.task != 'squad':\n","                self.build_dict('test_race')\n","\n","            torch.save(self.word2idx, os.path.join(path_dataset, self.task, 'word2idx.pt'))\n","            torch.save(self.idx2word, os.path.join(path_dataset, self.task, 'idx2word.pt'))\n","            torch.save(self.word2idx_count, os.path.join(path_dataset, self.task, 'word2idx_count.pt'))\n","\n","        filename_emb = os.path.join(path_dataset, task, 'embeddings.pt')\n","        print(filename_emb)\n","        if os.path.exists(filename_emb):\n","            self.embs = torch.load(filename_emb)\n","        else:\n","            self.embs = self.build_emb()\n","\n","        print (\"vocabulary size: \" + str(len(self.idx2word)))\n","\n","    def add_word(self, word):\n","        if word not in self.word2idx:\n","            self.word2idx[word] = len(self.idx2word)\n","            self.idx2word.append(word)\n","\n","            self.word2idx_count[word] = 1\n","        else:\n","            self.word2idx_count[word] += 1\n","\n","        return self.word2idx[word]\n","\n","    def build_dict(self, dataset):\n","        filename = os.path.join(path_dataset, self.task, 'sequence', dataset+'.json')\n","\n","        if self.task == 'race':\n","            with open(filename, 'r', encoding='utf-8') as fpr:\n","                data_all = json.load(fpr)\n","                for instance in data_all:\n","                    words = instance['question']\n","                    for option in instance['options']: words += option\n","                    for sent in instance['article']: words += sent\n","                    for word in words: self.add_word(word)\n","        else:\n","            assert False, 'the task ' + self.task + ' is not supported!'\n","\n","    def build_emb(self, all_vacob=False, filter=False, threshold=10):\n","        word2idx = torch.load(os.path.join(path_dataset, self.task, 'word2idx.pt'))\n","        idx2word = torch.load(os.path.join(path_dataset, self.task, 'idx2word.pt'))\n","        emb = torch.FloatTensor(len(idx2word), args['emb_dim']).zero_()\n","        print (\"Loading Glove ...\")\n","        print (\"Raw vacabulary size: \" + str(len(idx2word)) )\n","\n","        if not os.path.exists('drive/My Drive/CODE/MMRC/dataset/race/embeddings.pt'): \n","            prep_glove()\n","        glove_tensors, glove_vocab, glove_ivocab = torch.load('drive/My Drive/CODE/MMRC/dataset/race/embeddings.pt')\n","\n","        if not all_vacob:\n","            self.word2idx = {'<<padding>>':0, '<<unk>>':1}\n","            self.idx2word = ['<<padding>>', '<<unk>>']\n","        count = 0\n","        for w_id, word in enumerate(idx2word):\n","            if word in glove_vocab:\n","                id = self.add_word(word)\n","                emb[id] = glove_tensors[glove_vocab[word]]\n","                count += 1\n","        emb = emb[:len(self.idx2word)]\n","\n","        print(\"Number of words not appear in glove: \" + str(len(idx2word)-count) )\n","        print (\"Vocabulary size: \" + str(len(self.idx2word)))\n","        torch.save(emb, os.path.join(path_dataset, self.task, 'embeddings.pt'))\n","        torch.save(self.word2idx, os.path.join(path_dataset, self.task, 'word2idx.pt'))\n","        torch.save(self.idx2word, os.path.join(path_dataset, self.task, 'idx2word.pt'))\n","\n","        return emb\n","\n","    def filter(self, threshold=10):\n","        for word, count in self.word2idx_count.items():\n","            if count > threshold and word not in self.word2idx:\n","                self.word2idx[word] = len(self.idx2word)\n","                self.idx2word.append(word)\n","\n","    def __len__(self):\n","        return len(self.idx2word)\n","\n","\n","class Corpus(object):\n","    def __init__(self, task):\n","        self.task = task\n","        self.dictionary = Dictionary(task)\n","\n","        self.data_all, self.start_id, self.indices = {}, {}, {}\n","        setnames = ['train', 'dev', 'test']\n","        for setname in setnames:\n","            self.data_all[setname] = self.load_data(os.path.join(path_dataset, self.task, 'sequence', setname) + '.json')\n","            print(setname, len(self.data_all[setname]))\n","            self.start_id[setname] = 0\n","            self.indices[setname] = torch.randperm(len(self.data_all[setname])) if setname == 'train' else torch.range(0, len(self.data_all[setname])-1)\n","\n","    def get_dataset(self, dataset=\"dev\"):\n","        return self.data_all[dataset]\n","\n","    def seq2tensor(self, words):\n","        seq_tensor = torch.LongTensor(len(words))\n","        for id, word in enumerate(words):\n","            seq_tensor[id] = self.dictionary.word2idx[word] if word in self.dictionary.word2idx else 1\n","        return seq_tensor\n","\n","    def load_data(self, filename):\n","        with open(filename, 'r', encoding='utf-8') as fpr:\n","            data = json.load(fpr)\n","        return data\n","\n","    def get_batch(self, batch_size, setname):\n","        if self.start_id[setname] >= len(self.data_all[setname]):\n","            self.start_id[setname] = 0\n","            if setname == 'train': self.indices[setname] = torch.randperm(len(self.data_all[setname]))\n","\n","        end_id = self.start_id[setname] + batch_size if self.start_id[setname] + batch_size < len(self.data_all[setname]) else len(self.data_all[setname])\n","        documents, questions, options, labels = [], [], [], []\n","        for i in range(self.start_id[setname], end_id):\n","            instance_id = int(self.indices[setname][i])\n","\n","            instance = self.data_all[setname][instance_id]\n","\n","            questions.append(instance['question'])\n","            options.append(instance['options'])\n","            documents.append(instance['article'])\n","            labels.append(instance['ground_truth'])\n","\n","        self.start_id[setname] += batch_size\n","\n","        questions = self.seq2tensor(questions)\n","        documents = self.seq2Htensor(documents)\n","        options = self.seq2Htensor(options)\n","        labels = torch.LongTensor(labels)\n","        return [documents, questions, options, labels]\n","\n","    def seq2tensor(self, sents, sent_len_bound=50):\n","        sent_len_max = max([len(s) for s in sents])\n","        sent_len_max = min(sent_len_max, sent_len_bound)\n","\n","        sent_tensor = torch.LongTensor(len(sents), sent_len_max).zero_()\n","\n","        sent_len = torch.LongTensor(len(sents)).zero_()\n","        for s_id, sent in enumerate(sents):\n","            sent_len[s_id] = len(sent)\n","            for w_id, word in enumerate(sent):\n","                if w_id >= sent_len_max: break\n","                sent_tensor[s_id][w_id] = self.dictionary.word2idx.get(word, 1)\n","        return [sent_tensor, sent_len]\n","\n","    def seq2Htensor(self, docs, sent_num_bound=50, sent_len_bound=50):\n","        sent_num_max = max([len(s) for s in docs])\n","        sent_num_max = min(sent_num_max, sent_num_bound)\n","        sent_len_max = max([len(w) for s in docs for w in s ])\n","        sent_len_max = min(sent_len_max, sent_len_bound)\n","\n","        sent_tensor = torch.LongTensor(len(docs), sent_num_max, sent_len_max).zero_()\n","        sent_len = torch.LongTensor(len(docs), sent_num_max).zero_()\n","        doc_len = torch.LongTensor(len(docs)).zero_()\n","        for d_id, doc in enumerate(docs):\n","            doc_len[d_id] = len(doc)\n","            for s_id, sent in enumerate(doc):\n","                if s_id >= sent_num_max: break\n","                sent_len[d_id][s_id] = len(sent)\n","                for w_id, word in enumerate(sent):\n","                    if w_id >= sent_len_max: break\n","                    sent_tensor[d_id][s_id][w_id] = self.dictionary.word2idx.get(word, 1)\n","        return [sent_tensor, doc_len, sent_len]\n","\n","\n","if __name__ == '__main__':\n","    torch.manual_seed(args['seed'])\n","    if torch.cuda.is_available():\n","        if not args['cuda']:\n","            print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n","        else:\n","            torch.cuda.manual_seed(args['seed'])\n","\n","    corpus = Corpus(args['task'])\n","    model = eval(args['model'])(corpus, args)\n","    # model.train()\n","    criterion = nn.NLLLoss()\n","\n","    parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    optimizer = optim.Adamax(parameters, lr=args['lr'])\n","\n","    model, optimizer, criterion = torch.load(args['model_dir'] + args['task']+'_save_best.pt')\n","    score = evaluation(model, optimizer, criterion, corpus, args['cuda'], args['batch_size'], args['dataset'])\n","    # with open('drive/My Drive/CODE/MMRC/trainedmodel/'+args['task']+'_record.txt', 'a', encoding='utf-8') as fpw:\n","    #     fpw.write('TEST accuracy:\\t' + str(score) + '\\n')\n","    print('TEST accuracy: ' + str(score))"]},{"cell_type":"markdown","metadata":{"id":"lZqzT_03D25g"},"source":["# Result analysis "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"elapsed":977,"status":"ok","timestamp":1585577833570,"user":{"displayName":"Sơn Lưu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuWJIB-Kj03NohF54bi2lsV0RWqxXQ0iZQjuym=s64","userId":"09824077883060402796"},"user_tz":-420},"id":"r-h-Ftnj-M42","outputId":"ffc58515-3b61-446e-c106-22de7be42577"},"outputs":[{"name":"stdout","output_type":"stream","text":["220\n","294\n","0.7482993197278912\n","{\n","    \"Matching\": 0.019455252918287938,\n","    \"Paraphrasing\": 0.02529182879377432,\n","    \"Single-sentence Reasoning\": 0.17120622568093385,\n","    \"Multi-sentence Reasoning\": 0.2782101167315175,\n","    \"Ambiguous Or Insufficient\": 0.07782101167315175\n","}\n"]}],"source":["# result analysis\n","import json\n","\n","path_file = 'drive/My Drive/CODE/MMRC/dataset/result_MULTI_W_F_B_E.json'\n","\n","with open(path_file, \"r\") as f:\n","    results = json.loads(f.read())\n","\n","types = {\n","    'Matching': 0,\n","    'Paraphrasing': 0,\n","    'Single-sentence Reasoning': 0,\n","    'Multi-sentence Reasoning': 0,\n","    'Ambiguous Or Insufficient': 0\n","}\n","\n","right = 0\n","wrong = 0\n","\n","for r in results:\n","    if r['prediction'] != r['label']:\n","        types[r['types']] = types[r['types']] + 1\n","        wrong = wrong + 1\n","    else:\n","        right = right + 1\n","\n","print(right)\n","print(wrong)\n","print(right/wrong)\n","for k,v in types.items():\n","    types[k] = v / len(results)\n","\n","print(json.dumps(types, indent=4))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmpKioHfGfu4"},"outputs":[],"source":["MULTI: {\n","    \"Matching\": 0.019455252918287938,\n","    \"Paraphrasing\": 0.02529182879377432,\n","    \"Single-sentence Reasoning\": 0.17120622568093385,\n","    \"Multi-sentence Reasoning\": 0.2782101167315175,\n","    \"Ambiguous Or Insufficient\": 0.07782101167315175\n","}\n","ELMO: {\n","    \"Matching\": 0.023346303501945526,\n","    \"Paraphrasing\": 0.02529182879377432,\n","    \"Single-sentence Reasoning\": 0.15953307392996108,\n","    \"Multi-sentence Reasoning\": 0.26459143968871596,\n","    \"Ambiguous Or Insufficient\": 0.07003891050583658\n","}\n","Bert_Base: {\n","    \"Matching\": 0.027237354085603113,\n","    \"Paraphrasing\": 0.029182879377431907,\n","    \"Single-sentence Reasoning\": 0.17120622568093385,\n","    \"Multi-sentence Reasoning\": 0.2801556420233463,\n","    \"Ambiguous Or Insufficient\": 0.0914396887159533\n","}\n","\n","FastText: {\n","    \"Matching\": 0.023346303501945526,\n","    \"Paraphrasing\": 0.02529182879377432,\n","    \"Single-sentence Reasoning\": 0.17120622568093385,\n","    \"Multi-sentence Reasoning\": 0.28793774319066145,\n","    \"Ambiguous Or Insufficient\": 0.08560311284046693\n","}\n","\n","W2V_C2V: {\n","    \"Matching\": 0.029182879377431907,\n","    \"Paraphrasing\": 0.017509727626459144,\n","    \"Single-sentence Reasoning\": 0.17120622568093385,\n","    \"Multi-sentence Reasoning\": 0.31906614785992216,\n","    \"Ambiguous Or Insufficient\": 0.08949416342412451\n","}\n","\n","W2V: {\n","    \"Matching\": 0.029182879377431907,\n","    \"Paraphrasing\": 0.017509727626459144,\n","    \"Single-sentence Reasoning\": 0.17120622568093385,\n","    \"Multi-sentence Reasoning\": 0.31906614785992216,\n","    \"Ambiguous Or Insufficient\": 0.08949416342412451\n","}"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["lZqzT_03D25g"],"provenance":[],"machine_shape":"hm"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}