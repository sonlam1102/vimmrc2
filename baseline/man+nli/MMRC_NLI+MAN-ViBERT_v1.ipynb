{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":608,"status":"ok","timestamp":1676727187964,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"kimkG7xp6wvS","outputId":"2b763969-6881-40df-f323-bb2f5bf0a739"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Feb 18 13:33:06 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    56W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6135,"status":"ok","timestamp":1676727194096,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"n8OLTA2cqdHk","outputId":"7bd10037-42f5-49b4-a904-214ed55c24f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1676727194097,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"G4x_F5OtS5V8","outputId":"0b560aa9-4bba-4594-dc04-46c0334f50a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NCKH/ViMMRC_model\n"]}],"source":["%cd '/content/drive/MyDrive/NCKH/ViMMRC_model/'"]},{"cell_type":"markdown","metadata":{"id":"K_Pv9CIYm7BZ"},"source":["# Library\n","\n","https://github.com/mhardalov/exams-qa \\\n","https://github.com/microsoft/MT-DNN \\\n","https://github.com/jind11/MMM-MCQA"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108415,"status":"ok","timestamp":1676726849241,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"7znvNnvg-0de","outputId":"f822708e-21db-42a6-eb69-5e55a2d588eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.4/753.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.3/114.3 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.3/216.3 KB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.7/635.7 KB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.4.0 which is incompatible.\n","fastai 2.7.11 requires torch<1.14,>=1.7, but you have torch 1.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["%pip -q install -e git+https://github.com/microsoft/MT-DNN.git#egg=mtdnn"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74694,"status":"ok","timestamp":1676726987046,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"ksz16DuhgUtk","outputId":"c33c9065-8a4d-447f-8f5e-e1a89a0f429d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","mtdnn 1.1.0 requires torch==1.4.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","mtdnn 1.1.0 requires torch==1.4.0, but you have torch 1.13.1 which is incompatible.\n","mtdnn 1.1.0 requires transformers==2.9.0, but you have transformers 4.26.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["%pip -q install torch -U\n","%pip -q install transformers -U\n","%pip -q install tqdm -U\n","# %pip -q install --upgrade  git+https://github.com/lanpa/tensorboardX.git"]},{"cell_type":"markdown","metadata":{"id":"dT2PDGixT400"},"source":["Install apex package: https://stackoverflow.com/a/74561776\n","\n","Query the version Ubuntu Colab is running on:\\\n","`!lsb_release -a`\n","\n","Get the current cuda version run:\\\n","`!nvcc --version`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1676456036543,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"qWFKkQbKTUBA","outputId":"8594950a-e68e-4ff6-ed8a-27d1b31ea1ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Tue_Mar__8_18:18:20_PST_2022\n","Cuda compilation tools, release 11.6, V11.6.124\n","Build cuda_11.6.r11.6/compiler.31057947_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"markdown","metadata":{"id":"ioQPuCNdks1x"},"source":["# Models"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"svixfajDMreB","executionInfo":{"status":"ok","timestamp":1676727194097,"user_tz":-420,"elapsed":4,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}}},"outputs":[],"source":["#%pip install git+git@github.com:microsoft/mt-dnn.git@master#egg=mtdnn"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4x7vIh8LE40U","executionInfo":{"status":"ok","timestamp":1676727195935,"user_tz":-420,"elapsed":1841,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","from mtdnn.common.dropout_wrapper import DropoutWrapper\n","from mtdnn.common.optimizer import weight_norm as WN\n","from mtdnn.common.similarity import FlatSimilarityWrapper, SelfAttnWrapper, SimilarityWrapper\n","from mtdnn.common.activation_functions import activation\n","\n","\n","class DualAttentionWrapper(nn.Module):\n","    def __init__(self, x1_dim, x2_dim, prefix='attention', opt={}, dropout=None):\n","        super(DualAttentionWrapper, self).__init__()\n","        self.prefix = prefix\n","        if dropout is None:\n","            self.att_dropout = DropoutWrapper(opt.get('{}_att_dropout'.format(self.prefix), 0))\n","        else:\n","            self.att_dropout = dropout\n","        self.score_func = SimilarityWrapper(x1_dim, x2_dim, prefix=prefix, opt=opt, dropout=self.att_dropout)\n","\n","    def forward(self, query, key, query_padding_mask=None, key_padding_mask=None, return_scores=False):\n","        logits = self.score_func(query, key)\n","        # print(query.shape, key.shape, logits.shape, key_padding_mask.sum(dim=-1).max(), key_padding_mask.shape)\n","        query_mask = query_padding_mask.unsqueeze(2).expand_as(logits)\n","        key_mask = key_padding_mask.unsqueeze(1).expand_as(logits)\n","\n","        # first get attn_query\n","        logits_key = logits.data.masked_fill(key_mask.data, -float('inf'))\n","        prob_key = F.softmax(logits_key, -1)\n","        # prob_key = prob_key.view(-1, query.size(1), key.size(1))\n","        prob_key = self.att_dropout(prob_key)\n","        attn_query = prob_key.bmm(key)\n","\n","        # then get attn_key\n","        logits_query = logits.data.masked_fill(query_mask.data, -float('inf'))\n","        prob_query = F.softmax(logits_query, 1)\n","        # prob_query = prob_query.view(-1, key.size(1), query.size(1))\n","        prob_query = self.att_dropout(prob_query)\n","        attn_key = prob_query.transpose(1, 2).bmm(query)\n","\n","        if return_scores:\n","            return attn_query, attn_key, prob_query, logits\n","        else:\n","            return attn_query, attn_key\n","\n","\n","class Classifier(nn.Module):\n","    def __init__(self, x_size, y_size, opt, prefix='decoder', dropout=None):\n","        super(Classifier, self).__init__()\n","        self.opt = opt\n","        if dropout is None:\n","            self.dropout = DropoutWrapper(opt.get('{}_dropout_p'.format(prefix), 0))\n","        else:\n","            self.dropout = dropout\n","        self.merge_opt = opt.get('{}_merge_opt'.format(prefix), 0)\n","        self.weight_norm_on = opt.get('{}_weight_norm_on'.format(prefix), False)\n","\n","        if self.merge_opt == 1:\n","            self.proj = nn.Linear(x_size * 4, y_size)\n","        else:\n","            self.proj = nn.Linear(x_size * 2, y_size)\n","\n","        if self.weight_norm_on:\n","            self.proj = WN(self.proj)\n","\n","    def forward(self, x1, x2, mask=None, activation=None):\n","        seq_len = None\n","        if len(x1.size()) == 3:\n","            bz, seq_len, hidden_size = x1.size()\n","            x1 = x1.contiguous().view(-1, hidden_size)\n","            x2 = x2.contiguous().view(-1, hidden_size)\n","\n","        if self.merge_opt == 1:\n","            x = torch.cat([x1, x2, (x1 - x2).abs(), x1 * x2], 1)\n","        else:\n","            x = torch.cat([x1, x2], 1)\n","        x = self.dropout(x)\n","        if activation:\n","            scores = activation(self.proj(x))\n","        else:\n","            scores = self.proj(x)\n","\n","        if seq_len:\n","            return scores.view(bz, seq_len, -1)\n","        else:\n","            return scores\n","\n","# mtdnn.common.san.SANClassifier() super\n","class SANClassifier(nn.Module):\n","    \"\"\"Implementation of Stochastic Answer Networks for Natural Language Inference, Xiaodong Liu, Kevin Duh and Jianfeng Gao\n","    https://arxiv.org/abs/1804.07888\n","    \"\"\"\n","    def __init__(self, x_size, h_size, label_size, opt={}, prefix='decoder', dropout=None):\n","        super(SANClassifier, self).__init__()\n","        self.prefix = prefix\n","        if dropout is None:\n","            self.dropout = DropoutWrapper(opt.get('{}_dropout_p'.format(self.prefix), 0))\n","        else:\n","            self.dropout = dropout\n","        self.query_wsum = SelfAttnWrapper(x_size, prefix='mem_cum', opt=opt, dropout=self.dropout)\n","        self.attn = FlatSimilarityWrapper(x_size, h_size, prefix, opt, self.dropout)\n","        self.rnn_type = '{}{}'.format(opt.get('{}_rnn_type'.format(prefix), 'gru').upper(), 'Cell')\n","        self.rnn = getattr(nn, self.rnn_type)(x_size, h_size)\n","        self.num_turn = opt.get('{}_num_turn'.format(prefix), 5)\n","        self.opt = opt\n","        self.mem_random_drop = opt.get('{}_mem_drop_p'.format(prefix), 0)\n","        self.mem_type = opt.get('{}_mem_type'.format(prefix), 0)\n","        self.weight_norm_on = opt.get('{}_weight_norm_on'.format(prefix), False)\n","        self.label_size = label_size\n","        self.dump_state = opt.get('dump_state_on', False)\n","        self.alpha = Parameter(torch.zeros(1, 1), requires_grad=False)\n","        # self.hyp_attn = None\n","        # if opt.get('hyp_attn_premise', 0):\n","        #     self.hyp_attn = AttentionWrapper(x_size, h_size, prefix=prefix, opt=opt, dropout=self.dropout)\n","        #     self.hyp_merge = Classifier(x_size, x_size, opt, prefix=prefix, dropout=self.dropout)\n","        self.f = activation(opt.get('{}_activation'.format(self.prefix), 'relu'))\n","        if self.weight_norm_on:\n","            self.rnn = WN(self.rnn)\n","\n","        self.classifier = Classifier(x_size, 1, opt, prefix=prefix, dropout=self.dropout)\n","\n","    def _generate_mask(self, new_data, dropout_p=0.0, is_training=False):\n","        if not is_training:\n","            dropout_p = 0.0\n","        new_data = (1 - dropout_p) * (new_data.zero_() + 1)\n","        for i in range(new_data.size(0)):\n","            one = random.randint(0, new_data.size(1) - 1)\n","            new_data[i][one] = 1\n","        mask = 1.0 / (1 - dropout_p) * torch.bernoulli(new_data)\n","        mask.requires_grad = False\n","        return \n","\n","    def forward(self, x, h0, x_mask=None, h_mask=None, is_training=True):\n","        h0 = self.query_wsum(h0, h_mask)\n","        if type(self.rnn) is nn.LSTMCell:\n","            c0 = h0.new(h0.size()).zero_()\n","        scores_list = []\n","        for turn in range(self.num_turn):\n","            att_scores = self.attn(x, h0, x_mask)\n","            x_sum = torch.bmm(F.softmax(att_scores, 1).unsqueeze(1), x).squeeze(1)\n","            scores = self.classifier(x_sum, h0)\n","            scores_list.append(scores)\n","            # next turn\n","            if self.rnn is not None:\n","                h0 = self.dropout(h0)\n","                if type(self.rnn) is nn.LSTMCell:\n","                    h0, c0 = self.rnn(x_sum, (h0, c0))\n","                else:\n","                    h0 = self.rnn(x_sum, h0)\n","        if self.mem_type == 1:\n","            batch_size = x.size(0) // self.label_size\n","            mask = self._generate_mask(self.alpha.data.new(batch_size, self.num_turn), self.mem_random_drop, is_training)\n","            mask = [m.contiguous() for m in torch.unbind(mask, 1)]\n","            tmp_scores_list = [mask[idx].view(batch_size, 1).expand_as(inp.view(-1, self.label_size))\n","                               * F.softmax(inp.view(-1, self.label_size), 1)\n","                               for idx, inp in enumerate(scores_list)]\n","            scores = torch.stack(tmp_scores_list, 2)\n","            scores = torch.mean(scores, 2)\n","            scores = torch.log(scores)\n","        else:\n","            scores = scores_list[-1]\n","        if self.dump_state:\n","            return scores, scores_list\n","        else:\n","            return scores\n","\n","\n","class SANClassifier2(nn.Module):\n","    \"\"\"Implementation of Stochastic Answer Networks for Natural Language Inference, Xiaodong Liu, Kevin Duh and Jianfeng Gao\n","    https://arxiv.org/abs/1804.07888\n","    \"\"\"\n","    def __init__(self, x_size, h_size, label_size, opt={}, prefix='decoder', dropout=None):\n","        super(SANClassifier2, self).__init__()\n","        self.prefix = prefix\n","        if dropout is None:\n","            self.dropout = DropoutWrapper(opt.get('{}_dropout_p'.format(self.prefix), 0))\n","        else:\n","            self.dropout = dropout\n","        self.dual_attn = DualAttentionWrapper(x_size, h_size, prefix, opt, self.dropout)\n","        self.query_wsum = SelfAttnWrapper(x_size, prefix='mem_cum', opt=opt, dropout=self.dropout)\n","        self.attn = FlatSimilarityWrapper(x_size, h_size, prefix, opt, self.dropout)\n","        self.rnn_type = '{}{}'.format(opt.get('{}_rnn_type'.format(prefix), 'gru').upper(), 'Cell')\n","        self.rnn = getattr(nn, self.rnn_type)(x_size, h_size)\n","        self.num_turn = opt.get('{}_num_turn'.format(prefix), 5)\n","        self.opt = opt\n","        self.mem_random_drop = opt.get('{}_mem_drop_p'.format(prefix), 0)\n","        self.mem_type = opt.get('{}_mem_type'.format(prefix), 0)\n","        self.weight_norm_on = opt.get('{}_weight_norm_on'.format(prefix), False)\n","        self.label_size = label_size\n","        self.dump_state = opt.get('dump_state_on', False)\n","        self.alpha = Parameter(torch.zeros(1, 1), requires_grad=False)\n","        self.f = activation(opt.get('{}_activation'.format(self.prefix), 'relu'))\n","        self.hyp_first = opt.get('{}_hyp_first'.format(prefix), 1)\n","        self.hyp_raw = opt.get('{}_hyp_raw'.format(prefix), 0)\n","        if self.weight_norm_on:\n","            self.rnn = WN(self.rnn)\n","\n","        self.classifier = Classifier(x_size, 1, opt, prefix=prefix, dropout=self.dropout)\n","\n","        self.premise_merge = Classifier(x_size, x_size, opt, prefix=prefix, dropout=self.dropout)\n","        self.hyp_merge = Classifier(x_size, x_size, opt, prefix=prefix, dropout=self.dropout)\n","\n","    def _generate_mask(self, new_data, dropout_p=0.0, is_training=False):\n","        if not is_training:\n","            dropout_p = 0.0\n","        new_data = (1 - dropout_p) * (new_data.zero_() + 1)\n","        for i in range(new_data.size(0)):\n","            one = random.randint(0, new_data.size(1) - 1)\n","            new_data[i][one] = 1\n","        mask = 1.0 / (1 - dropout_p) * torch.bernoulli(new_data)\n","        mask.requires_grad = False\n","        return \n","\n","    def forward(self, x, h, x_mask=None, h_mask=None, is_training=True):\n","        if self.hyp_first and self.hyp_raw:\n","            pass\n","        elif self.hyp_first and not self.hyp_raw:\n","            _, h_attn = self.dual_attn(x, h, x_mask, h_mask)\n","            h = self.hyp_merge(h, h_attn, activation=self.f)\n","        else:\n","            raise NotImplementedError\n","\n","        h0 = self.query_wsum(h, h_mask)\n","        if type(self.rnn) is nn.LSTMCell:\n","            c0 = h0.new(h0.size()).zero_()\n","        scores_list = []\n","        for turn in range(self.num_turn):\n","            att_scores = self.attn(x, h0, x_mask)\n","            x_sum = torch.bmm(F.softmax(att_scores, 1).unsqueeze(1), x).squeeze(1)\n","            scores = self.classifier(x_sum, h0)\n","            scores_list.append(scores)\n","            # next turn\n","            if self.rnn is not None:\n","                h0 = self.dropout(h0)\n","                if type(self.rnn) is nn.LSTMCell:\n","                    h0, c0 = self.rnn(x_sum, (h0, c0))\n","                else:\n","                    h0 = self.rnn(x_sum, h0)\n","        if self.mem_type == 1:\n","            batch_size = x.size(0) // self.label_size\n","            mask = self._generate_mask(self.alpha.data.new(batch_size, self.num_turn), self.mem_random_drop, is_training)\n","            mask = [m.contiguous() for m in torch.unbind(mask, 1)]\n","            tmp_scores_list = [mask[idx].view(batch_size, 1).expand_as(inp.view(-1, self.label_size))\n","                               * F.softmax(inp.view(-1, self.label_size), 1)\n","                               for idx, inp in enumerate(scores_list)]\n","            scores = torch.stack(tmp_scores_list, 2)\n","            scores = torch.mean(scores, 2)\n","            scores = torch.log(scores)\n","        else:\n","            scores = scores_list[-1]\n","        if self.dump_state:\n","            return scores, scores_list\n","        else:\n","            return scores"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jJZdHqpLB3B6","executionInfo":{"status":"ok","timestamp":1676727198249,"user_tz":-420,"elapsed":2315,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}}},"outputs":[],"source":["# MMM-MCQA from https://github.com/jind11/MMM-MCQA\n","\n","#import copy\n","import math\n","import torch\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss, NLLLoss\n","from transformers.modeling_utils import prune_linear_layer\n","from transformers.models.bert.modeling_bert import (\n","    BertPreTrainedModel,\n","    BertEmbeddings,\n","    BertSelfOutput,\n","    BertIntermediate,\n","    BertOutput,\n","    BertPooler,\n","    BertModel,\n",")\n","\n","BertLayerNorm = torch.nn.LayerNorm\n","\n","# Add speaker_embeddings\n","# class BertEmbeddings(nn.Module):\n","#     def __init__(self, config, speaker_embeddings=False):\n","#     def forward(self, input_ids, token_type_ids=None, speaker_ids=None):\n","\n","# Config output_attentions, keep_multihead_output for output\n","class BertSelfAttention(nn.Module):\n","    def __init__(self, config, output_attentions=False, keep_multihead_output=False):\n","        super(BertSelfAttention, self).__init__()\n","        if config.hidden_size % config.num_attention_heads != 0:\n","            raise ValueError(\n","                \"The hidden size (%d) is not a multiple of the number of attention \"\n","                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads))\n","        self.output_attentions = output_attentions\n","        self.keep_multihead_output = keep_multihead_output\n","        self.multihead_output = None\n","\n","        self.num_attention_heads = config.num_attention_heads\n","        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n","        self.all_head_size = self.num_attention_heads * self.attention_head_size\n","\n","        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n","        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n","        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n","\n","        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n","\n","    def transpose_for_scores(self, x):\n","        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n","        x = x.view(*new_x_shape)\n","        return x.permute(0, 2, 1, 3)\n","\n","    def forward(self, hidden_states, attention_mask, head_mask=None):\n","        mixed_query_layer = self.query(hidden_states)\n","        mixed_key_layer = self.key(hidden_states)\n","        mixed_value_layer = self.value(hidden_states)\n","\n","        query_layer = self.transpose_for_scores(mixed_query_layer)\n","        key_layer = self.transpose_for_scores(mixed_key_layer)\n","        value_layer = self.transpose_for_scores(mixed_value_layer)\n","\n","        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n","        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n","        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n","        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n","        attention_scores = attention_scores + attention_mask\n","\n","        # Normalize the attention scores to probabilities.\n","        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n","\n","        # This is actually dropping out entire tokens to attend to, which might\n","        # seem a bit unusual, but is taken from the original Transformer paper.\n","        attention_probs = self.dropout(attention_probs)\n","\n","        # Mask heads if we want to\n","        if head_mask is not None:\n","            attention_probs = attention_probs * head_mask\n","\n","        context_layer = torch.matmul(attention_probs, value_layer)\n","        if self.keep_multihead_output:\n","            self.multihead_output = context_layer\n","            self.multihead_output.retain_grad()\n","\n","        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n","        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n","        context_layer = context_layer.view(*new_context_layer_shape)\n","        if self.output_attentions:\n","            return attention_probs, context_layer\n","        return context_layer\n","\n","# Config output_attentions, keep_multihead_output for BertSelfAttention(), change head pruned, attention output\n","class BertAttention(nn.Module):\n","    def __init__(self, config, output_attentions=False, keep_multihead_output=False):\n","        super(BertAttention, self).__init__()\n","        self.output_attentions = output_attentions\n","        self.self = BertSelfAttention(config, output_attentions=output_attentions, keep_multihead_output=keep_multihead_output)\n","        self.output = BertSelfOutput(config)\n","\n","    def prune_heads(self, heads):\n","        if len(heads) == 0:\n","            return\n","        mask = torch.ones(self.self.num_attention_heads, self.self.attention_head_size)\n","        for head in heads:\n","            mask[head] = 0\n","        mask = mask.view(-1).contiguous().eq(1)\n","        index = torch.arange(len(mask))[mask].long()\n","\n","        # Prune linear layers\n","        self.self.query = prune_linear_layer(self.self.query, index)\n","        self.self.key = prune_linear_layer(self.self.key, index)\n","        self.self.value = prune_linear_layer(self.self.value, index)\n","        self.output.dense = prune_linear_layer(self.output.dense, index, dim=1)\n","\n","        # Update hyper params\n","        self.self.num_attention_heads = self.self.num_attention_heads - len(heads)\n","        self.self.all_head_size = self.self.attention_head_size * self.self.num_attention_heads\n","\n","    def forward(self, input_tensor, attention_mask, head_mask=None):\n","        self_output = self.self(input_tensor, attention_mask, head_mask)\n","        if self.output_attentions:\n","            attentions, self_output = self_output\n","        attention_output = self.output(self_output, input_tensor)\n","        if self.output_attentions:\n","            return attentions, attention_output\n","        return attention_output\n","\n","# Config output_attentions, keep_multihead_output for BertAttention(), change attentions output on forward()\n","class BertLayer(nn.Module):\n","    def __init__(self, config, output_attentions=False, keep_multihead_output=False):\n","        super(BertLayer, self).__init__()\n","        self.output_attentions = output_attentions\n","        self.attention = BertAttention(config, output_attentions=output_attentions, keep_multihead_output=keep_multihead_output)\n","        self.intermediate = BertIntermediate(config)\n","        self.output = BertOutput(config)\n","\n","    def forward(self, hidden_states, attention_mask, head_mask=None):\n","        attention_output = self.attention(hidden_states, attention_mask, head_mask)\n","        if self.output_attentions:\n","            attentions, attention_output = attention_output\n","        intermediate_output = self.intermediate(attention_output)\n","        layer_output = self.output(intermediate_output, attention_output)\n","        if self.output_attentions:\n","            return attentions, layer_output\n","        return layer_output\n","\n","# Config output_attentions, keep_multihead_output for BertLayer(), change attentions layer in forward() \n","class BertEncoder(nn.Module):\n","    def __init__(self, config, output_attentions=False, keep_multihead_output=False):\n","        super(BertEncoder, self).__init__()\n","        self.output_attentions = output_attentions\n","        self.layer = nn.ModuleList([\n","            BertLayer(config, output_attentions=output_attentions, keep_multihead_output=keep_multihead_output)\n","            for _ in range(config.num_hidden_layers)\n","        ])\n","\n","    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True, head_mask=None):\n","        all_encoder_layers = []\n","        all_attentions = []\n","        for i, layer_module in enumerate(self.layer):\n","            hidden_states = layer_module(hidden_states, attention_mask, head_mask[i])\n","            if self.output_attentions:\n","                attentions, hidden_states = hidden_states\n","                all_attentions.append(attentions)\n","            if output_all_encoded_layers:\n","                all_encoder_layers.append(hidden_states)\n","        if not output_all_encoded_layers:\n","            all_encoder_layers.append(hidden_states)\n","        if self.output_attentions:\n","            return all_attentions, all_encoder_layers\n","        return all_encoder_layers\n","\n","# Config output_attentions, keep_multihead_output\n","class BertModel(BertPreTrainedModel):\n","    def __init__(self, config, output_attentions=False, keep_multihead_output=False, speaker_embeddings=False):\n","        super(BertModel, self).__init__(config)\n","\n","        self.output_attentions = output_attentions\n","        self.embeddings = BertEmbeddings(config)\n","        self.encoder = BertEncoder(config, output_attentions=output_attentions, keep_multihead_output=keep_multihead_output)\n","        self.pooler = BertPooler(config)\n","        self.apply(self._init_weights)#init_bert_weights)\n","\n","    def prune_heads(self, heads_to_prune):\n","        \"\"\" Prunes heads of the model.\n","            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n","        \"\"\"\n","        for layer, heads in heads_to_prune.items():\n","            self.encoder.layer[layer].attention.prune_heads(heads)\n","\n","    def get_multihead_outputs(self):\n","        \"\"\" Gather all multi-head outputs.\n","            Return: list (layers) of multihead module outputs with gradients\n","        \"\"\"\n","        return [layer.attention.self.multihead_output for layer in self.encoder.layer]\n","\n","    def forward(self, input_ids, token_type_ids=None, attention_mask=None, speaker_ids=None, output_all_encoded_layers=True, head_mask=None):\n","        if attention_mask is None:\n","            attention_mask = torch.ones_like(input_ids)\n","        if token_type_ids is None:\n","            token_type_ids = torch.zeros_like(input_ids)\n","\n","        # We create a 3D attention mask from a 2D tensor mask.\n","        # Sizes are [batch_size, 1, 1, to_seq_length]\n","        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n","        # this attention mask is more simple than the triangular masking of causal attention\n","        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n","        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n","\n","        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n","        # masked positions, this operation will create a tensor which is 0.0 for\n","        # positions we want to attend and -10000.0 for masked positions.\n","        # Since we are adding it to the raw scores before the softmax, this is\n","        # effectively the same as removing these entirely.\n","        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n","        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n","\n","        # Prepare head mask if needed\n","        # 1.0 in head_mask indicate we keep the head\n","        # attention_probs has shape bsz x n_heads x N x N\n","        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n","        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n","        if head_mask is not None:\n","            if head_mask.dim() == 1:\n","                head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n","                head_mask = head_mask.expand_as(self.config.num_hidden_layers, -1, -1, -1, -1)\n","            elif head_mask.dim() == 2:\n","                head_mask = head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)  # We can specify head_mask for each layer\n","            head_mask = head_mask.to(dtype=next(self.parameters()).dtype) # switch to fload if need + fp16 compatibility\n","        else:\n","            head_mask = [None] * self.config.num_hidden_layers\n","\n","        embedding_output = self.embeddings(input_ids, token_type_ids, speaker_ids)\n","        encoded_layers = self.encoder(embedding_output,\n","                                      extended_attention_mask,\n","                                      head_mask=head_mask,\n","                                      output_all_encoded_layers=output_all_encoded_layers)\n","        if self.output_attentions:\n","            all_attentions, encoded_layers = encoded_layers\n","        sequence_output = encoded_layers[-1]\n","        pooled_output = self.pooler(sequence_output)\n","\n","        if not output_all_encoded_layers:\n","            encoded_layers = encoded_layers[-1]\n","        if self.output_attentions:\n","            return all_attentions, encoded_layers, pooled_output\n","        return encoded_layers, pooled_output\n","\n","# Config output_attentions, keep_multihead_output, add premise_mask, hyp_mask attention\n","class BertForMultipleChoice_SAN(BertPreTrainedModel):\n","    def __init__(self, config, opt, num_choices, output_attentions=False, keep_multihead_output=False, same_linear_layer=0):\n","        super(BertForMultipleChoice_SAN, self).__init__(config)\n","        self.output_attentions = output_attentions\n","        self.num_choices = num_choices\n","        self.bert = BertModel(config, output_attentions=output_attentions, keep_multihead_output=keep_multihead_output)\n","        self.opt = opt\n","        self.use_SAN = opt.get('use_SAN', 1)\n","        self.same_linear_layer = same_linear_layer\n","        if not self.use_SAN:\n","            self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","            # self.classifier = nn.ModuleList([nn.Linear(config.hidden_size, 1)] * len(num_choices))\n","            if same_linear_layer:\n","                self.classifier = nn.Linear(config.hidden_size, 1)\n","            else:\n","                self.classifier = nn.ModuleList([nn.Linear(config.hidden_size, 1)] * len(num_choices))\n","        else:\n","            if same_linear_layer:\n","                self.out_proj = SANClassifier(config.hidden_size, config.hidden_size, 1, opt, prefix='answer')\n","            else:\n","                self.out_proj = []\n","                for num_choice in num_choices:\n","                    self.out_proj.append(SANClassifier(config.hidden_size, config.hidden_size, num_choice, opt, prefix='answer'))\n","                self.out_proj = nn.ModuleList(self.out_proj)\n","\n","        self.apply(self._init_weights)\n","\n","    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, head_mask=None, premise_mask=None, hyp_mask=None, is_training=True, task_id=None):\n","        input_ids = input_ids.view(-1, input_ids.size(-1))\n","        token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None\n","        attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None\n","\n","        outputs = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False, head_mask=head_mask)\n","        if self.output_attentions:\n","            all_attentions, sequence_output, pooled_output = outputs\n","        else:\n","            sequence_output, pooled_output = outputs\n","        # pooled_output = self.dropout(pooled_output)\n","        # logits = self.classifier(pooled_output)\n","        # reshaped_logits = logits.view(-1, self.num_choices)\n","\n","        # SAN module\n","        if self.use_SAN:\n","            premise_mask = premise_mask.view(-1, premise_mask.size(-1)) if premise_mask is not None else None\n","            hyp_mask = hyp_mask.view(-1, hyp_mask.size(-1)) if hyp_mask is not None else None\n","            max_query = hyp_mask.size(1)\n","            hyp_mem = sequence_output[:, :max_query]\n","            if self.same_linear_layer:\n","                logits = self.out_proj(sequence_output, hyp_mem, premise_mask, hyp_mask, is_training=is_training)\n","            else:\n","                logits = self.out_proj[task_id](sequence_output, hyp_mem, premise_mask, hyp_mask, is_training=is_training)\n","        else:\n","            pooled_output = self.dropout(pooled_output)\n","            if self.same_linear_layer:\n","                logits = self.classifier(pooled_output)\n","            else:\n","                logits = self.classifier[task_id](pooled_output)\n","\n","        if labels is not None:\n","            if self.opt.get('answer_mem_type', 0):\n","                loss_fct = NLLLoss()\n","            else:\n","                loss_fct = CrossEntropyLoss()\n","                logits = logits.view(-1, self.num_choices[task_id])\n","            labels = labels.view(-1)\n","            loss = loss_fct(logits, labels)\n","            return loss, logits\n","        elif self.output_attentions:\n","            return all_attentions, logits\n","        return logits\n","\n","\n","class BertForMultipleChoice_SAN2(BertPreTrainedModel):\n","    def __init__(self, config, opt, num_choices, output_attentions=False, keep_multihead_output=False):\n","        super(BertForMultipleChoice_SAN2, self).__init__(config)\n","        self.output_attentions = output_attentions\n","        self.num_choices = num_choices\n","        self.bert = BertModel(config, output_attentions=output_attentions, keep_multihead_output=keep_multihead_output)\n","        self.opt = opt\n","        self.use_SAN = opt.get('use_SAN', 1)\n","        if not self.use_SAN:\n","            self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","            self.classifier = nn.ModuleList([nn.Linear(config.hidden_size, 1)] * len(num_choices))\n","        else:\n","            self.out_proj = []\n","            for num_choice in num_choices:\n","                self.out_proj.append(SANClassifier2(config.hidden_size, config.hidden_size, num_choice, opt, prefix='answer'))\n","            self.out_proj = nn.ModuleList(self.out_proj)\n","\n","        self.apply(self._init_weights)#init_bert_weights)\n","\n","    def forward(\n","        self,\n","        input_ids,\n","        token_type_ids=None,\n","        attention_mask=None,\n","        labels=None,\n","        head_mask=None,\n","        premise_mask=None,\n","        hyp_mask=None,\n","        is_training=True,\n","        task_id=None\n","    ):\n","        input_ids = input_ids.view(-1, input_ids.size(-1))\n","        token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None\n","        attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None\n","\n","        outputs = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False, head_mask=head_mask)\n","        if self.output_attentions:\n","            all_attentions, sequence_output, pooled_output = outputs\n","        else:\n","            sequence_output, pooled_output = outputs\n","        # pooled_output = self.dropout(pooled_output)\n","        # logits = self.classifier(pooled_output)\n","        # reshaped_logits = logits.view(-1, self.num_choices)\n","\n","        # SAN module\n","        if self.use_SAN:\n","            premise_mask = premise_mask.view(-1, premise_mask.size(-1)) if premise_mask is not None else None\n","            hyp_mask = hyp_mask.view(-1, hyp_mask.size(-1)) if hyp_mask is not None else None\n","            max_query = hyp_mask.size(1)\n","            hyp_mem = sequence_output[:, :max_query]\n","            premise_mem, premise_mask = masked_select(sequence_output, premise_mask)\n","            logits = self.out_proj[task_id](premise_mem, hyp_mem, premise_mask, hyp_mask, is_training=is_training)\n","        else:\n","            pooled_output = self.dropout(pooled_output)\n","            logits = self.classifier[task_id](pooled_output)\n","\n","        if labels is not None:\n","            if self.opt.get('answer_mem_type', 0):\n","                loss_fct = NLLLoss()\n","            else:\n","                loss_fct = CrossEntropyLoss()\n","                logits = logits.view(-1, self.num_choices[task_id])\n","            labels = labels.view(-1)\n","            loss = loss_fct(logits, labels)\n","            return loss, logits\n","        elif self.output_attentions:\n","            return all_attentions, logits\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"uWwt6WujlC1Q"},"source":["# Utils"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"HZxTWqhmlCaO","executionInfo":{"status":"ok","timestamp":1676727198249,"user_tz":-420,"elapsed":9,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}}},"outputs":[],"source":["import csv\n","import glob\n","import json\n","import logging\n","import os\n","from typing import List\n","\n","import numpy as np\n","from tqdm.auto import tqdm, trange\n","from transformers import PreTrainedTokenizer\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","\n","    def __init__(self, guid, text_a, text_b=None, label=None, text_c=None):\n","        \"\"\"Constructs a InputExample.\n","        Args:\n","            guid: Unique id for the example.\n","            text_a: string. The untokenized text of the first sequence. For single sequence tasks, only this sequence must be specified.\n","            text_b: (Optional) string. The untokenized text of the second sequence. Only must be specified for sequence pair tasks.\n","            label: (Optional) string. The label of the example. This should be specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.guid = guid\n","        self.text_a = text_a\n","        self.text_b = text_b\n","        self.text_c = text_c\n","        self.label = label\n","\n","\n","class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(self, guid, input_ids, input_mask, segment_ids, label_id, premise_mask, hypothesis_mask):\n","        self.guid = guid\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_id = label_id\n","        self.premise_mask = premise_mask\n","        self.hypothesis_mask = hypothesis_mask\n","\n","\n","class DataProcessor(object):\n","    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_labels(self):\n","        \"\"\"Gets the list of labels for this data set.\"\"\"\n","        raise NotImplementedError()\n","\n","    @classmethod\n","    def _read_tsv(cls, input_file, quotechar=None):\n","        \"\"\"Reads a tab separated value file.\"\"\"\n","        with open(input_file, \"r\") as f:\n","            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n","            lines = []\n","            for line in reader:\n","                lines.append(line)\n","            return lines\n","\n","    @classmethod\n","    def _read_json(cls, input_file):\n","        \"\"\"Reads a json file.\"\"\"\n","        with open(input_file, \"r\", encoding='utf-8') as fpr:\n","            raw_list = json.load(fpr)\n","            return raw_list\n","\n","    @classmethod\n","    def _read_jsonl(cls, input_file):\n","        \"\"\"Reads a json file.\"\"\"\n","        with open(input_file, \"r\", encoding='utf-8') as fpr:\n","            raw_list = list()\n","            for json_str in list(fpr):\n","                raw_list.append(json.loads(json_str))\n","            return raw_list\n","\n","\n","class VimmrcProcessor(DataProcessor):\n","    \"\"\"Processor for the MultiNLI data set (GLUE version).\"\"\"\n","    def get_train_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._read_samples(data_dir, \"train\")\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._read_samples(data_dir, \"dev\")\n","        \n","    def get_test_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._read_samples(data_dir, \"test\")\n","\n","    def get_labels(self):\n","        \"\"\"See base class.\"\"\"\n","        return [\"A\", \"B\", \"C\", \"D\"]\n","\n","    def _read_samples(self, data_dir, set_type):\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\n","        # Init reader\n","        examples = []\n","        #example_id = 0\n","        # with open(filename, 'r', encoding='utf-8') as fpr:\n","        #     raw_list = json.load(fpr)\n","        raw_list = self._read_json(os.path.join(data_dir, set_type + \".json\"))\n","\n","        for data_raw in raw_list:\n","            # data_raw = json.load(fpr)\n","            article = data_raw['content']\n","            example_id = 0\n","            title = '_'.join(data_raw['files'].split('/')[-1].split('_')[:-1])\n","            for i in range(len(data_raw['questions'])):\n","                example_id += 1\n","                #truth = str(ord(data_raw['questions'][i]['answer']) - ord('A'))\n","                truth = data_raw['questions'][i]['answer']\n","                question = data_raw['questions'][i]['question']\n","                options = data_raw['questions'][i]['options']\n","                for k in range(len(options)):\n","                    guid = \"%s-%s-%s-%s\" % (set_type, title, example_id, k)\n","                    option = list(options[k].values())[0]\n","                    examples.append(\n","                        InputExample(guid=guid, text_a=article, text_b=option, label=truth, text_c=question))\n","\n","        return examples\n","\n","\n","class VinliProcessor(DataProcessor):\n","    \"\"\"Processor for the MultiNLI data set (GLUE version).\"\"\"\n","    def get_train_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._read_samples(data_dir, \"train\")\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._read_samples(data_dir, \"dev\")\n","        \n","    def get_test_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._read_samples(data_dir, \"test\")\n","\n","    def get_labels(self):\n","        \"\"\"See base class.\"\"\"\n","        return [\"contradiction\", \"entailment\", \"neutral\"]\n","\n","    def _read_samples(self, data_dir, set_type):\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\n","        # Init reader\n","        examples = []\n","        raw_list = self._read_jsonl(os.path.join(data_dir, set_type + \".jsonl\"))\n","        for data_line in raw_list:\n","            guid = \"%s-%s\" % (set_type, data_line['pairID'])\n","            text_a = data_line['sentence1']\n","            text_b = data_line['sentence2']\n","            label = data_line['gold_label']\n","            if label in self.get_labels():\n","                examples.append(\n","                    InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n","\n","        return examples\n","\n","\n","class RaceProcessor(DataProcessor):\n","    \"\"\"Processor for the RACE data set.\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        logger.info(\"LOOKING AT {} train\".format(data_dir))\n","        high = os.path.join(data_dir, \"train_race.json\")\n","        # middle = os.path.join(data_dir, \"train/middle\")\n","        high = self._read_txt(high)\n","        # middle = self._read_txt(middle)\n","        return self._create_examples(high, \"train\")\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        logger.info(\"LOOKING AT {} dev\".format(data_dir))\n","        high = os.path.join(data_dir, \"dev_race.json\")\n","        # middle = os.path.join(data_dir, \"dev/middle\")\n","        high = self._read_txt(high)\n","        # middle = self._read_txt(middle)\n","        return self._create_examples(high, \"dev\")\n","\n","    def get_test_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        logger.info(\"LOOKING AT {} test\".format(data_dir))\n","        high = os.path.join(data_dir, \"test_race.json\")\n","        # middle = os.path.join(data_dir, \"test/middle\")\n","        high = self._read_txt(high)\n","        # middle = self._read_txt(middle)\n","        return self._create_examples(high, \"test\")\n","\n","    def get_labels(self):\n","        \"\"\"See base class.\"\"\"\n","        return [\"A\", \"B\", \"C\", \"D\"]\n","\n","    def _read_txt(self, input_dir):\n","        lines = []\n","        with open(input_dir, \"r\", encoding=\"utf-8\") as fin:\n","            data_raw = json.load(fin)\n","        for d in data_raw:\n","            d['race_id'] = d['files']\n","            lines.append(d)\n","        return lines\n","\n","    def _create_examples(self, lines, set_type):\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\n","        examples = []\n","        for (_, data_raw) in enumerate(lines):\n","            race_id = \"%s-%s\" % (set_type, data_raw[\"race_id\"])\n","            article = data_raw[\"article\"]\n","            for i in range(len(data_raw[\"answers\"])):\n","                truth = data_raw[\"answers\"][i]\n","                question = data_raw[\"questions\"][i]\n","                options = data_raw[\"options\"][i]\n","                for k in range(len(options)):\n","                    guid = \"%s-%s\" % (race_id, k)\n","                    examples.append(\n","                        InputExample(\n","                            guid=guid,\n","                            text_a=article,\n","                            text_b=options[k], #list(options[k].values())[0]\n","                            label=truth,\n","                            text_c=question\n","                        )\n","                    )\n","        return examples\n","\n","\n","class InfiniteDataLoader:\n","    def __init__(self, data_loader):\n","        self.data_loader = data_loader\n","        self.data_iter = iter(data_loader)\n","\n","    def get_next(self):\n","        try:\n","            data = next(self.data_iter)\n","        except StopIteration:\n","            # StopIteration is thrown if dataset ends\n","            # reinitialize data loader\n","            self.data_iter = iter(self.data_loader)\n","            data = next(self.data_iter)\n","        return data\n","\n","\n","def convert_examples_to_features(\n","    examples: List[InputExample],\n","    label_list: List[str],\n","    max_seq_length: int,\n","    tokenizer,\n","    n_class,\n","    do_lower_case,\n","    output_mode,\n","    set_type,\n","    is_multi_choice=True\n",") -> List[InputFeatures]:\n","    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n","\n","    label_map = {label: i for i, label in enumerate(label_list)}\n","\n","    if is_multi_choice:\n","        features = [[]]\n","    else:\n","        features = []\n","\n","    feature_iterator = tqdm(examples, desc=\"Convert examples to features\")\n","    for (ex_index, example) in enumerate(feature_iterator):\n","        feature_iterator.set_description(\"Convert %d of %d example to features\" % (ex_index, len(examples)))\n","\n","        tokens_a = tokenizer.tokenize(example.text_a.lower() if do_lower_case else example.text_a)  # dialogues\n","\n","        tokens_b = [] # None\n","        tokens_c = [] # None\n","\n","        if example.text_b:\n","            tokens_b = tokenizer.tokenize(example.text_b.lower() if do_lower_case else example.text_b)  # answers\n","\n","        if example.text_c:\n","            tokens_c = tokenizer.tokenize(example.text_c.lower() if do_lower_case else example.text_c)  # questions\n","\n","        if tokens_c:\n","            _truncate_seq_tuple(tokens_a, tokens_b, tokens_c, max_seq_length - 4)\n","            tokens_b = tokens_c + [\"[SEP]\"] + tokens_b\n","        elif tokens_b:\n","            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n","        else:\n","            if len(tokens_a) > max_seq_length - 2:\n","                tokens_a = tokens_a[0:(max_seq_length - 2)]\n","\n","        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n","        segment_ids = (len(tokens_a) + 2) * [0]\n","        premise_mask = (len(tokens_a) + 2) * [1]\n","        hypothesis_mask = (len(tokens_a) + 2) * [0]\n","\n","        if tokens_b:\n","            tokens += tokens_b + [\"[SEP]\"]\n","            segment_ids += [1] * (len(tokens_b) + 1)\n","            premise_mask += [1] * (len(tokens_c) + 1)\n","            premise_mask += [0] * (len(tokens_b) - len(tokens_c))\n","            hypothesis_mask += [0] * (len(tokens_c) + 1)\n","            hypothesis_mask += [1] * (len(tokens_b) - len(tokens_c))\n","\n","        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","        # The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n","        input_mask = [1] * len(input_ids)\n","\n","        # Zero-pad up to the sequence length.\n","        pad_length = max_seq_length - len(input_ids)\n","        input_ids += [0] * pad_length\n","        input_mask += [0] * pad_length\n","        segment_ids += [0] * pad_length\n","        premise_mask += [0] * pad_length\n","        hypothesis_mask += [0] * pad_length\n","\n","        assert len(input_ids) == max_seq_length\n","        assert len(input_mask) == max_seq_length\n","        assert len(segment_ids) == max_seq_length\n","        assert len(premise_mask) == max_seq_length\n","        assert len(hypothesis_mask) == max_seq_length\n","\n","        if output_mode in [\"classification\", \"multi-choice\"]:\n","            label_id = label_map[example.label]\n","        elif output_mode == \"regression\":\n","            label_id = float(example.label)\n","        else:\n","            raise KeyError(output_mode)\n","\n","        if is_multi_choice:\n","            features[-1].append(\n","                InputFeatures(\n","                    guid=example.guid,\n","                    input_ids=input_ids,\n","                    input_mask=input_mask,\n","                    segment_ids=segment_ids,\n","                    label_id=label_id,\n","                    premise_mask = premise_mask,\n","                    hypothesis_mask = hypothesis_mask))\n","            if len(features[-1]) == n_class:\n","                features.append([])\n","        else:\n","            features.append(\n","                InputFeatures(\n","                    guid=example.guid,\n","                    input_ids=input_ids,\n","                    input_mask=input_mask,\n","                    segment_ids=segment_ids,\n","                    label_id=label_id,\n","                    premise_mask = premise_mask,\n","                    hypothesis_mask = hypothesis_mask))\n","            \n","        ## display some example\n","        if set_type == 'train' and ex_index < 4:\n","            logger.info(\"*** Example ***\")\n","            logger.info(f\"guid: {example.guid}\")\n","            logger.info(f\"tokens: {' '.join(tokens)}\")\n","            logger.info(f\"input_ids: {' '.join(map(str, input_ids))}\")\n","            logger.info(f\"input_mask: {' '.join(map(str, input_mask))}\")\n","            logger.info(f\"segment_ids: {' '.join(map(str, segment_ids))}\")\n","            logger.info(f\"premis_mask: {' '.join(map(str, premise_mask))}\")\n","            logger.info(f\"hypoth_mask: {' '.join(map(str, hypothesis_mask))}\")\n","            try:\n","                logger.info(f\"label: {example.label}\")\n","            except:\n","                pass\n","\n","    if is_multi_choice:\n","        if len(features[-1]) == 0:\n","            features = features[:-1]\n","\n","    return features\n","\n","\n","def convert_features_to_tensors(features, output_mode, is_multi_choice=True):\n","\n","    input_ids = []\n","    input_mask = []\n","    segment_ids = []\n","    label_id = []\n","    premise_mask = []\n","    hypothesis_mask = []\n","\n","    if is_multi_choice:\n","        n_class = len(features[0])\n","        for f in features:\n","            input_ids.append([])\n","            input_mask.append([])\n","            segment_ids.append([])\n","            premise_mask.append([])\n","            hypothesis_mask.append([])\n","            for i in range(n_class):\n","                input_ids[-1].append(f[i].input_ids)\n","                input_mask[-1].append(f[i].input_mask)\n","                segment_ids[-1].append(f[i].segment_ids)\n","                premise_mask[-1].append(f[i].premise_mask)\n","                hypothesis_mask[-1].append(f[i].hypothesis_mask)\n","\n","            label_id.append([f[0].label_id])\n","    else:\n","        for f in features:\n","            input_ids.append(f.input_ids)\n","            input_mask.append(f.input_mask)\n","            segment_ids.append(f.segment_ids)\n","            label_id.append(f.label_id)\n","            premise_mask.append(f.premise_mask)\n","            hypothesis_mask.append(f.hypothesis_mask)\n","\n","    all_input_ids = torch.tensor(input_ids, dtype=torch.long)\n","    all_input_mask = torch.tensor(input_mask, dtype=torch.long)\n","    all_segment_ids = torch.tensor(segment_ids, dtype=torch.long)\n","    all_premise_mask = torch.tensor(premise_mask, dtype=torch.bool)\n","    all_hypothesis_mask = torch.tensor(hypothesis_mask, dtype=torch.bool)\n","\n","    if output_mode in [\"classification\", \"multi-choice\"]:\n","        all_label_ids = torch.tensor(label_id, dtype=torch.long)\n","    elif output_mode == \"regression\":\n","        all_label_ids = torch.tensor(label_id, dtype=torch.float)\n","\n","    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_premise_mask, all_hypothesis_mask, all_label_ids)\n","\n","    return data\n","\n","\n","def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) > len(tokens_b):\n","            tokens_a.pop()\n","        else:\n","            tokens_b.pop()\n","\n","\n","def _truncate_seq_tuple(tokens_a, tokens_b, tokens_c, max_length):\n","    \"\"\"Truncates a sequence tuple in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b) + len(tokens_c)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) >= len(tokens_b) and len(tokens_a) >= len(tokens_c):\n","            tokens_a.pop()\n","        elif len(tokens_b) >= len(tokens_a) and len(tokens_b) >= len(tokens_c):\n","            tokens_b.pop()\n","        else:\n","            tokens_c.pop()\n","\n","\n","processors = {\n","    \"vimmrc\": VimmrcProcessor,\n","    \"vinli\": VinliProcessor,\n","    \"vimmrc_race\": RaceProcessor,\n","}\n","\n","output_modes = {\n","    \"vimmrc\": 'multi-choice',\n","    \"vimmrc_race\": 'multi-choice',\n","    \"vinli\": \"classification\",\n","}\n","\n","GLUE_TASKS_NUM_LABELS = { \"vimmrc\": 4, \"vimmrc_race\": 4, \"vinli\": 3 }\n","\n","MAX_SEQ_LENGTHS = { \"vimmrc\": 512, \"vimmrc_race\": 512, \"vinli\": 128 }"]},{"cell_type":"markdown","metadata":{"id":"yoiGjVs5kuwD"},"source":["# Module"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"VG-MZ9JcbuBo","executionInfo":{"status":"ok","timestamp":1676727198250,"user_tz":-420,"elapsed":9,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}}},"outputs":[],"source":["import argparse\n","import glob\n","import json\n","import logging\n","import os\n","import random\n","\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n","from torch.utils.data.distributed import DistributedSampler\n","#from torch.optim import AdamW\n","from tqdm.auto import tqdm, trange\n","from transformers import (\n","    WEIGHTS_NAME, CONFIG_NAME,\n","    AdamW,\n","    BertConfig,\n","    BertForMultipleChoice,\n","    BertTokenizer,\n","    RobertaConfig,\n","    RobertaForMultipleChoice,\n","    RobertaTokenizer,\n","    XLMRobertaConfig,\n","    XLMRobertaForMultipleChoice,\n","    XLMRobertaTokenizer,\n","    XLNetConfig,\n","    XLNetForMultipleChoice,\n","    XLNetTokenizer,\n","    get_linear_schedule_with_warmup,\n",")\n","\n","from transformers import BERT_PRETRAINED_CONFIG_ARCHIVE_MAP, DISTILBERT_PRETRAINED_CONFIG_ARCHIVE_MAP, XLM_ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP\n","from transformers import DistilBertConfig, DistilBertForMultipleChoice, DistilBertTokenizer\n","\n","# try:\n","#     from torch.utils.tensorboard import SummaryWriter\n","# except ImportError:\n","#     from tensorboardX import SummaryWriter\n","\n","logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', datefmt='%m/%d/%Y %H:%M:%S', level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","logger.setLevel(logging.INFO)\n","\n","ALL_MODELS = tuple(DISTILBERT_PRETRAINED_CONFIG_ARCHIVE_MAP.keys()) + tuple(BERT_PRETRAINED_CONFIG_ARCHIVE_MAP.keys()) + tuple(XLM_ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP.keys())\n","\n","MODEL_CLASSES = {\n","    \"bert-man\": (BertConfig, BertForMultipleChoice_SAN, BertTokenizer),\n","    #\"roberta\": (RobertaConfig, RobertaForMultipleChoice, RobertaTokenizer),\n","    #\"xlm-roberta\": (XLMRobertaConfig, XLMRobertaForMultipleChoice, XLMRobertaTokenizer)\n","}"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"9Iow6D0wkEez","executionInfo":{"status":"ok","timestamp":1676727198250,"user_tz":-420,"elapsed":8,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}}},"outputs":[],"source":["def select_field(features, field):\n","    return [[choice[field] for choice in feature.choices_features] for feature in features]\n","\n","\n","def simple_accuracy(preds, labels):\n","    return (preds == labels).mean()\n","\n","\n","def set_seed(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    if args.n_gpu > 0:\n","        torch.cuda.manual_seed_all(args.seed)\n","\n","\n","def load_and_cache_examples(args, task, tokenizer, set_type='train'):\n","    if args.local_rank not in [-1, 0]:\n","        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n","    \n","    output_mode = output_modes[task]\n","    is_multi_choice = True if output_mode == 'multi-choice' else False\n","    processor = processors[task]()\n","    # Load data features from cache or dataset file\n","    cached_features_file = os.path.join(\n","        args.data_dir,\n","        'cached_{}_{}_{}_{}'.format(\n","            set_type,\n","            list(filter(None, args.model_name_or_path.split('/'))).pop(),\n","            str(MAX_SEQ_LENGTHS[task]),\n","            str(task)\n","        )\n","    )\n","    if os.path.exists(cached_features_file):\n","        logger.info(\"Loading features from cached file %s\", cached_features_file)\n","        features = torch.load(cached_features_file)\n","    else:\n","        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n","        label_list = processor.get_labels()\n","        if set_type == 'train':\n","            examples = processor.get_train_examples(args.data_dir)\n","        elif set_type == 'dev':\n","            examples = processor.get_dev_examples(args.data_dir)\n","        else:\n","            examples = processor.get_test_examples(args.data_dir)\n","        logger.info(\"Training number: %s\", str(len(examples)))\n","        features = convert_examples_to_features(\n","            examples,\n","            label_list,\n","            MAX_SEQ_LENGTHS[task],\n","            tokenizer,\n","            len(label_list),\n","            output_mode=output_mode,\n","            set_type=set_type,\n","            do_lower_case=args.do_lower_case,\n","            is_multi_choice=is_multi_choice\n","        )\n","        if args.local_rank in [-1, 0]:\n","            logger.info(\"Saving features into cached file %s\", cached_features_file)\n","            torch.save(features, cached_features_file)\n","\n","    # Convert to Tensors and build dataset\n","    dataset = convert_features_to_tensors(\n","        features, output_mode, is_multi_choice=is_multi_choice\n","    )\n","\n","    if set_type == 'dev' or set_type == 'test':\n","        all_example_ids = [x.guid for feature_set in features for x in feature_set]#[x.example_id for x in features]\n","        return dataset, all_example_ids\n","    else:\n","        return dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"2gdQTXe8k1Cf","executionInfo":{"status":"ok","timestamp":1676727198250,"user_tz":-420,"elapsed":8,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}}},"outputs":[],"source":["def train(args, train_datasets, model, tokenizer):\n","    \"\"\" Train the model \"\"\"\n","    # if args.local_rank in [-1, 0]:\n","    #     tb_writer = SummaryWriter()\n","    #     pass\n","\n","    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n","    train_iters = []\n","    tr_batches = []\n","    #for idx, train_dataset in enumerate(train_datasets):\n","    train_sampler = RandomSampler(train_datasets) if args.local_rank == -1 else DistributedSampler(train_datasets)\n","    train_dataloader = DataLoader(train_datasets, sampler=train_sampler, batch_size=args.train_batch_size)\n","    train_iters.append(InfiniteDataLoader(train_dataloader))\n","    tr_batches.append(len(train_dataloader))\n","\n","    ## set sampling proportion\n","    total_n_tr_batches = sum(tr_batches)\n","    sampling_prob = [float(n_batches) / total_n_tr_batches for n_batches in tr_batches]\n","    t_total = total_n_tr_batches // args.gradient_accumulation_steps * args.num_train_epochs\n","\n","    # Prepare optimizer and schedule (linear warmup and decay)\n","    no_decay = ['bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","         'weight_decay': args.weight_decay},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","         'weight_decay': 0.0}\n","    ]\n","\n","    # optimizer = BertAdam(\n","    #     optimizer_grouped_parameters,\n","    #     lr=args.learning_rate,\n","    #     warmup=args.warmup_proportion,\n","    #     max_grad_norm=args.max_grad_norm, t_total=t_total)\n","    \n","    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, correct_bias=False, no_deprecation_warning=True) # To reproduce BertAdam specific behavior set correct_bias=False\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=int(args.warmup_proportion * t_total),\n","        num_training_steps=t_total,\n","    ) # PyTorch scheduler\n","\n","    # Train!\n","    logger.info(\"***** Running training *****\")\n","    logger.info(\"  Num examples = %d\", len(train_datasets))\n","    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n","    logger.info(\"  Instantaneous batch size per GPU = %s\", args.per_gpu_train_batch_size)\n","    logger.info(\n","        \" Total train batch size (w. parallel, distributed & accumulation) = %d\",\n","        args.train_batch_size\n","        * args.gradient_accumulation_steps\n","        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n","    )\n","    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n","    logger.info(\"  Total optimization steps = %d\", t_total)\n","\n","    global_step = 0\n","    tr_loss, logging_loss, tmp_loss = 0.0, 0.0, 0.0\n","    best_dev_acc = 0.0\n","    best_steps = 0\n","    nb_tr_examples = 0\n","    model.zero_grad()\n","    train_iterator = tqdm(range(int(args.num_train_epochs)), desc=\"Epoch\") #, disable=args.local_rank not in [-1, 0])\n","    set_seed(args)  # Added here for reproductibility (even between python 2 and 3)\n","    for epoch, _ in enumerate(train_iterator):\n","        epoch_iterator = tqdm(range(total_n_tr_batches), desc=\"Iteration\") #, disable=args.local_rank not in [-1, 0])\n","        for step, _ in enumerate(epoch_iterator):\n","            epoch_iterator.set_description(\n","                \"train loss: {}\".format(tr_loss / nb_tr_examples if nb_tr_examples else tr_loss)\n","            )\n","            model.train()\n","            # select task id\n","            task_id = np.argmax(np.random.multinomial(1, sampling_prob))\n","            batch = train_iters[task_id].get_next()\n","            batch = tuple(t.to(args.device) for t in batch)\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'token_type_ids': batch[2],\n","                      'premise_mask':   batch[3],\n","                      'hyp_mask':       batch[4],\n","                      'labels':         batch[5],\n","                      'task_id':        task_id}\n","            outputs = model(**inputs)  # model outputs are always tuple in transformers (see doc)\n","            loss = outputs[0]\n","\n","            if args.n_gpu > 1:\n","                loss = loss.mean() # mean() to average on multi-gpu parallel training\n","            if args.gradient_accumulation_steps > 1:\n","                loss = loss / args.gradient_accumulation_steps\n","\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","\n","            tr_loss += loss.item()\n","            nb_tr_examples += inputs['input_ids'].size(0)\n","            if (step + 1) % args.gradient_accumulation_steps == 0:\n","                optimizer.step()\n","                scheduler.step()  # Update learning rate schedule\n","                model.zero_grad()\n","                global_step += 1\n","                #tb_writer.add_scalar(\"train_{}\".format(\"loss_\"), tr_loss - tmp_loss, global_step)\n","                tmp_loss = tr_loss\n","\n","        # Save model checkpoint\n","        # if args.do_epoch_checkpoint:\n","        epoch_output_dir = os.path.join(args.output_dir, 'epoch_{}'.format(epoch+1))\n","        os.makedirs(epoch_output_dir, exist_ok=True)\n","        output_model_file = os.path.join(epoch_output_dir, WEIGHTS_NAME)\n","        output_config_file = os.path.join(epoch_output_dir, CONFIG_NAME)\n","        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n","        torch.save(model_to_save.state_dict(), output_model_file)\n","        model_to_save.config.to_json_file(output_config_file)\n","        tokenizer.save_vocabulary(epoch_output_dir)\n","\n","        # evaluate(args, model, tokenizer, epoch=epoch, is_test=False)\n","        # evaluate(args, model, tokenizer, epoch=epoch, is_test=True)\n","    # if args.local_rank in [-1, 0]:\n","    #     tb_writer.close()\n","\n","    return global_step, tr_loss / global_step, best_steps"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"hUI-m6tlk3iR","executionInfo":{"status":"ok","timestamp":1676727198250,"user_tz":-420,"elapsed":7,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}}},"outputs":[],"source":["def evaluate(args, model, tokenizer, checkpoint='', is_test=False, error=False):\n","    # Loop to handle MNLI double evaluation (matched, mis-matched)\n","    eval_task_names = args.task_name\n","    eval_output_dir = args.output_dir\n","\n","    set_type = 'test' if is_test else 'dev'\n","    results = {}\n","    #for task_id, eval_task in enumerate(eval_task_names):\n","    #for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n","    eval_dataset, all_example_ids = load_and_cache_examples(args, eval_task_names, tokenizer, set_type)\n","    \n","    if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n","        os.makedirs(eval_output_dir)\n","\n","    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n","    # Note that DistributedSampler samples randomly\n","    eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)\n","    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n","\n","    # Eval!\n","    logger.info(\"***** Running evaluation for {} on {} for {} *****\".format(eval_task_names, set_type, checkpoint))\n","    logger.info(\"  Num examples = %d\", len(eval_dataset))\n","    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    logits_all = None\n","    out_label_ids = None\n","    preds_softmax = None\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","        model.eval()\n","        batch = tuple(t.to(args.device) for t in batch)\n","\n","        with torch.no_grad():\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'token_type_ids': batch[2],\n","                      'premise_mask':   batch[3],\n","                      'hyp_mask':       batch[4],\n","                      'labels':         batch[5],\n","                      'task_id':        0}\n","            outputs = model(**inputs)\n","            tmp_eval_loss, logits = outputs[:2]\n","            # input_ids, input_mask, segment_ids, label_ids = batch\n","            # tmp_eval_loss, logits = model(input_ids, segment_ids, input_mask, label_ids, task_id=task_id)\n","            eval_loss += tmp_eval_loss.mean().item()\n","        nb_eval_steps += 1\n","        if logits_all is None:\n","            logits_all = logits.detach().cpu().numpy()\n","            preds_softmax = torch.softmax(logits, -1).detach().cpu().numpy()\n","            out_label_ids = inputs['labels'].detach().cpu().numpy()\n","        else:\n","            logits_all = np.append(logits_all, logits.detach().cpu().numpy(), axis=0)\n","            preds_softmax = np.append(preds_softmax, torch.softmax(logits, -1).detach().cpu().numpy(), axis=0)\n","            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    preds_softmax = [[round(x.tolist(), 4) for x in p] for p in preds_softmax]\n","    example_ids = [id[:-2] for id in all_example_ids[::4]]\n","    per_id_pred = dict(zip(example_ids, preds_softmax))\n","    output_mode = output_modes[eval_task_names]\n","\n","    preds = np.argmax(logits_all, axis=1)\n","    acc = simple_accuracy(preds, out_label_ids.reshape(-1))\n","    #result = compute_metrics(eval_task, preds, out_label_ids.reshape(-1))\n","    result = {\"eval_acc\": acc, \"eval_loss\": eval_loss}\n","    results.update(result)\n","\n","    output_eval_file = os.path.join(eval_output_dir, \"eval_results_{}_{}.txt\".format(eval_task_names, set_type))\n","    with open(output_eval_file, \"a\") as writer:\n","        logger.info(\"***** Eval results for {} on {} for {} *****\".format(eval_task_names, set_type, checkpoint))\n","        writer.write(\"***** Eval results for {} *****\\n\".format(checkpoint))\n","        writer.write(\n","            \"total batch size=%d\\n\"\n","            % (\n","                args.per_gpu_train_batch_size\n","                * args.gradient_accumulation_steps\n","                * (torch.distributed.get_world_size() if args.local_rank != -1 else 1)\n","            )\n","        )\n","        writer.write(\"train num epochs=%d\\n\" % args.num_train_epochs)\n","        writer.write(\"max seq length  =%d\\n\" % MAX_SEQ_LENGTHS[eval_task_names])#args.max_seq_length)\n","        for key in sorted(result.keys()):\n","            logger.info(\"  %s = %s\", key, str(result[key]))\n","            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","        logger.info(\"\\n\")\n","    \n","    # Write pred\n","    output_pred_file = os.path.join(eval_output_dir, \"predictions_\" + str(is_test).lower() + \"_eval_results.json\")\n","    with open(output_pred_file, \"w\") as writer:\n","        json.dump(per_id_pred, writer, indent=4)\n","        logger.info(\"Saved {0}\".format(output_pred_file))\n","\n","    # Write pred with label\n","    processor = processors[args.task_name]()\n","    label_list = processor.get_labels()#['A','B','C','D']\n","    idx2label = {i: label for i, label in enumerate(label_list)}\n","    output_pred_file = os.path.join(eval_output_dir, \"predictions_\" + str(is_test).lower() + \"_eval_results_label.json\")\n","    with open(output_pred_file, \"w\") as writer:\n","        json.dump({'pred': [idx2label[id[0]] for id in out_label_ids.tolist()]}, writer, indent=4)\n","        logger.info(\"Saved {0}\".format(output_pred_file))\n","\n","    # Get error idx\n","    if error:\n","        correct_idx = np.argwhere(preds == out_label_ids).tolist()\n","        wrong_idx = np.argwhere(preds != out_label_ids).tolist()\n","        wrong_idx_dict = {\n","            'correct': correct_idx, 'wrong': wrong_idx,\n","            'preds': preds.tolist(), 'logits': logits_all.tolist(),\n","            'labels': out_label_ids.tolist()\n","        }\n","        output_error_file = os.path.join(eval_output_dir,\"error_idx_{}_{}.json\".format(eval_task_names, set_type))\n","        with open(output_error_file, \"w\") as writer:\n","            json.dump(wrong_idx_dict, writer)\n","            logger.info(\"Saved {0}\".format(output_error_file))\n","\n","    return results"]},{"cell_type":"markdown","metadata":{"id":"fyV2VX7Vk1RA"},"source":["# Main"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"daHi3mJlTi69","executionInfo":{"status":"ok","timestamp":1676727198251,"user_tz":-420,"elapsed":8,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}}},"outputs":[],"source":["PRJ_DIR = '/content/drive/MyDrive/NCKH/ViMMRC_model'\n","OUTPUT_DIR = PRJ_DIR + '/models/vibert_nli_man_v1'"]},{"cell_type":"code","source":["def main(args):\n","\n","    # Setup distant debugging if needed\n","    # if args.server_ip and args.server_port:\n","    #     # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n","    #     import ptvsd\n","\n","    #     print(\"Waiting for debugger attach\")\n","    #     ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n","    #     ptvsd.wait_for_attach()\n","\n","    # Setup CUDA, GPU & distributed training\n","    if args.local_rank == -1 or args.no_cuda:\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n","        args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n","    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n","        torch.cuda.set_device(args.local_rank)\n","        device = torch.device(\"cuda\", args.local_rank)\n","        torch.distributed.init_process_group(backend=\"nccl\")\n","        args.n_gpu = 1\n","    logger.info(\"device: %s, n_gpu: %d, distributed training %r\", device, args.n_gpu, bool(args.local_rank != -1))\n","    args.device = device\n","\n","    if args.gradient_accumulation_steps < 1:\n","        raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\n","            args.gradient_accumulation_steps))\n","\n","    if os.path.exists(args.output_dir) and os.listdir(args.output_dir):\n","        if args.do_train:\n","            print(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n","    else:\n","        os.makedirs(args.output_dir, exist_ok=True)\n","    \n","    # Set seed\n","    set_seed(args)\n","\n","    # Prepare GLUE task\n","    args.task_name = args.task_name.lower()\n","    if args.task_name not in processors:\n","        raise ValueError(\"Task not found: %s\" % (args.task_name))\n","    processor = processors[args.task_name]()\n","    label_list = processor.get_labels()\n","    num_labels = len(label_list)\n","\n","    # Load pretrained model and tokenizer\n","    if args.local_rank not in [-1, 0]:\n","        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n","\n","    args.model_type = args.model_type.lower()\n","    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n","    config = config_class.from_pretrained(\n","        args.config_name if args.config_name else args.model_name_or_path,\n","        num_labels=num_labels,\n","        early_stopping = True,\n","        finetuning_task=args.task_name,\n","        cache_dir=args.cache_dir if args.cache_dir else None,\n","    )\n","    tokenizer = tokenizer_class.from_pretrained(\n","        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n","        do_lower_case=args.do_lower_case,\n","        cache_dir=args.cache_dir if args.cache_dir else None,\n","    )\n","    model = model_class.from_pretrained(\n","        args.model_name_or_path,\n","        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n","        config=config,\n","        cache_dir=args.cache_dir if args.cache_dir else None,\n","        opt={\"use_SAN\": 1},\n","        num_choices=[4]\n","    )\n","\n","    if args.local_rank == 0:\n","        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n","\n","    options_print = \"\"\n","    logging.info(\"Arg Options:\")\n","    for arg in vars(args):\n","        options_print += \"opt: %s=%s\\r\\n\" % (arg, getattr(args, arg))\n","    logging.info(options_print)\n","\n","    model.to(args.device)\n","\n","    def get_model_base_obj(model, model_type):\n","        if model_type == \"bert\":\n","            return model.bert\n","        elif model_type == \"xlm-roberta\" or model_type == \"roberta\":\n","            return model.roberta\n","        elif model_type == \"distilbert\":\n","            return model.distilbert    \n","        else:\n","            raise ValueError(\"model_type='{0}' is not supported!\")\n","\n","    if args.freeze_embeddings:\n","        for param in list(get_model_base_obj(model, args.model_type).embeddings.parameters()):\n","            param.requires_grad = False\n","        logger.info(\"Froze Embedding Layer\")\n","\n","    # freeze_layers is a string \"1,2,3\" representing layer number\n","    if args.freeze_layers:\n","        layer_indexes = [int(x) for x in args.freeze_layers]\n","        for layer_idx in layer_indexes:\n","            for param in list(\n","                get_model_base_obj(model, args.model_type).encoder.layer[layer_idx].parameters()\n","            ):\n","                param.requires_grad = False\n","            logger.info(\"Froze Layer: %s\", layer_idx)\n","\n","    logger.info(\"Training/evaluation parameters %s\", args)\n","    best_steps = 0\n","\n","    # Training\n","    if args.do_train:\n","        train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, set_type='train')\n","        global_step, tr_loss, best_steps = train(args, train_dataset, model, tokenizer)\n","        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n","\n","    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n","        # Create output directory if needed\n","        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n","            os.makedirs(args.output_dir)\n","\n","        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n","        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","        # They can then be reloaded using `from_pretrained()`\n","        model_to_save = (\n","            model.module if hasattr(model, \"module\") else model\n","        )  # Take care of distributed/parallel training\n","        model_to_save.save_pretrained(args.output_dir)\n","        tokenizer.save_pretrained(args.output_dir)\n","\n","        # Good practice: save your training arguments together with the trained model\n","        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n","\n","        # Load a trained model and vocabulary that you have fine-tuned\n","        model = model_class.from_pretrained(args.output_dir, opt={\"use_SAN\": 1}, num_choices=[4])\n","        tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n","        model.to(args.device)\n","\n","    # Evaluation\n","    results = {}\n","    if args.do_eval and args.local_rank in [-1, 0]:\n","        if not args.do_train:\n","            args.output_dir = args.model_name_or_path\n","        checkpoints = [args.output_dir]\n","        if args.eval_all_checkpoints:\n","            checkpoints = list(\n","                os.path.dirname(c)\n","                for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n","            )\n","            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n","        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","        for checkpoint in checkpoints:\n","            global_step = checkpoint.split(\"/\")[-1] if len(checkpoints) > 1 else \"\"\n","            model = model_class.from_pretrained(checkpoint, opt={\"use_SAN\": 1}, num_choices=[4])\n","            model.to(args.device)\n","            result = evaluate(args, model, tokenizer, global_step)\n","            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n","            results.update(result)\n","\n","    if args.do_test and args.local_rank in [-1, 0]:\n","        checkpoints = [args.output_dir]\n","        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","        for checkpoint in checkpoints:\n","            global_step = checkpoint.split(\"/\")[-1]\n","            model = model_class.from_pretrained(checkpoint, opt={\"use_SAN\": 1}, num_choices=[4])\n","            model.to(args.device)\n","            result = evaluate(args, model, tokenizer, global_step, is_test=True)\n","            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n","            results.update(result)\n","    # if best_steps:\n","    #     logger.info(\"best steps of eval acc is the following checkpoints: %s\", best_steps)\n","    return results"],"metadata":{"id":"buie7mv2VosR","executionInfo":{"status":"ok","timestamp":1676727198251,"user_tz":-420,"elapsed":8,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"42dvg6DqZPg2"},"source":["## Train "]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1676727198251,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"Tfky1cL1wKzR","outputId":"40fb1cb1-d165-4465-afaf-5f3234a3bbf4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'data_dir': '/content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1',\n"," 'model_type': 'bert-man',\n"," 'model_name_or_path': '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli',\n"," 'task_name': 'vimmrc_race',\n"," 'output_predictions': True,\n"," 'output_dir': '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1',\n"," 'freeze_embeddings': False,\n"," 'freeze_layers': None,\n"," 'tb_log_dir': '',\n"," 'config_name': '',\n"," 'tokenizer_name': '',\n"," 'cache_dir': '/content/drive/MyDrive/NCKH/ViMMRC_model/models/cached',\n"," 'max_seq_length': 512,\n"," 'do_train': True,\n"," 'do_eval': True,\n"," 'do_test': False,\n"," 'evaluate_during_training': True,\n"," 'do_lower_case': False,\n"," 'per_gpu_train_batch_size': 8,\n"," 'per_gpu_eval_batch_size': 4,\n"," 'gradient_accumulation_steps': 4,\n"," 'learning_rate': 3e-05,\n"," 'weight_decay': 0.01,\n"," 'max_grad_norm': 1.0,\n"," 'num_train_epochs': 10,\n"," 'max_steps': -1,\n"," 'warmup_proportion': 0.1,\n"," 'eval_all_checkpoints': True,\n"," 'no_cuda': False,\n"," 'seed': 42,\n"," 'local_rank': -1,\n"," 'f': '/root/.local/share/jupyter/runtime/kernel-929c737f-7388-4c32-babe-4ee6ce6e1833.json'}"]},"metadata":{},"execution_count":14}],"source":["parser = argparse.ArgumentParser()\n","\n","if True:\n","    # Required parameters\n","    parser.add_argument(\n","        \"--data_dir\", default=\"{}/dataset/ViMMRC_RACE_v1\".format(PRJ_DIR), type=str,\n","        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n","    )\n","\n","    parser.add_argument(\n","        \"--model_type\", default=\"bert-man\", type=str,\n","        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n","    )\n","    parser.add_argument(\n","        \"--model_name_or_path\", default=\"{}/models/vibert_nli\".format(PRJ_DIR), type=str,\n","        help=\"Path to pre-trained model or shortcut name selected in the list: \" + \", \".join(ALL_MODELS),\n","    )\n","    \n","    parser.add_argument(\n","        \"--task_name\", default=\"vimmrc_race\", type=str,\n","        help=\"The name of the task to train selected in the list: \" + \", \".join(processors.keys()),\n","    )\n","    # parser.add_argument(\n","    #     \"--para_type\", default=\"per_choice\", type=str,\n","    #     choices=[\"per_choice\", \"concat_choices\", \"ignore\"],\n","    #     help=\"Paragraph building strategy for ARC (default: %(default)s)\",\n","    # )\n","    parser.add_argument(\n","        \"--output_predictions\", default=True, type=bool, help=\"Whether to export the predictions from the eval step.\",\n","    )\n","    parser.add_argument(\n","        \"--output_dir\", default=OUTPUT_DIR, type=str, help=\"The output directory where the model predictions and checkpoints will be written.\",\n","    )\n","    parser.add_argument(\"--freeze_embeddings\", default=False, action=\"store_true\", help=\"Whether to freeze the embeeding layer.\",)\n","    parser.add_argument(\"--freeze_layers\", nargs=\"*\", help=\"Whether to freeze the embeeding layer.\",)\n","\n","    # Other parameters\n","    parser.add_argument(\"--tb_log_dir\", default=\"\", type=str, help=\"Tensorboard log dir for the current experiment\")\n","    parser.add_argument(\"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\")\n","    parser.add_argument(\"--tokenizer_name\", default=\"\", type=str, help=\"Pretrained tokenizer name or path if not the same as model_name\")\n","    parser.add_argument(\n","        \"--cache_dir\", default=\"{}/models/cached\".format(PRJ_DIR), type=str, help=\"Where do you want to store the pre-trained models downloaded from s3\",\n","    )\n","    parser.add_argument(\n","        \"--max_seq_length\", default=MAX_SEQ_LENGTHS['vimmrc'], type=int,\n","        help=\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\",\n","    )\n","    parser.add_argument(\"--do_train\", default = True, action=\"store_true\", help=\"Whether to run training.\")\n","    parser.add_argument(\"--do_eval\", default = True, action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n","    parser.add_argument(\"--do_test\", default = False, action=\"store_true\", help=\"Whether to run test on the test set\")\n","    parser.add_argument(\n","        \"--evaluate_during_training\", action=\"store_true\", default = True, help=\"Run evaluation during training at each logging step.\",\n","    )\n","    parser.add_argument(\n","        \"--do_lower_case\", action=\"store_true\", default = False, help=\"Set this flag if you are using an uncased model.\",\n","    )\n","\n","    parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\",)\n","    parser.add_argument(\"--per_gpu_eval_batch_size\", default=4, type=int, help=\"Batch size per GPU/CPU for evaluation.\",)\n","    parser.add_argument(\n","        \"--gradient_accumulation_steps\", type=int, default=4, help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n","    )\n","    parser.add_argument(\"--learning_rate\", default=3e-5, type=float, help=\"The initial learning rate for Adam.\")\n","    parser.add_argument(\"--weight_decay\", default=0.01, type=float, help=\"Weight decay if we apply some.\")\n","    # parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n","    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n","    parser.add_argument(\"--num_train_epochs\", default=10, type=float, help=\"Total number of training epochs to perform.\")\n","    parser.add_argument(\"--max_steps\", default=-1, type=int, help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n","    parser.add_argument(\"--warmup_proportion\", default=0.1, type=float, help=\"Linear warmup over warmup_proportion.\")\n","\n","    # parser.add_argument(\"--logging_steps\", type=int, default=100, help=\"Log every X updates steps.\")\n","    # parser.add_argument(\"--save_steps\", type=int, default=500, help=\"Save checkpoint every X updates steps.\")\n","    parser.add_argument(\n","        \"--eval_all_checkpoints\", default=True, action=\"store_true\",\n","        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n","    )\n","    parser.add_argument(\"--no_cuda\", default=False, action=\"store_true\", help=\"Avoid using CUDA when available\")\n","    # parser.add_argument(\n","    #     \"--overwrite_output_dir\", default = True, action=\"store_true\", help=\"Overwrite the content of the output directory\",\n","    # )\n","    # parser.add_argument(\n","    #     \"--overwrite_cache\", default = True, action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\",\n","    # )\n","    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n","\n","    # parser.add_argument(\n","    #     \"--fp16\", action=\"store_true\", help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n","    # )\n","    # parser.add_argument(\n","    #     \"--fp16_opt_level\", type=str, default=\"O1\",\n","    #     help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n","    #     \"See details at https://nvidia.github.io/apex/amp.html\",\n","    # )\n","    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n","    # parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n","    # parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n","\n","    parser.add_argument('-f')\n","\n","args = parser.parse_args()\n","vars(args)\n","# options_print = \"\"\n","# logger.info(\"Arg Options - input:\")\n","# for arg in vars(args):\n","#     options_print += \"opt: %s=%s\\r\\n\" % (arg, getattr(args, arg))\n","# logger.info(options_print)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9b601f9616f24a7aa0c72996ebb04971","1d5dbe36178c4ee4a3405886f427561e","43acc2439ead4fefb6e1b891f4f2f15c","126d0132e5b6476a84a226cb02be54e6","bde3c1a42f964828abc5bca374ae80d4","31bb667022b548f9be44f5a590b8441d","acc1e40e943f4e59a95b57e025a11bfb","4141e4effc3b4b9887a7f9d90dc10618","940ba46411e249aaa20dba8b822f3d0d","8fc37818955148419daa16c9b8019b66","6cc22202292c49cab997d5c38494a070","33923d6619e94c1cb50e66fb5e33b0e7","bf8002d92a9647b89480ef33f1552309","73752f76b5284bd588409bdac7719358","7460a7584959433c88678a02ce0f0386","4d051cc0a7f2410a9c452bd29012f8cc","89930426c94546feb488eb545af2b553","5c67f24a17a74f7fb4b24b2da269f8eb","e5cf2035d50b404f992345e9bce1ae06","13034e0dfe004c64896197315125575c","c3a40fb7c0aa43c3bb9cb6632251ea18","8aba81c970994ef4bab9c20492994051","6ebac90c871c4185bc32b1e3838c67d3","e555dbd489734eada121d3d1385bede8","c9efa2d681c04319b60fa3a7b4241c23","ea1dc092122145afb45682c74b6cc9cf","16844095349242dd9c139f88562cf25c","5fb5b84bd98349d185dc6bfb4740338a","37db88d58c86471eabb68b4ad606ba2a","8caab8f9cb084aa281cc66c381575216","1e1141403e6b4b42af740c781ff2acd8","0d866b17239b4e92936b4e827241b153","cc5552e6ce904e06b90eaaa6f294ccc5","58d6d2103cb4447b8793050fd3a48ad0","16a72352a03a4bd099c2e3b8b7fb2968","6838fc040aaf4e528406329a5dc97f1b","fe7dc05ae26a467c9f4c2e7838914a6a","f79ee69d38fd4abd9c5e84d21e293fdb","69bfe07e8ae546b99d2c3b6e180e002c","22d656e3844141a3b5655311dc4f2e00","95ea8a0209a248049378d077d6876e4e","10878fba474a419baca20f9c1f7a972c","42227a25a140439381e403f238476511","bfc0982631934990800b0eba19cbcef4","9800f6586ffc494ba7fff773c1e0505d","6581ff832e2d45d685dd1bc4bd76edc7","c2b606455e0249deb3017fe930d1c7a6","639e24219f264df5ba00304ded68c4fa","8347af56bbe6452c8c8ba0ee2dc1c59a","6897e9ed9933451ebdaa5a2a3a4f63ce","5e49f2cd9e1548a2b967a0b13a0ee0ea","f24e1a00836f468ea01db0dec23e8956","ec8cc218bf66460b8f0d62942f730167","2ceaa0400fd64de3a54149894f0f2b87","baaad33c4f034cfaa257250ef1f29078","e66832b5663d4c0e9b9ed6a594449597","ae0dfda4e1fa4dc79187a403a9c685c8","0b378bd3ba604019b2b721937f9363c1","d0cecbe4c55d4cc986859493ca743ef2","3b668d04306f46c88e1c98de7faa72ae","3e7b41802fcb45c981e006b3ef3bed38","4cb804ffbf8b4df08e117466f13922f6","770cf2d42f3e4a4cada567c423709880","1e3b34a4aab64fc7b301cb9a8a4267d4","7b6e5e6308fe42b084dd6b5c3fefb8de","4925f6b0fe6947cead094ad19d072073","d1dbc8440dd34915857687d04636a11c","67a630662e0a4c7d9ce1d28c729da259","2e8e558d029e40449667f802fc5291d3","a83f5b85530649d6ae41c66a75ab1951","cd8f9d5cdf924d819866bead78299e5c","8e7de8f9a2934b35b5287541432014f1","a423f1ea74dd42b780e63440521fd4ee","5dd8406ab91d4ce98149fb9a6c74686e","45f1c9669b3145379eaf18038a05132a","ddd425401fc94716aa7dca7bc64fa97b","1c6f7cf3e0174c28b92bcb6e36761dc7","7e57ca7fe56b4b68aad9b10a4056fb34","0af2b17d0fc446a6b2f45c7c19601beb","d658462c434347eab67c7ce7f115c2d8","a6d3918a80a8498aac6f049f53df074e","87bb9796df8d466c965d8ae915363f7a","8ca603a2bd8d4c8e8cb1503d39882b7d","15a94cb4557a4f319e3ab51069f1920c","d9caf54d1dad4c47ba3f1326113acf58","071d6ffc0ca048ee9b9981965dfe15ff","b37a1b340a96439e8d2a1108e6a802d7","a9e4a1d9065c480cafdab9aadb367da8","9ffce7554eca4486a9337167f3df89c4","2cfe663e5e17471c9dbce4dfe3851884","313b57a647724c6db41d3db3ffc221f8","fd4078c0962a488e9727c80fc830fedd","3479f20b5dfe4e109a21208e722f64ee","97fb5774bc2a4c6a8250330f5b035ac5","648afef31dda473fa93485142fea7ee7","ab742ad6c7d048048fa490767681dd62","fd1c449efe8d47a29da356c3dd2c7c97","6931f0c87be14d7db57fc0270c89019a","61868b94255044029ad9cf15013dfcba","ba078e942c0940a49616f2c0d3b974f5","1717111de5a54043a0ab6623b728f370","4a8b3f994e25492c9e4b1e111442b8b4","381a3719c69040b3bf874c2e1f2b1dfe","9c00c16e41ab43a2b822e364cbf3d2a7","2be381021e7e46b99c9f9331b148974f","5709f1c6f60c47c29a4fd3c47177e596","8c835f65c2ff43ee8dd1b0791ef366c7","397aa7d787f745f3b791d3495eb4c3db","340cbbd3251445448fa583d9e1575499","835a6949f96c4487ae5497b5d2ef63d4","450cf948ddd042c28fa2ba09163f4b17","9f07ddae4a4d4e6892ce83ebdd695fe3","7e2fea16ee3c4006a28cea4cea5aa768","5009f576f3e5499a81c7fac71067ce17","b384d368afd74d19bdab6d874bc03763","0d688b4f9e20453b9372eea0f30a7bc8","7401ba2fcee84cc992a069a5158aad5c","1a191040c8a640d98c98b2cf97d22c64","8a67bf6f3ea54d1aa366de9977964aa0","8ef0ad6a430d4ddb929485e5afde2cd0","f991d0f194eb4d08899acee37cf042a6","425b9b76d217450e91d071f9dc0c75dd","c26c56b225904dfe8bbaa848ed62bcaf","a43c3cb6879741568319c2b111fcf549","ac325c5ab4224a9881359b049d2a0611","7b7d797534614b6cacd61b885f4ca7cf","efd9cd89ea4743738d335bb2617c0a9b","c99731f820564c2b9f41b6fc74f4fff7","2f2d73acf6844613800e2381e2470c4c","5813410990574b8e8d24b3f7af642e4d","8d8e65a52df5419e9132b53f96739c5c","01b8c265725a463fae4fc14c4684af71","3c80eed0966d4794989b50391a61b52d","f8143bbf69e6451cae1f599e33cccf30","134cdcd04ac04a30919dee9325cb4de2","88a06841cc9c461d8b72f02eb0eecdb5","605e4f1a1e6043aabff4263fafcf1d63","04f725c6e815494eab9e950242f6c89b","3d5ddac0519d406c882be60ce038a7cd","975893d6c4eb4d3d9203a2cc53517e61","f024e07b76e64b168e49f45bad20b5d3","2edb6662b52046d3af5cddb0170ea8a5","efc0e584479d4556b8b2e36b21feb4c5","8baa15ba0cf545fab6e43a82299c8706","82dd5d6df5f74a4e95eea20310cf089b","1373da9782094c43b21e438c6ba5ac44","139ddd0036c94003bae52c554023be15","3807c05b29d948dbb35ceb5d3783d79f","cefe10b11cdc4cdca8b262a742b7f95a","05cff7601f4b404f88a76c3122729ece","2bb8f49c87834ace8be98ad5862d237f","6901f761a3814241a15fa7df74cdc36d","ce7fd709dcbb4efea07a6d491bdbd96e","18318480508341c7858262b6c8bb5aea","2dc2eb8c92e448e3becd29c2e29e16d2","80c3841463e342dd99ffff5bbcb0299b","6a2b02cfe101449c9932bf47eaed359b","a041ca8bd46348248e466a09a4c5036b","e716cc86540e496bb7221b9aa13aa163","08c38b434ae14247948b35a984f27b03","e32de9755ba94fa3bc2e07548651b4c8","6cb299e0b8484655b6316c47486b2387","a66e06043e5248aab5b803efd7744d7b","44ea5fa45507415fadc8c6de5647c1a4","7b37d5118260455a832a7b4573952559","01abf26250d64fe79ff2d9297c3a40e7","08356ad962984c0fafaff384d35a933a","8008b1a9694c42aa88f51878ba60cd7c","7bf551a2890c4550a61bb56a9e5ce875","19d3dec988bc4bc4af25dd6686b97f1e","249988992c964e789ef1746336bec4fb","0c42924a2a2347688778a0acf3042c00","4cda783093d84138b79b54f84592c9b5","0a5b3dc19d294b458f643f86063cc07d","fc6f63b8f94647cba0fe7e200a60244f","26c84e44ac0d4b16ae4b0823f62bda50","d07d39d4c8d449b0969ffd16149eb3fe","3cee9b3536fb4ddf9fe8baa84a1c6b60","2fd2b4f82bb44ffeb3680280fdea167d","fbadf3a1b157412489db20f2af4e1d1e","a16a0f7a106c49a8bd00c39d19457255","a7b088fcb5c54935b6f6d83fffaf41b3","1eef994556944cbe8a7677a1dd0e2db7","5988a14a29084476a6beacd775fc896e","ba23219429414214b474f5380deffd24","fa8a7afd08f2409d8f1f2710c1cf26ed","72ae85f489784c83bc1dd530d1fb7d59","34a3702cd6d34932a7a0ab9daf62bdf2","0349aa8db23e41ffbcc5468f8ac98410","af1ecf6b9768477585479b8f5bc35d1c","07879b75fccc4dd99e820ad23d880629","867a620953f1461db3a34723b1d31484","968896e31fca4e4d8dafdddacb9b92a8","1fe347ba1b034df78d32de6feeb91e85","63f1708b2c344ecc953193bf32eada3a","0572092fb1d34afdab0f21f167a9e292","343250b2f34c4bb1b7433bc6c69c4287","f5476d626b564950b1ce406cadc91ba8","896bed3df9214b46b4795f386ff92d05","e9b4e9899f4b49ff9733cf6cae1aa67d","0d6f0ad81079404a868237d0c20e2a81","8a4e0f3573814693b014306362af7697","6c5aac6c62574a3c90472a00f2a1398b","b339924bfa784391969d00686927f194","7f5f49f9cc6c4bb5928435fee3ee92bc","61682430c75f4ee6bef48720d42f8204","f03a9f5f78f64b45ab50ff6e8adbd47c","8395d586272c4ea29e8331b58af97a7a","6064c1fe859e41eeb8d0b797fcb484a1","bb6466d993464f6bba820a6de5cd66e8","8202a28f65ca42f6b7a88870f2655ea5","1c390b3b808440d58b80b7b48dc943b4","3767f64327254cd7ac412ac30d156717","29f60c6386b2410fb97f420fbf07b878","195cd0f856a54c829a8bcaffa278e68d","67b22addb20141969da6fc3c5925b744","0ae17a63b96a499286863754856c3fa7","e6fba296f215438487e6a91cf8eb93a3","837fd13cbc1541c18eaa13f2cbd0628c","2b423cbad2834b4eaa335b588fc212a8","bf92019fdb2841b190c60e9dbe4650ff","3b1156fb4ee944b59e26a74b38a71d53","b96b8096c4d9438dadb8163d6d819169","63189285da6c4bf6869e579bd8bfcc09","6ea846a6c8694c4bac9321647f450ae6","d879fd988cc54888bd0ec059cce87890","242fffc5b9734d78a0758033a0cedcbf","e84fbfb80d154949b30db0616041616a","99bd83b85c4b4204b50287ba5b75f1d8","89b25f3fd64e4848847bd40bb73f0456","f0533260297942ba967364b0fa7244d9","c5f53751180042d1b5ac47459ef4d4a5","b59242ab233b4869af1fd313ced13080","f053acff192d4d629f956105b3dc9eaf","c7d54c93a5d64e90a3282c86294312d0","0bffc4fd9f3d4b2eba8724ea7263cfbd","46a0c35a93f94380b813925376b7936a","a67f57e63abe438cb9345d556ee144f9","75c8ab3783514be9890e3dc5f1879e6f","b779da19f542465783533f0e2072c14c","0f560fbe78744124addc19f209fdf838","02540b99a49c4679b5e85c08cc153855","53b06e56d91441f6be1b6b1fd5a0699d","4eda7d5a5ef243bc9dccca667e8f2c30","a124873171f94e3ea50d169326ff38de","b14e4e35b23943bc83faca273beab283","c7e0eb8f87c24b6ca765d734d9b3869f","a7d9ca411f4d43ecac5233ceec1a0fd8","52aca8b93ef54669890a50f6a5d6f3b6","30059b896d17420d909b0cd4293792f6","be3e33c912404e6796a22006c3f831c9","bd636612b7c04ae389767fc37e2aa112","b006b0867c5b4cec9db420d3ff8b87c0","b34ab1d6399c481dbb887d01daf287b5","5367f8cbbbbc42cdbed06d664f5a2743","0596886531ea4f9e930cb390eba4e5a7","e22a2b4eb1154defa72bb09601f26068","689b0512bf974476befa139653d97d5b","9a1f4277409246ae9ef7f3d6455ac1c7","bfd0cc7e44c749ab989e6c567b67c6d1","cf4b94ebc83e41c883884e35df0e0ac6","37d14731a7e4472d847fa83268e023e9","9c983090923f4bd7882122d3f1589384","2f38343fdafc46c4b9d575693839a526"]},"executionInfo":{"elapsed":1932420,"status":"ok","timestamp":1676729131407,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"THNDibdjb9we","outputId":"30254ef6-7101-437c-e4b7-d9d2ca3ffdaf"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:__main__:device: cuda, n_gpu: 1, distributed training False\n","Some weights of the model checkpoint at /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli were not used when initializing BertForMultipleChoice_SAN: ['classifier.bias', 'classifier.weight']\n","- This IS expected if you are initializing BertForMultipleChoice_SAN from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMultipleChoice_SAN from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForMultipleChoice_SAN were not initialized from the model checkpoint at /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli and are newly initialized: ['out_proj.0.rnn.weight_ih', 'out_proj.0.query_wsum.att.linear.weight', 'out_proj.0.rnn.bias_ih', 'out_proj.0.alpha', 'out_proj.0.classifier.proj.bias', 'out_proj.0.rnn.bias_hh', 'out_proj.0.attn.score_func.linear.weight', 'out_proj.0.classifier.proj.weight', 'out_proj.0.rnn.weight_hh', 'out_proj.0.query_wsum.att.linear.bias', 'out_proj.0.attn.score_func.linear.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:__main__:Training/evaluation parameters Namespace(cache_dir='/content/drive/MyDrive/NCKH/ViMMRC_model/models/cached', config_name='', data_dir='/content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_test=False, do_train=True, eval_all_checkpoints=True, evaluate_during_training=True, f='/root/.local/share/jupyter/runtime/kernel-929c737f-7388-4c32-babe-4ee6ce6e1833.json', freeze_embeddings=False, freeze_layers=None, gradient_accumulation_steps=4, learning_rate=3e-05, local_rank=-1, max_grad_norm=1.0, max_seq_length=512, max_steps=-1, model_name_or_path='/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli', model_type='bert-man', n_gpu=1, no_cuda=False, num_train_epochs=10, output_dir='/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1', output_predictions=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=8, seed=42, task_name='vimmrc_race', tb_log_dir='', tokenizer_name='', warmup_proportion=0.1, weight_decay=0.01)\n","INFO:__main__:Creating features from dataset file at /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1\n","INFO:__main__:LOOKING AT /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1 train\n","INFO:__main__:Training number: 7900\n"]},{"output_type":"display_data","data":{"text/plain":["Convert examples to features:   0%|          | 0/7900 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b601f9616f24a7aa0c72996ebb04971"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:*** Example ***\n","INFO:__main__:guid: train-drive/MyDrive/CODE/ViMMRC/RAW/raw_data_ver1/train/grade_5_74_train.json-0\n","INFO:__main__:tokens: [CLS] C ##ụ Ú ##n làm nghề th ##ầy c ##ún ##g đã lâu năm . K ##h ##ắp làng xa bản gần , nhà nào có người ố ##m cũng nhờ cụ đến c ##ún ##g để đuổi t ##à ma . Nhiều người tôn cụ làm th ##ầy , c ##ắp sách theo cụ học nghề c ##ún ##g bá ##i . V ##ậ ##y mà gần một năm nay , chẳng hiểu cái ma nào làm cụ Ú ##n ố ##m . B ##ụng cụ đau qu ##ặ ##n , l ##ắm lúc tưởng như có con dao cứ ##a mạnh vào từng khúc ru ##ột . các học trò của cụ đã nhiều lần c ##ún ##g cho th ##ầy mà bệnh tình không thu ##yên giảm . Th ##ấy cha ngày càng đau nặng , con trai cụ k ##h ##ân khoản xin đưa cụ đi bệnh viện . Anh nói mã ##i , n ##ể lời , cụ mới đi . B ##ác sĩ bảo cụ bị s ##ỏ ##i th ##ận , phải m ##ổ lấy s ##ỏ ##i ra . C ##ụ sợ m ##ổ . H ##ơn nữa , cụ không tin bác sĩ người Kinh bắt được con ma người Thái . Thế là cụ tr ##ốn về nhà , Nhưng về đến nhà , cụ lại lên cơ ##n đau qu ##ằn qu ##ại . C ##ụ bắt con mời th ##ầy Vu ##i , học trò gi ##ỏ ##i nhất của cụ , đến c ##ún ##g trừ ma . C ##ún ##g suốt ngày đêm , bệnh vẫn không lui . Sá ##ng hôm sau , b ##ỗ ##ng có hai người mặc áo trắng tất tả phi ngựa đến . Hóa ra họ là bác sĩ và y tá bệnh viện đi tìm cụ Ú ##n . B ##ác sĩ ti ##êm thuốc giảm đau , cụ Ú ##n thấy đỡ . Ng ##ồi bên gi ##ường người bệnh , ông bác sĩ ô ##n tồn giải thích . Gia đình lại đưa cụ lên bệnh viện . N ##ử ##a tháng sau , cụ Ú ##n khỏi bệnh . Về nhà , cụ nói với bà con : - Từ nay , tôi d ##ứt k ##ho ##át bỏ nghề th ##ầy c ##ún ##g . Bà con ố ##m đau nên đi bệnh viện . [SEP] C ##ụ Ú ##n làm nghề gì ? [SEP] Th ##ầy c ##ún ##g trừ ma chữa bệnh . [SEP]\n","INFO:__main__:input_ids: 2 133 521 3531 23 67 1365 54 942 86 1049 50 18 719 74 6 285 21 560 1331 632 320 385 5 85 139 9 26 1989 33 38 981 741 69 86 1049 50 36 1672 152 333 812 6 1277 26 1264 741 67 54 942 5 86 560 748 196 741 191 1365 86 1049 50 1251 20 6 166 918 49 56 385 25 74 182 5 732 557 193 812 139 67 741 3531 23 1989 33 6 68 1775 741 1026 775 1528 23 5 34 388 386 797 46 9 95 1773 459 89 419 61 483 1452 1496 973 6 28 191 835 12 741 18 72 247 86 1049 50 13 54 942 56 504 223 14 225 1178 216 6 163 250 699 91 726 1026 870 5 95 720 741 37 21 403 917 337 407 741 84 504 829 6 299 144 296 20 5 15 1165 485 5 741 111 84 6 68 1108 442 311 741 77 102 361 20 54 519 5 66 40 777 377 102 361 20 44 6 133 521 906 40 777 6 151 770 291 5 741 14 218 669 442 26 1691 441 16 95 812 26 764 6 1067 10 741 145 1133 63 85 5 566 63 69 85 5 741 53 162 183 23 1026 775 2222 775 665 6 133 521 441 95 1515 54 942 2020 20 5 191 835 206 361 20 117 12 741 5 69 86 1049 50 1473 812 6 133 1049 50 1258 91 1052 5 504 172 14 2696 6 1727 65 592 97 5 51 667 65 9 197 26 710 664 948 682 1429 1018 2074 69 6 1965 44 198 10 669 442 11 634 1267 504 829 84 414 741 3531 23 6 68 1108 442 569 750 1094 216 1026 5 741 3531 23 159 1457 6 445 607 272 206 995 26 504 5 118 669 442 860 23 1661 215 411 6 1064 417 53 407 741 162 504 829 6 246 807 89 266 97 5 741 3531 23 883 504 6 1541 85 5 741 144 24 501 95 156 187 1038 182 5 81 73 1079 37 453 1260 471 1365 54 942 86 1049 50 6 1203 95 1989 33 1026 114 84 504 829 6 3 133 521 3531 23 67 1365 143 444 3 163 942 86 1049 50 1473 812 1322 504 6 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:premis_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:hypoth_mask: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:label: A\n","INFO:__main__:*** Example ***\n","INFO:__main__:guid: train-drive/MyDrive/CODE/ViMMRC/RAW/raw_data_ver1/train/grade_5_74_train.json-1\n","INFO:__main__:tokens: [CLS] C ##ụ Ú ##n làm nghề th ##ầy c ##ún ##g đã lâu năm . K ##h ##ắp làng xa bản gần , nhà nào có người ố ##m cũng nhờ cụ đến c ##ún ##g để đuổi t ##à ma . Nhiều người tôn cụ làm th ##ầy , c ##ắp sách theo cụ học nghề c ##ún ##g bá ##i . V ##ậ ##y mà gần một năm nay , chẳng hiểu cái ma nào làm cụ Ú ##n ố ##m . B ##ụng cụ đau qu ##ặ ##n , l ##ắm lúc tưởng như có con dao cứ ##a mạnh vào từng khúc ru ##ột . các học trò của cụ đã nhiều lần c ##ún ##g cho th ##ầy mà bệnh tình không thu ##yên giảm . Th ##ấy cha ngày càng đau nặng , con trai cụ k ##h ##ân khoản xin đưa cụ đi bệnh viện . Anh nói mã ##i , n ##ể lời , cụ mới đi . B ##ác sĩ bảo cụ bị s ##ỏ ##i th ##ận , phải m ##ổ lấy s ##ỏ ##i ra . C ##ụ sợ m ##ổ . H ##ơn nữa , cụ không tin bác sĩ người Kinh bắt được con ma người Thái . Thế là cụ tr ##ốn về nhà , Nhưng về đến nhà , cụ lại lên cơ ##n đau qu ##ằn qu ##ại . C ##ụ bắt con mời th ##ầy Vu ##i , học trò gi ##ỏ ##i nhất của cụ , đến c ##ún ##g trừ ma . C ##ún ##g suốt ngày đêm , bệnh vẫn không lui . Sá ##ng hôm sau , b ##ỗ ##ng có hai người mặc áo trắng tất tả phi ngựa đến . Hóa ra họ là bác sĩ và y tá bệnh viện đi tìm cụ Ú ##n . B ##ác sĩ ti ##êm thuốc giảm đau , cụ Ú ##n thấy đỡ . Ng ##ồi bên gi ##ường người bệnh , ông bác sĩ ô ##n tồn giải thích . Gia đình lại đưa cụ lên bệnh viện . N ##ử ##a tháng sau , cụ Ú ##n khỏi bệnh . Về nhà , cụ nói với bà con : - Từ nay , tôi d ##ứt k ##ho ##át bỏ nghề th ##ầy c ##ún ##g . Bà con ố ##m đau nên đi bệnh viện . [SEP] C ##ụ Ú ##n làm nghề gì ? [SEP] Ông lang chữa bệnh bằng thuốc nam . [SEP]\n","INFO:__main__:input_ids: 2 133 521 3531 23 67 1365 54 942 86 1049 50 18 719 74 6 285 21 560 1331 632 320 385 5 85 139 9 26 1989 33 38 981 741 69 86 1049 50 36 1672 152 333 812 6 1277 26 1264 741 67 54 942 5 86 560 748 196 741 191 1365 86 1049 50 1251 20 6 166 918 49 56 385 25 74 182 5 732 557 193 812 139 67 741 3531 23 1989 33 6 68 1775 741 1026 775 1528 23 5 34 388 386 797 46 9 95 1773 459 89 419 61 483 1452 1496 973 6 28 191 835 12 741 18 72 247 86 1049 50 13 54 942 56 504 223 14 225 1178 216 6 163 250 699 91 726 1026 870 5 95 720 741 37 21 403 917 337 407 741 84 504 829 6 299 144 296 20 5 15 1165 485 5 741 111 84 6 68 1108 442 311 741 77 102 361 20 54 519 5 66 40 777 377 102 361 20 44 6 133 521 906 40 777 6 151 770 291 5 741 14 218 669 442 26 1691 441 16 95 812 26 764 6 1067 10 741 145 1133 63 85 5 566 63 69 85 5 741 53 162 183 23 1026 775 2222 775 665 6 133 521 441 95 1515 54 942 2020 20 5 191 835 206 361 20 117 12 741 5 69 86 1049 50 1473 812 6 133 1049 50 1258 91 1052 5 504 172 14 2696 6 1727 65 592 97 5 51 667 65 9 197 26 710 664 948 682 1429 1018 2074 69 6 1965 44 198 10 669 442 11 634 1267 504 829 84 414 741 3531 23 6 68 1108 442 569 750 1094 216 1026 5 741 3531 23 159 1457 6 445 607 272 206 995 26 504 5 118 669 442 860 23 1661 215 411 6 1064 417 53 407 741 162 504 829 6 246 807 89 266 97 5 741 3531 23 883 504 6 1541 85 5 741 144 24 501 95 156 187 1038 182 5 81 73 1079 37 453 1260 471 1365 54 942 86 1049 50 6 1203 95 1989 33 1026 114 84 504 829 6 3 133 521 3531 23 67 1365 143 444 3 621 2348 1322 504 269 1094 733 6 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:premis_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:hypoth_mask: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:label: A\n","INFO:__main__:*** Example ***\n","INFO:__main__:guid: train-drive/MyDrive/CODE/ViMMRC/RAW/raw_data_ver1/train/grade_5_74_train.json-2\n","INFO:__main__:tokens: [CLS] C ##ụ Ú ##n làm nghề th ##ầy c ##ún ##g đã lâu năm . K ##h ##ắp làng xa bản gần , nhà nào có người ố ##m cũng nhờ cụ đến c ##ún ##g để đuổi t ##à ma . Nhiều người tôn cụ làm th ##ầy , c ##ắp sách theo cụ học nghề c ##ún ##g bá ##i . V ##ậ ##y mà gần một năm nay , chẳng hiểu cái ma nào làm cụ Ú ##n ố ##m . B ##ụng cụ đau qu ##ặ ##n , l ##ắm lúc tưởng như có con dao cứ ##a mạnh vào từng khúc ru ##ột . các học trò của cụ đã nhiều lần c ##ún ##g cho th ##ầy mà bệnh tình không thu ##yên giảm . Th ##ấy cha ngày càng đau nặng , con trai cụ k ##h ##ân khoản xin đưa cụ đi bệnh viện . Anh nói mã ##i , n ##ể lời , cụ mới đi . B ##ác sĩ bảo cụ bị s ##ỏ ##i th ##ận , phải m ##ổ lấy s ##ỏ ##i ra . C ##ụ sợ m ##ổ . H ##ơn nữa , cụ không tin bác sĩ người Kinh bắt được con ma người Thái . Thế là cụ tr ##ốn về nhà , Nhưng về đến nhà , cụ lại lên cơ ##n đau qu ##ằn qu ##ại . C ##ụ bắt con mời th ##ầy Vu ##i , học trò gi ##ỏ ##i nhất của cụ , đến c ##ún ##g trừ ma . C ##ún ##g suốt ngày đêm , bệnh vẫn không lui . Sá ##ng hôm sau , b ##ỗ ##ng có hai người mặc áo trắng tất tả phi ngựa đến . Hóa ra họ là bác sĩ và y tá bệnh viện đi tìm cụ Ú ##n . B ##ác sĩ ti ##êm thuốc giảm đau , cụ Ú ##n thấy đỡ . Ng ##ồi bên gi ##ường người bệnh , ông bác sĩ ô ##n tồn giải thích . Gia đình lại đưa cụ lên bệnh viện . N ##ử ##a tháng sau , cụ Ú ##n khỏi bệnh . Về nhà , cụ nói với bà con : - Từ nay , tôi d ##ứt k ##ho ##át bỏ nghề th ##ầy c ##ún ##g . Bà con ố ##m đau nên đi bệnh viện . [SEP] C ##ụ Ú ##n làm nghề gì ? [SEP] B ##ác sĩ . [SEP]\n","INFO:__main__:input_ids: 2 133 521 3531 23 67 1365 54 942 86 1049 50 18 719 74 6 285 21 560 1331 632 320 385 5 85 139 9 26 1989 33 38 981 741 69 86 1049 50 36 1672 152 333 812 6 1277 26 1264 741 67 54 942 5 86 560 748 196 741 191 1365 86 1049 50 1251 20 6 166 918 49 56 385 25 74 182 5 732 557 193 812 139 67 741 3531 23 1989 33 6 68 1775 741 1026 775 1528 23 5 34 388 386 797 46 9 95 1773 459 89 419 61 483 1452 1496 973 6 28 191 835 12 741 18 72 247 86 1049 50 13 54 942 56 504 223 14 225 1178 216 6 163 250 699 91 726 1026 870 5 95 720 741 37 21 403 917 337 407 741 84 504 829 6 299 144 296 20 5 15 1165 485 5 741 111 84 6 68 1108 442 311 741 77 102 361 20 54 519 5 66 40 777 377 102 361 20 44 6 133 521 906 40 777 6 151 770 291 5 741 14 218 669 442 26 1691 441 16 95 812 26 764 6 1067 10 741 145 1133 63 85 5 566 63 69 85 5 741 53 162 183 23 1026 775 2222 775 665 6 133 521 441 95 1515 54 942 2020 20 5 191 835 206 361 20 117 12 741 5 69 86 1049 50 1473 812 6 133 1049 50 1258 91 1052 5 504 172 14 2696 6 1727 65 592 97 5 51 667 65 9 197 26 710 664 948 682 1429 1018 2074 69 6 1965 44 198 10 669 442 11 634 1267 504 829 84 414 741 3531 23 6 68 1108 442 569 750 1094 216 1026 5 741 3531 23 159 1457 6 445 607 272 206 995 26 504 5 118 669 442 860 23 1661 215 411 6 1064 417 53 407 741 162 504 829 6 246 807 89 266 97 5 741 3531 23 883 504 6 1541 85 5 741 144 24 501 95 156 187 1038 182 5 81 73 1079 37 453 1260 471 1365 54 942 86 1049 50 6 1203 95 1989 33 1026 114 84 504 829 6 3 133 521 3531 23 67 1365 143 444 3 68 1108 442 6 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:premis_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:hypoth_mask: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:label: A\n","INFO:__main__:*** Example ***\n","INFO:__main__:guid: train-drive/MyDrive/CODE/ViMMRC/RAW/raw_data_ver1/train/grade_5_74_train.json-3\n","INFO:__main__:tokens: [CLS] C ##ụ Ú ##n làm nghề th ##ầy c ##ún ##g đã lâu năm . K ##h ##ắp làng xa bản gần , nhà nào có người ố ##m cũng nhờ cụ đến c ##ún ##g để đuổi t ##à ma . Nhiều người tôn cụ làm th ##ầy , c ##ắp sách theo cụ học nghề c ##ún ##g bá ##i . V ##ậ ##y mà gần một năm nay , chẳng hiểu cái ma nào làm cụ Ú ##n ố ##m . B ##ụng cụ đau qu ##ặ ##n , l ##ắm lúc tưởng như có con dao cứ ##a mạnh vào từng khúc ru ##ột . các học trò của cụ đã nhiều lần c ##ún ##g cho th ##ầy mà bệnh tình không thu ##yên giảm . Th ##ấy cha ngày càng đau nặng , con trai cụ k ##h ##ân khoản xin đưa cụ đi bệnh viện . Anh nói mã ##i , n ##ể lời , cụ mới đi . B ##ác sĩ bảo cụ bị s ##ỏ ##i th ##ận , phải m ##ổ lấy s ##ỏ ##i ra . C ##ụ sợ m ##ổ . H ##ơn nữa , cụ không tin bác sĩ người Kinh bắt được con ma người Thái . Thế là cụ tr ##ốn về nhà , Nhưng về đến nhà , cụ lại lên cơ ##n đau qu ##ằn qu ##ại . C ##ụ bắt con mời th ##ầy Vu ##i , học trò gi ##ỏ ##i nhất của cụ , đến c ##ún ##g trừ ma . C ##ún ##g suốt ngày đêm , bệnh vẫn không lui . Sá ##ng hôm sau , b ##ỗ ##ng có hai người mặc áo trắng tất tả phi ngựa đến . Hóa ra họ là bác sĩ và y tá bệnh viện đi tìm cụ Ú ##n . B ##ác sĩ ti ##êm thuốc giảm đau , cụ Ú ##n thấy đỡ . Ng ##ồi bên gi ##ường người bệnh , ông bác sĩ ô ##n tồn giải thích . Gia đình lại đưa cụ lên bệnh viện . N ##ử ##a tháng sau , cụ Ú ##n khỏi bệnh . Về nhà , cụ nói với bà con : - Từ nay , tôi d ##ứt k ##ho ##át bỏ nghề th ##ầy c ##ún ##g . Bà con ố ##m đau nên đi bệnh viện . [SEP] C ##ụ Ú ##n làm nghề gì ? [SEP] N ##ông dân . [SEP]\n","INFO:__main__:input_ids: 2 133 521 3531 23 67 1365 54 942 86 1049 50 18 719 74 6 285 21 560 1331 632 320 385 5 85 139 9 26 1989 33 38 981 741 69 86 1049 50 36 1672 152 333 812 6 1277 26 1264 741 67 54 942 5 86 560 748 196 741 191 1365 86 1049 50 1251 20 6 166 918 49 56 385 25 74 182 5 732 557 193 812 139 67 741 3531 23 1989 33 6 68 1775 741 1026 775 1528 23 5 34 388 386 797 46 9 95 1773 459 89 419 61 483 1452 1496 973 6 28 191 835 12 741 18 72 247 86 1049 50 13 54 942 56 504 223 14 225 1178 216 6 163 250 699 91 726 1026 870 5 95 720 741 37 21 403 917 337 407 741 84 504 829 6 299 144 296 20 5 15 1165 485 5 741 111 84 6 68 1108 442 311 741 77 102 361 20 54 519 5 66 40 777 377 102 361 20 44 6 133 521 906 40 777 6 151 770 291 5 741 14 218 669 442 26 1691 441 16 95 812 26 764 6 1067 10 741 145 1133 63 85 5 566 63 69 85 5 741 53 162 183 23 1026 775 2222 775 665 6 133 521 441 95 1515 54 942 2020 20 5 191 835 206 361 20 117 12 741 5 69 86 1049 50 1473 812 6 133 1049 50 1258 91 1052 5 504 172 14 2696 6 1727 65 592 97 5 51 667 65 9 197 26 710 664 948 682 1429 1018 2074 69 6 1965 44 198 10 669 442 11 634 1267 504 829 84 414 741 3531 23 6 68 1108 442 569 750 1094 216 1026 5 741 3531 23 159 1457 6 445 607 272 206 995 26 504 5 118 669 442 860 23 1661 215 411 6 1064 417 53 407 741 162 504 829 6 246 807 89 266 97 5 741 3531 23 883 504 6 1541 85 5 741 144 24 501 95 156 187 1038 182 5 81 73 1079 37 453 1260 471 1365 54 942 86 1049 50 6 1203 95 1989 33 1026 114 84 504 829 6 3 133 521 3531 23 67 1365 143 444 3 246 701 317 6 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:premis_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:hypoth_mask: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:__main__:label: A\n","INFO:__main__:Saving features into cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_train_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running training *****\n","INFO:__main__:  Num examples = 1975\n","INFO:__main__:  Num Epochs = 10\n","INFO:__main__:  Instantaneous batch size per GPU = 8\n","INFO:__main__: Total train batch size (w. parallel, distributed & accumulation) = 32\n","INFO:__main__:  Gradient Accumulation steps = 4\n","INFO:__main__:  Total optimization steps = 610\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33923d6619e94c1cb50e66fb5e33b0e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/247 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ebac90c871c4185bc32b1e3838c67d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/247 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58d6d2103cb4447b8793050fd3a48ad0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/247 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9800f6586ffc494ba7fff773c1e0505d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/247 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e66832b5663d4c0e9b9ed6a594449597"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/247 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1dbc8440dd34915857687d04636a11c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/247 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e57ca7fe56b4b68aad9b10a4056fb34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/247 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ffce7554eca4486a9337167f3df89c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/247 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba078e942c0940a49616f2c0d3b974f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/247 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"450cf948ddd042c28fa2ba09163f4b17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/247 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"425b9b76d217450e91d071f9dc0c75dd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__: global_step = 610, average loss = 0.42900587769675025\n","INFO:__main__:Saving model checkpoint to /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1\n","INFO:__main__:Evaluate the following checkpoints: ['/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_1', '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_10', '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_2', '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_3', '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_4', '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_5', '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_6', '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_7', '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_8', '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_9', '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1']\n","INFO:__main__:Creating features from dataset file at /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1\n","INFO:__main__:LOOKING AT /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1 dev\n","INFO:__main__:Training number: 1176\n"]},{"output_type":"display_data","data":{"text/plain":["Convert examples to features:   0%|          | 0/1176 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c80eed0966d4794989b50391a61b52d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:Saving features into cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for epoch_1 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8baa15ba0cf545fab6e43a82299c8706"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for epoch_1 *****\n","INFO:__main__:  eval_acc = 0.6802721088435374\n","INFO:__main__:  eval_loss = 0.8567044119778517\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for epoch_10 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dc2eb8c92e448e3becd29c2e29e16d2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for epoch_10 *****\n","INFO:__main__:  eval_acc = 0.7210884353741497\n","INFO:__main__:  eval_loss = 1.492544149299647\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for epoch_2 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01abf26250d64fe79ff2d9297c3a40e7"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for epoch_2 *****\n","INFO:__main__:  eval_acc = 0.6972789115646258\n","INFO:__main__:  eval_loss = 0.852726170944201\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for epoch_3 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d07d39d4c8d449b0969ffd16149eb3fe"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for epoch_3 *****\n","INFO:__main__:  eval_acc = 0.6870748299319728\n","INFO:__main__:  eval_loss = 0.9264121541652728\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for epoch_4 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34a3702cd6d34932a7a0ab9daf62bdf2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for epoch_4 *****\n","INFO:__main__:  eval_acc = 0.7074829931972789\n","INFO:__main__:  eval_loss = 0.9814978616148535\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for epoch_5 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"896bed3df9214b46b4795f386ff92d05"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for epoch_5 *****\n","INFO:__main__:  eval_acc = 0.7414965986394558\n","INFO:__main__:  eval_loss = 0.9948404621572007\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for epoch_6 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb6466d993464f6bba820a6de5cd66e8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for epoch_6 *****\n","INFO:__main__:  eval_acc = 0.7380952380952381\n","INFO:__main__:  eval_loss = 1.0733642820504847\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for epoch_7 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf92019fdb2841b190c60e9dbe4650ff"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for epoch_7 *****\n","INFO:__main__:  eval_acc = 0.7448979591836735\n","INFO:__main__:  eval_loss = 1.1087983090971671\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for epoch_8 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5f53751180042d1b5ac47459ef4d4a5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for epoch_8 *****\n","INFO:__main__:  eval_acc = 0.7108843537414966\n","INFO:__main__:  eval_loss = 1.3146601494173975\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for epoch_9 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b06e56d91441f6be1b6b1fd5a0699d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for epoch_9 *****\n","INFO:__main__:  eval_acc = 0.7210884353741497\n","INFO:__main__:  eval_loss = 1.435716446865479\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_dev_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on dev for vibert_nli_man_v1 *****\n","INFO:__main__:  Num examples = 294\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/74 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b34ab1d6399c481dbb887d01daf287b5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on dev for vibert_nli_man_v1 *****\n","INFO:__main__:  eval_acc = 0.7210884353741497\n","INFO:__main__:  eval_loss = 1.492544149299647\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/predictions_false_eval_results_label.json\n"]}],"source":["if __name__ == \"__main__\":\n","    main(args)"]},{"cell_type":"markdown","metadata":{"id":"Ix8RCrSpZSoL"},"source":["## Test"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1676729472405,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"z4Vc0QbZ1XY7","outputId":"87ee0f2c-261c-49cf-9072-07baaa28c6a0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'data_dir': '/content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1',\n"," 'model_type': 'bert-man',\n"," 'model_name_or_path': '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli',\n"," 'task_name': 'vimmrc_race',\n"," 'output_predictions': True,\n"," 'output_dir': '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_1',\n"," 'freeze_embeddings': False,\n"," 'freeze_layers': None,\n"," 'tb_log_dir': '',\n"," 'config_name': '',\n"," 'tokenizer_name': '',\n"," 'cache_dir': '/content/drive/MyDrive/NCKH/ViMMRC_model/models/cached',\n"," 'max_seq_length': 512,\n"," 'do_train': False,\n"," 'do_eval': False,\n"," 'do_test': True,\n"," 'evaluate_during_training': True,\n"," 'do_lower_case': False,\n"," 'per_gpu_train_batch_size': 8,\n"," 'per_gpu_eval_batch_size': 4,\n"," 'gradient_accumulation_steps': 4,\n"," 'learning_rate': 3e-05,\n"," 'weight_decay': 0.01,\n"," 'max_grad_norm': 1.0,\n"," 'num_train_epochs': 10,\n"," 'max_steps': -1,\n"," 'warmup_proportion': 0.1,\n"," 'eval_all_checkpoints': True,\n"," 'no_cuda': False,\n"," 'seed': 42,\n"," 'local_rank': -1,\n"," 'f': '/root/.local/share/jupyter/runtime/kernel-929c737f-7388-4c32-babe-4ee6ce6e1833.json'}"]},"metadata":{},"execution_count":34}],"source":["parser = argparse.ArgumentParser()\n","\n","if True:\n","    # Required parameters\n","    parser.add_argument(\n","        \"--data_dir\", default=\"{}/dataset/ViMMRC_RACE_v1\".format(PRJ_DIR), type=str,\n","        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n","    )\n","\n","    parser.add_argument(\n","        \"--model_type\", default=\"bert-man\", type=str,\n","        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n","    )\n","    parser.add_argument(\n","        \"--model_name_or_path\", default=\"{}/models/vibert_nli\".format(PRJ_DIR), type=str,\n","        help=\"Path to pre-trained model or shortcut name selected in the list: \" + \", \".join(ALL_MODELS),\n","    )\n","    \n","    parser.add_argument(\n","        \"--task_name\", default=\"vimmrc_race\", type=str,\n","        help=\"The name of the task to train selected in the list: \" + \", \".join(processors.keys()),\n","    )\n","    # parser.add_argument(\n","    #     \"--para_type\", default=\"per_choice\", type=str,\n","    #     choices=[\"per_choice\", \"concat_choices\", \"ignore\"],\n","    #     help=\"Paragraph building strategy for ARC (default: %(default)s)\",\n","    # )\n","    parser.add_argument(\n","        \"--output_predictions\", default=True, type=bool, help=\"Whether to export the predictions from the eval step.\",\n","    )\n","    parser.add_argument(\n","        \"--output_dir\", default=OUTPUT_DIR+'/epoch_1', type=str, help=\"The output directory where the model predictions and checkpoints will be written.\",\n","    )\n","    parser.add_argument(\"--freeze_embeddings\", default=False, action=\"store_true\", help=\"Whether to freeze the embeeding layer.\",)\n","    parser.add_argument(\"--freeze_layers\", nargs=\"*\", help=\"Whether to freeze the embeeding layer.\",)\n","\n","    # Other parameters\n","    parser.add_argument(\"--tb_log_dir\", default=\"\", type=str, help=\"Tensorboard log dir for the current experiment\")\n","    parser.add_argument(\"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\")\n","    parser.add_argument(\"--tokenizer_name\", default=\"\", type=str, help=\"Pretrained tokenizer name or path if not the same as model_name\")\n","    parser.add_argument(\n","        \"--cache_dir\", default=\"{}/models/cached\".format(PRJ_DIR), type=str, help=\"Where do you want to store the pre-trained models downloaded from s3\",\n","    )\n","    parser.add_argument(\n","        \"--max_seq_length\", default=MAX_SEQ_LENGTHS['vimmrc'], type=int,\n","        help=\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\",\n","    )\n","    parser.add_argument(\"--do_train\", default = False, action=\"store_true\", help=\"Whether to run training.\")\n","    parser.add_argument(\"--do_eval\", default = False, action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n","    parser.add_argument(\"--do_test\", default = True, action=\"store_true\", help=\"Whether to run test on the test set\")\n","    parser.add_argument(\n","        \"--evaluate_during_training\", action=\"store_true\", default = True, help=\"Run evaluation during training at each logging step.\",\n","    )\n","    parser.add_argument(\n","        \"--do_lower_case\", action=\"store_true\", default = False, help=\"Set this flag if you are using an uncased model.\",\n","    )\n","\n","    parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\",)\n","    parser.add_argument(\"--per_gpu_eval_batch_size\", default=4, type=int, help=\"Batch size per GPU/CPU for evaluation.\",)\n","    parser.add_argument(\n","        \"--gradient_accumulation_steps\", type=int, default=4, help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n","    )\n","    parser.add_argument(\"--learning_rate\", default=3e-5, type=float, help=\"The initial learning rate for Adam.\")\n","    parser.add_argument(\"--weight_decay\", default=0.01, type=float, help=\"Weight decay if we apply some.\")\n","    # parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n","    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n","    parser.add_argument(\"--num_train_epochs\", default=10, type=float, help=\"Total number of training epochs to perform.\")\n","    parser.add_argument(\"--max_steps\", default=-1, type=int, help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n","    parser.add_argument(\"--warmup_proportion\", default=0.1, type=float, help=\"Linear warmup over warmup_proportion.\")\n","\n","    # parser.add_argument(\"--logging_steps\", type=int, default=100, help=\"Log every X updates steps.\")\n","    # parser.add_argument(\"--save_steps\", type=int, default=500, help=\"Save checkpoint every X updates steps.\")\n","    parser.add_argument(\n","        \"--eval_all_checkpoints\", default=True, action=\"store_true\",\n","        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n","    )\n","    parser.add_argument(\"--no_cuda\", default=False, action=\"store_true\", help=\"Avoid using CUDA when available\")\n","    # parser.add_argument(\n","    #     \"--overwrite_output_dir\", default = True, action=\"store_true\", help=\"Overwrite the content of the output directory\",\n","    # )\n","    # parser.add_argument(\n","    #     \"--overwrite_cache\", default = True, action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\",\n","    # )\n","    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n","\n","    # parser.add_argument(\n","    #     \"--fp16\", action=\"store_true\", help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n","    # )\n","    # parser.add_argument(\n","    #     \"--fp16_opt_level\", type=str, default=\"O1\",\n","    #     help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n","    #     \"See details at https://nvidia.github.io/apex/amp.html\",\n","    # )\n","    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n","    # parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n","    # parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n","\n","    parser.add_argument('-f')\n","\n","args = parser.parse_args()\n","vars(args)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399,"referenced_widgets":["670efc5c8b3b494db3e157e545cfa700","8075783e2cb541c49090de03a5d65b20","7b2a187931e546eab9fca7b824ba4640","cc64e78c62a84374bfe1648d5d0e620f","b796409c6c204693b1004d9f365f6561","3e6f830de4284e69a8f636eecada8f6f","2ffed6afbb214283809799c730b303ed","57db4da18e1e42edbf7fdc324b225998","c82ddf29cd4c47c1965ba9569a6e34e6","1fd9b7e09f174041a8031d8454f39297","ef0ef7576d0b42e094dda77fb40f2e60"]},"executionInfo":{"elapsed":22113,"status":"ok","timestamp":1676729497244,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"Q_0j2qEMx2Ry","outputId":"6ff1c7ab-7f69-4e6e-b04b-3d8a28e79afe"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:__main__:device: cuda, n_gpu: 1, distributed training False\n","Some weights of the model checkpoint at /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli were not used when initializing BertForMultipleChoice_SAN: ['classifier.bias', 'classifier.weight']\n","- This IS expected if you are initializing BertForMultipleChoice_SAN from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMultipleChoice_SAN from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForMultipleChoice_SAN were not initialized from the model checkpoint at /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli and are newly initialized: ['out_proj.0.rnn.weight_ih', 'out_proj.0.query_wsum.att.linear.weight', 'out_proj.0.rnn.bias_ih', 'out_proj.0.alpha', 'out_proj.0.classifier.proj.bias', 'out_proj.0.rnn.bias_hh', 'out_proj.0.attn.score_func.linear.weight', 'out_proj.0.classifier.proj.weight', 'out_proj.0.rnn.weight_hh', 'out_proj.0.query_wsum.att.linear.bias', 'out_proj.0.attn.score_func.linear.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:__main__:Training/evaluation parameters Namespace(cache_dir='/content/drive/MyDrive/NCKH/ViMMRC_model/models/cached', config_name='', data_dir='/content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1', device=device(type='cuda'), do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_all_checkpoints=True, evaluate_during_training=True, f='/root/.local/share/jupyter/runtime/kernel-929c737f-7388-4c32-babe-4ee6ce6e1833.json', freeze_embeddings=False, freeze_layers=None, gradient_accumulation_steps=4, learning_rate=3e-05, local_rank=-1, max_grad_norm=1.0, max_seq_length=512, max_steps=-1, model_name_or_path='/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli', model_type='bert-man', n_gpu=1, no_cuda=False, num_train_epochs=10, output_dir='/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_1', output_predictions=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=8, seed=42, task_name='vimmrc_race', tb_log_dir='', tokenizer_name='', warmup_proportion=0.1, weight_decay=0.01)\n","INFO:__main__:Evaluate the following checkpoints: ['/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_1']\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC_RACE_v1/cached_test_vibert_nli_512_vimmrc_race\n","INFO:__main__:***** Running evaluation for vimmrc_race on test for epoch_1 *****\n","INFO:__main__:  Num examples = 514\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/129 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"670efc5c8b3b494db3e157e545cfa700"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc_race on test for epoch_1 *****\n","INFO:__main__:  eval_acc = 0.6050583657587548\n","INFO:__main__:  eval_loss = 1.0088030995959922\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_1/predictions_true_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_nli_man_v1/epoch_1/predictions_true_eval_results_label.json\n"]}],"source":["if __name__ == \"__main__\":\n","    main(args)"]},{"cell_type":"markdown","metadata":{"id":"fNt9JzIuemic"},"source":["## Debug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nTjtjEV5dWst","colab":{"base_uri":"https://localhost:8080/","height":498,"referenced_widgets":["211eaddf31ab4edb83516d06f6edb56d","f249276962be40e5955be496237a5656","2d3c8bae69fe49f38503e7086c5c26a1","52c4fe24e4a34c959302b79d3f019ba5","28116101f54a4b6387a9db208f227607","91457cd790844eb086717221daa79882","063b83abb83d41ab999039a8fbd7df1f","2cea38d2dd71493892d702e405643b93","5c233cae1e2243c6a11c98aa0708aaee","4f1cbe53272c44cda8b84907548521de","280aa964f17b4326b00b74a7435d50a6","3d129203d94445c4b375fe61a4afb00d","eb5e6d50b59a40ceb2ce3a1ab9895dad","f111af1c463c4f32814923c8b38f3d4d","b0e1cea4999848b389aad5aacfbd7502","8317b8dd4a9d4d338f00c57e6010d47a","f56bf80cb6dc48f18b089f90c11e4231","e1ec998cd98f4a59a320658195e2dfbc","84880378438e4c81bd187156eca63a76","3847b809fdea448cbbae90235d9a7d2e","a89214bd7aaa4c45b4be3f27f8d24019","3a87250bc7a54965bd0d67a6da3a8b26"]},"executionInfo":{"status":"ok","timestamp":1676052915255,"user_tz":-420,"elapsed":245364,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}},"outputId":"4ac91cca-73e4-4b6c-8d86-1387d821893f"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:__main__:device: cuda, n_gpu: 1, distributed training False\n","INFO:__main__:Evaluate the following checkpoints: ['/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man']\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC/cached_test_vibert-base-cased_512_vimmrc\n","INFO:__main__:***** Running evaluation for vimmrc on test for vibert_man *****\n","INFO:__main__:  Num examples = 1109\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/278 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211eaddf31ab4edb83516d06f6edb56d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc on test for vibert_man *****\n","INFO:__main__:  eval_acc = 0.5545536519386834\n","INFO:__main__:  eval_loss = 2.56232390433669\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/predictions_true_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/predictions_true_eval_results_label.json\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC/cached_dev_vibert-base-cased_512_vimmrc\n","INFO:__main__:***** Running evaluation for vimmrc on dev for vibert_man *****\n","INFO:__main__:  Num examples = 564\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/141 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d129203d94445c4b375fe61a4afb00d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc on dev for vibert_man *****\n","INFO:__main__:  eval_acc = 0.5425531914893617\n","INFO:__main__:  eval_loss = 2.508770821923308\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/predictions_false_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/predictions_false_eval_results_label.json\n"]}],"source":["#%debug\n","# Setup CUDA, GPU & distributed training\n","if args.local_rank == -1 or args.no_cuda:\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n","    args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n","else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n","    torch.cuda.set_device(args.local_rank)\n","    device = torch.device(\"cuda\", args.local_rank)\n","    torch.distributed.init_process_group(backend=\"nccl\")\n","    args.n_gpu = 1\n","logger.info(\"device: %s, n_gpu: %d, distributed training %r\", device, args.n_gpu, bool(args.local_rank != -1))\n","args.device = device\n","\n","args.task_name = args.task_name.lower()\n","config_class, model_class, tokenizer_class = BertConfig, BertForMultipleChoice_SAN, BertTokenizer#MODEL_CLASSES[args.model_type]\n","\n","# Evaluation\n","results = {}\n","if args.do_test and args.local_rank in [-1, 0]:\n","    checkpoints = [args.output_dir]\n","    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","    for checkpoint in checkpoints:\n","        global_step = checkpoint.split(\"/\")[-1]\n","        model = model_class.from_pretrained(checkpoint, opt={\"use_SAN\": 1}, num_choices=[4])\n","        model.to(args.device)\n","        tokenizer = tokenizer_class.from_pretrained(checkpoint)\n","        result = evaluate(args, model, tokenizer, global_step, is_test=True)\n","        evaluate(args, model, tokenizer, global_step)\n","        # result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n","        # results.update(result)"]},{"cell_type":"markdown","source":["### Epoch 3 test"],"metadata":{"id":"onKfPBZqxlSG"}},{"cell_type":"code","source":["parser = argparse.ArgumentParser()\n","\n","if True:\n","    # Required parameters\n","    parser.add_argument(\n","        \"--data_dir\", default=\"/content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC\", type=str,\n","        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n","    )\n","\n","    parser.add_argument(\n","        \"--model_type\", default=\"bert-man\", type=str,\n","        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n","    )\n","    parser.add_argument(\n","        \"--model_name_or_path\", default=\"FPTAI/vibert-base-cased\", type=str,\n","        help=\"Path to pre-trained model or shortcut name selected in the list: \" + \", \".join(ALL_MODELS),\n","    )\n","    \n","    parser.add_argument(\n","        \"--task_name\", default=\"vimmrc\", type=str,\n","        help=\"The name of the task to train selected in the list: \" + \", \".join(processors.keys()),\n","    )\n","    # parser.add_argument(\n","    #     \"--para_type\", default=\"per_choice\", type=str,\n","    #     choices=[\"per_choice\", \"concat_choices\", \"ignore\"],\n","    #     help=\"Paragraph building strategy for ARC (default: %(default)s)\",\n","    # )\n","    parser.add_argument(\n","        \"--output_predictions\", default=True, type=bool, help=\"Whether to export the predictions from the eval step.\",\n","    )\n","    parser.add_argument(\n","        \"--output_dir\", default=OUTPUT_DIR+'/epoch_3', type=str, help=\"The output directory where the model predictions and checkpoints will be written.\",\n","    )\n","    parser.add_argument(\"--freeze_embeddings\", default=False, action=\"store_true\", help=\"Whether to freeze the embeeding layer.\",)\n","    parser.add_argument(\"--freeze_layers\", nargs=\"*\", help=\"Whether to freeze the embeeding layer.\",)\n","\n","    # Other parameters\n","    parser.add_argument(\"--tb_log_dir\", default=\"\", type=str, help=\"Tensorboard log dir for the current experiment\")\n","    parser.add_argument(\"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\")\n","    parser.add_argument(\"--tokenizer_name\", default=\"\", type=str, help=\"Pretrained tokenizer name or path if not the same as model_name\")\n","    parser.add_argument(\n","        \"--cache_dir\", default=\"{}/cached\".format(OUTPUT_DIR), type=str, help=\"Where do you want to store the pre-trained models downloaded from s3\",\n","    )\n","    parser.add_argument(\n","        \"--max_seq_length\", default=MAX_SEQ_LENGTHS['vimmrc'], type=int,\n","        help=\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\",\n","    )\n","    parser.add_argument(\"--do_train\", default = False, action=\"store_true\", help=\"Whether to run training.\")\n","    parser.add_argument(\"--do_eval\", default = False, action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n","    parser.add_argument(\"--do_test\", default = True, action=\"store_true\", help=\"Whether to run test on the test set\")\n","    parser.add_argument(\n","        \"--evaluate_during_training\", action=\"store_true\", default = True, help=\"Run evaluation during training at each logging step.\",\n","    )\n","    parser.add_argument(\n","        \"--do_lower_case\", action=\"store_true\", default = False, help=\"Set this flag if you are using an uncased model.\",\n","    )\n","\n","    parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\",)\n","    parser.add_argument(\"--per_gpu_eval_batch_size\", default=4, type=int, help=\"Batch size per GPU/CPU for evaluation.\",)\n","    parser.add_argument(\n","        \"--gradient_accumulation_steps\", type=int, default=4, help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n","    )\n","    parser.add_argument(\"--learning_rate\", default=3e-5, type=float, help=\"The initial learning rate for Adam.\")\n","    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n","    # parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n","    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n","    parser.add_argument(\"--num_train_epochs\", default=10, type=float, help=\"Total number of training epochs to perform.\")\n","    parser.add_argument(\"--max_steps\", default=-1, type=int, help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n","    parser.add_argument(\"--warmup_proportion\", default=0.1, type=float, help=\"Linear warmup over warmup_proportion.\")\n","\n","    # parser.add_argument(\"--logging_steps\", type=int, default=100, help=\"Log every X updates steps.\")\n","    # parser.add_argument(\"--save_steps\", type=int, default=500, help=\"Save checkpoint every X updates steps.\")\n","    parser.add_argument(\n","        \"--eval_all_checkpoints\", default=True, action=\"store_true\",\n","        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n","    )\n","    parser.add_argument(\"--no_cuda\", default=False, action=\"store_true\", help=\"Avoid using CUDA when available\")\n","    # parser.add_argument(\n","    #     \"--overwrite_output_dir\", default = True, action=\"store_true\", help=\"Overwrite the content of the output directory\",\n","    # )\n","    # parser.add_argument(\n","    #     \"--overwrite_cache\", default = True, action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\",\n","    # )\n","    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n","\n","    # parser.add_argument(\n","    #     \"--fp16\", action=\"store_true\", help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n","    # )\n","    # parser.add_argument(\n","    #     \"--fp16_opt_level\", type=str, default=\"O1\",\n","    #     help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n","    #     \"See details at https://nvidia.github.io/apex/amp.html\",\n","    # )\n","    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n","    # parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n","    # parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n","\n","    parser.add_argument('-f')\n","\n","args = parser.parse_args()\n","vars(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IWrzFYQ2xonc","executionInfo":{"status":"ok","timestamp":1676107346387,"user_tz":-420,"elapsed":584,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}},"outputId":"1cfd09eb-163b-4eef-f808-b2c8268f915e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'data_dir': '/content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC',\n"," 'model_type': 'bert-man',\n"," 'model_name_or_path': 'FPTAI/vibert-base-cased',\n"," 'task_name': 'vimmrc',\n"," 'output_predictions': True,\n"," 'output_dir': '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/epoch_3',\n"," 'freeze_embeddings': False,\n"," 'freeze_layers': None,\n"," 'tb_log_dir': '',\n"," 'config_name': '',\n"," 'tokenizer_name': '',\n"," 'cache_dir': '/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/cached',\n"," 'max_seq_length': 512,\n"," 'do_train': False,\n"," 'do_eval': False,\n"," 'do_test': True,\n"," 'evaluate_during_training': True,\n"," 'do_lower_case': False,\n"," 'per_gpu_train_batch_size': 8,\n"," 'per_gpu_eval_batch_size': 4,\n"," 'gradient_accumulation_steps': 4,\n"," 'learning_rate': 3e-05,\n"," 'weight_decay': 0.0,\n"," 'max_grad_norm': 1.0,\n"," 'num_train_epochs': 10,\n"," 'max_steps': -1,\n"," 'warmup_proportion': 0.1,\n"," 'eval_all_checkpoints': True,\n"," 'no_cuda': False,\n"," 'seed': 42,\n"," 'local_rank': -1,\n"," 'f': '/root/.local/share/jupyter/runtime/kernel-f1dbfc3e-639b-4ff3-9c86-b4b275338497.json'}"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["def main(args):\n","\n","    # Setup distant debugging if needed\n","    # if args.server_ip and args.server_port:\n","    #     # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n","    #     import ptvsd\n","\n","    #     print(\"Waiting for debugger attach\")\n","    #     ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n","    #     ptvsd.wait_for_attach()\n","\n","    # Setup CUDA, GPU & distributed training\n","    if args.local_rank == -1 or args.no_cuda:\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n","        args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n","    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n","        torch.cuda.set_device(args.local_rank)\n","        device = torch.device(\"cuda\", args.local_rank)\n","        torch.distributed.init_process_group(backend=\"nccl\")\n","        args.n_gpu = 1\n","    logger.info(\"device: %s, n_gpu: %d, distributed training %r\", device, args.n_gpu, bool(args.local_rank != -1))\n","    args.device = device\n","\n","    if args.gradient_accumulation_steps < 1:\n","        raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\n","            args.gradient_accumulation_steps))\n","\n","    if os.path.exists(args.output_dir) and os.listdir(args.output_dir):\n","        if args.do_train:\n","            print(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n","    else:\n","        os.makedirs(args.output_dir, exist_ok=True)\n","    \n","    # Set seed\n","    set_seed(args)\n","\n","    # Prepare GLUE task\n","    args.task_name = args.task_name.lower()\n","    if args.task_name not in processors:\n","        raise ValueError(\"Task not found: %s\" % (args.task_name))\n","    processor = processors[args.task_name]()\n","    label_list = processor.get_labels()\n","    num_labels = len(label_list)\n","\n","    # Load pretrained model and tokenizer\n","    if args.local_rank not in [-1, 0]:\n","        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n","\n","    args.model_type = args.model_type.lower()\n","    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n","    config = config_class.from_pretrained(\n","        args.config_name if args.config_name else args.model_name_or_path,\n","        num_labels=num_labels,\n","        early_stopping = True,\n","        finetuning_task=args.task_name,\n","        cache_dir=args.cache_dir if args.cache_dir else None,\n","    )\n","    tokenizer = tokenizer_class.from_pretrained(\n","        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n","        do_lower_case=args.do_lower_case,\n","        cache_dir=args.cache_dir if args.cache_dir else None,\n","    )\n","    model = model_class.from_pretrained(\n","        args.model_name_or_path,\n","        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n","        config=config,\n","        cache_dir=args.cache_dir if args.cache_dir else None,\n","        opt={\"use_SAN\": 1},\n","        num_choices=[4]\n","    )\n","\n","    if args.local_rank == 0:\n","        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n","\n","    options_print = \"\"\n","    logging.info(\"Arg Options:\")\n","    for arg in vars(args):\n","        options_print += \"opt: %s=%s\\r\\n\" % (arg, getattr(args, arg))\n","    logging.info(options_print)\n","\n","    model.to(args.device)\n","\n","    def get_model_base_obj(model, model_type):\n","        if model_type == \"bert\":\n","            return model.bert\n","        elif model_type == \"xlm-roberta\" or model_type == \"roberta\":\n","            return model.roberta\n","        elif model_type == \"distilbert\":\n","            return model.distilbert    \n","        else:\n","            raise ValueError(\"model_type='{0}' is not supported!\")\n","\n","    if args.freeze_embeddings:\n","        for param in list(get_model_base_obj(model, args.model_type).embeddings.parameters()):\n","            param.requires_grad = False\n","        logger.info(\"Froze Embedding Layer\")\n","\n","    # freeze_layers is a string \"1,2,3\" representing layer number\n","    if args.freeze_layers:\n","        layer_indexes = [int(x) for x in args.freeze_layers]\n","        for layer_idx in layer_indexes:\n","            for param in list(\n","                get_model_base_obj(model, args.model_type).encoder.layer[layer_idx].parameters()\n","            ):\n","                param.requires_grad = False\n","            logger.info(\"Froze Layer: %s\", layer_idx)\n","\n","    logger.info(\"Training/evaluation parameters %s\", args)\n","    best_steps = 0\n","\n","    # Training\n","    if args.do_train:\n","        train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, set_type='train')\n","        global_step, tr_loss, best_steps = train(args, train_dataset, model, tokenizer)\n","        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n","\n","    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n","        # Create output directory if needed\n","        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n","            os.makedirs(args.output_dir)\n","\n","        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n","        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","        # They can then be reloaded using `from_pretrained()`\n","        model_to_save = (\n","            model.module if hasattr(model, \"module\") else model\n","        )  # Take care of distributed/parallel training\n","        model_to_save.save_pretrained(args.output_dir)\n","        tokenizer.save_pretrained(args.output_dir)\n","\n","        # Good practice: save your training arguments together with the trained model\n","        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n","\n","        # Load a trained model and vocabulary that you have fine-tuned\n","        model = model_class.from_pretrained(args.output_dir, opt={\"use_SAN\": 1}, num_choices=[4])\n","        tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n","        model.to(args.device)\n","\n","    # Evaluation\n","    results = {}\n","    if args.do_eval and args.local_rank in [-1, 0]:\n","        if not args.do_train:\n","            args.output_dir = args.model_name_or_path\n","        checkpoints = [args.output_dir]\n","        if args.eval_all_checkpoints:\n","            checkpoints = list(\n","                os.path.dirname(c)\n","                for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n","            )\n","            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n","        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","        for checkpoint in checkpoints:\n","            global_step = checkpoint.split(\"/\")[-1] if len(checkpoints) > 1 else \"\"\n","            model = model_class.from_pretrained(checkpoint, opt={\"use_SAN\": 1}, num_choices=[4])\n","            model.to(args.device)\n","            result = evaluate(args, model, tokenizer, global_step)\n","            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n","            results.update(result)\n","\n","    if args.do_test and args.local_rank in [-1, 0]:\n","        checkpoints = [args.output_dir]\n","        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","        for checkpoint in checkpoints:\n","            global_step = checkpoint.split(\"/\")[-1]\n","            model = model_class.from_pretrained(checkpoint, opt={\"use_SAN\": 1}, num_choices=[4])\n","            model.to(args.device)\n","            result = evaluate(args, model, tokenizer, global_step, is_test=True)\n","            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n","            results.update(result)\n","    # if best_steps:\n","    #     logger.info(\"best steps of eval acc is the following checkpoints: %s\", best_steps)\n","    return results\n","\n","if __name__ == \"__main__\":\n","    main(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399,"referenced_widgets":["77acda4cf7514e7ca1b80d7093059d53","3f1ead2cfa7a417e968769adef4393c4","57e946ec137d4506ba34c33e2fe83886","ac4d86d6cdcd476d8d13fcc7af4f5fc3","82dbf31183ee4fb8a135eeda23077bb8","d68ce6b728994e97866ac5e5214d5515","012d06c3974d420485518ae35d564105","e6fde4af50764278b4ea8d5391e87ed1","1f0c7a56c72f480ba026ba5079318310","29f282f4681646279269f7bcc2fd90d7","a355b927a87d4a95a66aa99e6b1f7818"]},"id":"riR2kACzyKYH","executionInfo":{"status":"ok","timestamp":1676107407243,"user_tz":-420,"elapsed":40853,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"}},"outputId":"e81c06f0-f2cc-4fa6-d4f7-84310126eff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:__main__:device: cuda, n_gpu: 1, distributed training False\n","Some weights of the model checkpoint at FPTAI/vibert-base-cased were not used when initializing BertForMultipleChoice_SAN: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForMultipleChoice_SAN from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMultipleChoice_SAN from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForMultipleChoice_SAN were not initialized from the model checkpoint at FPTAI/vibert-base-cased and are newly initialized: ['out_proj.0.query_wsum.att.linear.weight', 'out_proj.0.classifier.proj.weight', 'out_proj.0.rnn.weight_hh', 'out_proj.0.classifier.proj.bias', 'out_proj.0.attn.score_func.linear.bias', 'out_proj.0.query_wsum.att.linear.bias', 'out_proj.0.alpha', 'out_proj.0.rnn.weight_ih', 'out_proj.0.attn.score_func.linear.weight', 'out_proj.0.rnn.bias_hh', 'out_proj.0.rnn.bias_ih']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:__main__:Training/evaluation parameters Namespace(cache_dir='/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/cached', config_name='', data_dir='/content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC', device=device(type='cuda'), do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_all_checkpoints=True, evaluate_during_training=True, f='/root/.local/share/jupyter/runtime/kernel-f1dbfc3e-639b-4ff3-9c86-b4b275338497.json', freeze_embeddings=False, freeze_layers=None, gradient_accumulation_steps=4, learning_rate=3e-05, local_rank=-1, max_grad_norm=1.0, max_seq_length=512, max_steps=-1, model_name_or_path='FPTAI/vibert-base-cased', model_type='bert-man', n_gpu=1, no_cuda=False, num_train_epochs=10, output_dir='/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/epoch_3', output_predictions=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=8, seed=42, task_name='vimmrc', tb_log_dir='', tokenizer_name='', warmup_proportion=0.1, weight_decay=0.0)\n","INFO:__main__:Evaluate the following checkpoints: ['/content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/epoch_3']\n","INFO:__main__:Loading features from cached file /content/drive/MyDrive/NCKH/ViMMRC_model/dataset/ViMMRC/cached_test_vibert-base-cased_512_vimmrc\n","INFO:__main__:***** Running evaluation for vimmrc on test for epoch_3 *****\n","INFO:__main__:  Num examples = 1109\n","INFO:__main__:  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/278 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77acda4cf7514e7ca1b80d7093059d53"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Eval results for vimmrc on test for epoch_3 *****\n","INFO:__main__:  eval_acc = 0.5716862037871957\n","INFO:__main__:  eval_loss = 1.1529127638050014\n","INFO:__main__:\n","\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/epoch_3/predictions_true_eval_results.json\n","INFO:__main__:Saved /content/drive/MyDrive/NCKH/ViMMRC_model/models/vibert_man/epoch_3/predictions_true_eval_results_label.json\n"]}]},{"cell_type":"markdown","metadata":{"id":"s81etsZKpXd-"},"source":["### tmp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["f62c08a72d1142fdab953c980fbbce4f","6bc521f800fc43b8bb54d18794abe787","a19e893d1d554573b11135419da009c0","e138b179be854426ac7bada21f0a1899","8e9a7e93962644e8b1212262c8418d24","3de9dabd8f69498daf9603445f464b64","2ec3743436a94c5b9970c907936c936a","ea55b0955c934145b9f0f08dbbe399fe","d3b7eca35933477aaa5a3fedff84a2e2","ad0cdef0307a4eeea3981bd9f541cc7a","03913b8267fd4b90914caec90b1ba430"]},"executionInfo":{"elapsed":74392,"status":"ok","timestamp":1675954862116,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"DPAJMHt2pGuF","outputId":"46dc2285-59e5-43e9-900f-fde2c5da1aa8"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f62c08a72d1142fdab953c980fbbce4f","version_major":2,"version_minor":0},"text/plain":["Writing example:   0%|          | 0/4436 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["task = 'vimmrc'\n","set_type = 'test'\n","processor = processors[task]()\n","label_list = processor.get_labels()\n","output_mode = output_modes[task]\n","is_multi_choice = True if output_mode == 'multi-choice' else False\n","\n","examples = processor.get_test_examples(args.data_dir)\n","features = convert_examples_to_features(\n","            examples,\n","            label_list,\n","            MAX_SEQ_LENGTHS[task],\n","            tokenizer,\n","            len(label_list),\n","            output_mode=output_mode,\n","            set_type=set_type,\n","            do_lower_case=args.do_lower_case,\n","            is_multi_choice=is_multi_choice\n","        )\n","all_example_ids = [x.guid for feature_set in features for x in feature_set]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1675954862116,"user":{"displayName":"Khôi Hoàng","userId":"04631266824167781561"},"user_tz":-420},"id":"0tyYwkcFrzuX","outputId":"813b087d-9718-4bf1-f290-4d8ec0fb46a1"},"outputs":[{"data":{"text/plain":["4436"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["len(all_example_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jvcyCzOmr5OK"},"outputs":[],"source":["all_example_ids"]}],"metadata":{"colab":{"collapsed_sections":["K_Pv9CIYm7BZ","ioQPuCNdks1x","uWwt6WujlC1Q","yoiGjVs5kuwD","fNt9JzIuemic","onKfPBZqxlSG","s81etsZKpXd-"],"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.0"},"vscode":{"interpreter":{"hash":"5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"03913b8267fd4b90914caec90b1ba430":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ec3743436a94c5b9970c907936c936a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3de9dabd8f69498daf9603445f464b64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bc521f800fc43b8bb54d18794abe787":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3de9dabd8f69498daf9603445f464b64","placeholder":"​","style":"IPY_MODEL_2ec3743436a94c5b9970c907936c936a","value":"Writing example: 100%"}},"8e9a7e93962644e8b1212262c8418d24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a19e893d1d554573b11135419da009c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea55b0955c934145b9f0f08dbbe399fe","max":4436,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3b7eca35933477aaa5a3fedff84a2e2","value":4436}},"ad0cdef0307a4eeea3981bd9f541cc7a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b7eca35933477aaa5a3fedff84a2e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e138b179be854426ac7bada21f0a1899":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad0cdef0307a4eeea3981bd9f541cc7a","placeholder":"​","style":"IPY_MODEL_03913b8267fd4b90914caec90b1ba430","value":" 4436/4436 [01:14&lt;00:00, 40.52it/s]"}},"ea55b0955c934145b9f0f08dbbe399fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f62c08a72d1142fdab953c980fbbce4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6bc521f800fc43b8bb54d18794abe787","IPY_MODEL_a19e893d1d554573b11135419da009c0","IPY_MODEL_e138b179be854426ac7bada21f0a1899"],"layout":"IPY_MODEL_8e9a7e93962644e8b1212262c8418d24"}},"211eaddf31ab4edb83516d06f6edb56d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f249276962be40e5955be496237a5656","IPY_MODEL_2d3c8bae69fe49f38503e7086c5c26a1","IPY_MODEL_52c4fe24e4a34c959302b79d3f019ba5"],"layout":"IPY_MODEL_28116101f54a4b6387a9db208f227607"}},"f249276962be40e5955be496237a5656":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91457cd790844eb086717221daa79882","placeholder":"​","style":"IPY_MODEL_063b83abb83d41ab999039a8fbd7df1f","value":"Evaluating: 100%"}},"2d3c8bae69fe49f38503e7086c5c26a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cea38d2dd71493892d702e405643b93","max":278,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c233cae1e2243c6a11c98aa0708aaee","value":278}},"52c4fe24e4a34c959302b79d3f019ba5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f1cbe53272c44cda8b84907548521de","placeholder":"​","style":"IPY_MODEL_280aa964f17b4326b00b74a7435d50a6","value":" 278/278 [02:35&lt;00:00,  2.31it/s]"}},"28116101f54a4b6387a9db208f227607":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91457cd790844eb086717221daa79882":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"063b83abb83d41ab999039a8fbd7df1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cea38d2dd71493892d702e405643b93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c233cae1e2243c6a11c98aa0708aaee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f1cbe53272c44cda8b84907548521de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"280aa964f17b4326b00b74a7435d50a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d129203d94445c4b375fe61a4afb00d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb5e6d50b59a40ceb2ce3a1ab9895dad","IPY_MODEL_f111af1c463c4f32814923c8b38f3d4d","IPY_MODEL_b0e1cea4999848b389aad5aacfbd7502"],"layout":"IPY_MODEL_8317b8dd4a9d4d338f00c57e6010d47a"}},"eb5e6d50b59a40ceb2ce3a1ab9895dad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f56bf80cb6dc48f18b089f90c11e4231","placeholder":"​","style":"IPY_MODEL_e1ec998cd98f4a59a320658195e2dfbc","value":"Evaluating: 100%"}},"f111af1c463c4f32814923c8b38f3d4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84880378438e4c81bd187156eca63a76","max":141,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3847b809fdea448cbbae90235d9a7d2e","value":141}},"b0e1cea4999848b389aad5aacfbd7502":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a89214bd7aaa4c45b4be3f27f8d24019","placeholder":"​","style":"IPY_MODEL_3a87250bc7a54965bd0d67a6da3a8b26","value":" 141/141 [01:18&lt;00:00,  1.80it/s]"}},"8317b8dd4a9d4d338f00c57e6010d47a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f56bf80cb6dc48f18b089f90c11e4231":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1ec998cd98f4a59a320658195e2dfbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84880378438e4c81bd187156eca63a76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3847b809fdea448cbbae90235d9a7d2e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a89214bd7aaa4c45b4be3f27f8d24019":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a87250bc7a54965bd0d67a6da3a8b26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77acda4cf7514e7ca1b80d7093059d53":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f1ead2cfa7a417e968769adef4393c4","IPY_MODEL_57e946ec137d4506ba34c33e2fe83886","IPY_MODEL_ac4d86d6cdcd476d8d13fcc7af4f5fc3"],"layout":"IPY_MODEL_82dbf31183ee4fb8a135eeda23077bb8"}},"3f1ead2cfa7a417e968769adef4393c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d68ce6b728994e97866ac5e5214d5515","placeholder":"​","style":"IPY_MODEL_012d06c3974d420485518ae35d564105","value":"Evaluating: 100%"}},"57e946ec137d4506ba34c33e2fe83886":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6fde4af50764278b4ea8d5391e87ed1","max":278,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f0c7a56c72f480ba026ba5079318310","value":278}},"ac4d86d6cdcd476d8d13fcc7af4f5fc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29f282f4681646279269f7bcc2fd90d7","placeholder":"​","style":"IPY_MODEL_a355b927a87d4a95a66aa99e6b1f7818","value":" 278/278 [00:32&lt;00:00,  8.51it/s]"}},"82dbf31183ee4fb8a135eeda23077bb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d68ce6b728994e97866ac5e5214d5515":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"012d06c3974d420485518ae35d564105":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6fde4af50764278b4ea8d5391e87ed1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f0c7a56c72f480ba026ba5079318310":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29f282f4681646279269f7bcc2fd90d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a355b927a87d4a95a66aa99e6b1f7818":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b601f9616f24a7aa0c72996ebb04971":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d5dbe36178c4ee4a3405886f427561e","IPY_MODEL_43acc2439ead4fefb6e1b891f4f2f15c","IPY_MODEL_126d0132e5b6476a84a226cb02be54e6"],"layout":"IPY_MODEL_bde3c1a42f964828abc5bca374ae80d4"}},"1d5dbe36178c4ee4a3405886f427561e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31bb667022b548f9be44f5a590b8441d","placeholder":"​","style":"IPY_MODEL_acc1e40e943f4e59a95b57e025a11bfb","value":"Convert 7899 of 7900 example to features: 100%"}},"43acc2439ead4fefb6e1b891f4f2f15c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4141e4effc3b4b9887a7f9d90dc10618","max":7900,"min":0,"orientation":"horizontal","style":"IPY_MODEL_940ba46411e249aaa20dba8b822f3d0d","value":7900}},"126d0132e5b6476a84a226cb02be54e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fc37818955148419daa16c9b8019b66","placeholder":"​","style":"IPY_MODEL_6cc22202292c49cab997d5c38494a070","value":" 7900/7900 [00:37&lt;00:00, 190.80it/s]"}},"bde3c1a42f964828abc5bca374ae80d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31bb667022b548f9be44f5a590b8441d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acc1e40e943f4e59a95b57e025a11bfb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4141e4effc3b4b9887a7f9d90dc10618":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"940ba46411e249aaa20dba8b822f3d0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fc37818955148419daa16c9b8019b66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cc22202292c49cab997d5c38494a070":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33923d6619e94c1cb50e66fb5e33b0e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf8002d92a9647b89480ef33f1552309","IPY_MODEL_73752f76b5284bd588409bdac7719358","IPY_MODEL_7460a7584959433c88678a02ce0f0386"],"layout":"IPY_MODEL_4d051cc0a7f2410a9c452bd29012f8cc"}},"bf8002d92a9647b89480ef33f1552309":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89930426c94546feb488eb545af2b553","placeholder":"​","style":"IPY_MODEL_5c67f24a17a74f7fb4b24b2da269f8eb","value":"Epoch: 100%"}},"73752f76b5284bd588409bdac7719358":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5cf2035d50b404f992345e9bce1ae06","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13034e0dfe004c64896197315125575c","value":10}},"7460a7584959433c88678a02ce0f0386":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3a40fb7c0aa43c3bb9cb6632251ea18","placeholder":"​","style":"IPY_MODEL_8aba81c970994ef4bab9c20492994051","value":" 10/10 [28:52&lt;00:00, 173.19s/it]"}},"4d051cc0a7f2410a9c452bd29012f8cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89930426c94546feb488eb545af2b553":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c67f24a17a74f7fb4b24b2da269f8eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5cf2035d50b404f992345e9bce1ae06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13034e0dfe004c64896197315125575c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3a40fb7c0aa43c3bb9cb6632251ea18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aba81c970994ef4bab9c20492994051":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ebac90c871c4185bc32b1e3838c67d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e555dbd489734eada121d3d1385bede8","IPY_MODEL_c9efa2d681c04319b60fa3a7b4241c23","IPY_MODEL_ea1dc092122145afb45682c74b6cc9cf"],"layout":"IPY_MODEL_16844095349242dd9c139f88562cf25c"}},"e555dbd489734eada121d3d1385bede8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fb5b84bd98349d185dc6bfb4740338a","placeholder":"​","style":"IPY_MODEL_37db88d58c86471eabb68b4ad606ba2a","value":"train loss: 0.03463044215554023: 100%"}},"c9efa2d681c04319b60fa3a7b4241c23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8caab8f9cb084aa281cc66c381575216","max":247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e1141403e6b4b42af740c781ff2acd8","value":247}},"ea1dc092122145afb45682c74b6cc9cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d866b17239b4e92936b4e827241b153","placeholder":"​","style":"IPY_MODEL_cc5552e6ce904e06b90eaaa6f294ccc5","value":" 247/247 [02:52&lt;00:00,  1.50it/s]"}},"16844095349242dd9c139f88562cf25c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fb5b84bd98349d185dc6bfb4740338a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37db88d58c86471eabb68b4ad606ba2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8caab8f9cb084aa281cc66c381575216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e1141403e6b4b42af740c781ff2acd8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d866b17239b4e92936b4e827241b153":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc5552e6ce904e06b90eaaa6f294ccc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58d6d2103cb4447b8793050fd3a48ad0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_16a72352a03a4bd099c2e3b8b7fb2968","IPY_MODEL_6838fc040aaf4e528406329a5dc97f1b","IPY_MODEL_fe7dc05ae26a467c9f4c2e7838914a6a"],"layout":"IPY_MODEL_f79ee69d38fd4abd9c5e84d21e293fdb"}},"16a72352a03a4bd099c2e3b8b7fb2968":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69bfe07e8ae546b99d2c3b6e180e002c","placeholder":"​","style":"IPY_MODEL_22d656e3844141a3b5655311dc4f2e00","value":"train loss: 0.030798564480077697: 100%"}},"6838fc040aaf4e528406329a5dc97f1b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95ea8a0209a248049378d077d6876e4e","max":247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10878fba474a419baca20f9c1f7a972c","value":247}},"fe7dc05ae26a467c9f4c2e7838914a6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42227a25a140439381e403f238476511","placeholder":"​","style":"IPY_MODEL_bfc0982631934990800b0eba19cbcef4","value":" 247/247 [02:51&lt;00:00,  1.49it/s]"}},"f79ee69d38fd4abd9c5e84d21e293fdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69bfe07e8ae546b99d2c3b6e180e002c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22d656e3844141a3b5655311dc4f2e00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95ea8a0209a248049378d077d6876e4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10878fba474a419baca20f9c1f7a972c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42227a25a140439381e403f238476511":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfc0982631934990800b0eba19cbcef4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9800f6586ffc494ba7fff773c1e0505d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6581ff832e2d45d685dd1bc4bd76edc7","IPY_MODEL_c2b606455e0249deb3017fe930d1c7a6","IPY_MODEL_639e24219f264df5ba00304ded68c4fa"],"layout":"IPY_MODEL_8347af56bbe6452c8c8ba0ee2dc1c59a"}},"6581ff832e2d45d685dd1bc4bd76edc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6897e9ed9933451ebdaa5a2a3a4f63ce","placeholder":"​","style":"IPY_MODEL_5e49f2cd9e1548a2b967a0b13a0ee0ea","value":"train loss: 0.027175989747928703: 100%"}},"c2b606455e0249deb3017fe930d1c7a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f24e1a00836f468ea01db0dec23e8956","max":247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec8cc218bf66460b8f0d62942f730167","value":247}},"639e24219f264df5ba00304ded68c4fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ceaa0400fd64de3a54149894f0f2b87","placeholder":"​","style":"IPY_MODEL_baaad33c4f034cfaa257250ef1f29078","value":" 247/247 [02:52&lt;00:00,  1.49it/s]"}},"8347af56bbe6452c8c8ba0ee2dc1c59a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6897e9ed9933451ebdaa5a2a3a4f63ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e49f2cd9e1548a2b967a0b13a0ee0ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f24e1a00836f468ea01db0dec23e8956":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec8cc218bf66460b8f0d62942f730167":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ceaa0400fd64de3a54149894f0f2b87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baaad33c4f034cfaa257250ef1f29078":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e66832b5663d4c0e9b9ed6a594449597":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ae0dfda4e1fa4dc79187a403a9c685c8","IPY_MODEL_0b378bd3ba604019b2b721937f9363c1","IPY_MODEL_d0cecbe4c55d4cc986859493ca743ef2"],"layout":"IPY_MODEL_3b668d04306f46c88e1c98de7faa72ae"}},"ae0dfda4e1fa4dc79187a403a9c685c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e7b41802fcb45c981e006b3ef3bed38","placeholder":"​","style":"IPY_MODEL_4cb804ffbf8b4df08e117466f13922f6","value":"train loss: 0.024245394499346862: 100%"}},"0b378bd3ba604019b2b721937f9363c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_770cf2d42f3e4a4cada567c423709880","max":247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e3b34a4aab64fc7b301cb9a8a4267d4","value":247}},"d0cecbe4c55d4cc986859493ca743ef2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b6e5e6308fe42b084dd6b5c3fefb8de","placeholder":"​","style":"IPY_MODEL_4925f6b0fe6947cead094ad19d072073","value":" 247/247 [02:51&lt;00:00,  1.49it/s]"}},"3b668d04306f46c88e1c98de7faa72ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e7b41802fcb45c981e006b3ef3bed38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cb804ffbf8b4df08e117466f13922f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"770cf2d42f3e4a4cada567c423709880":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e3b34a4aab64fc7b301cb9a8a4267d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b6e5e6308fe42b084dd6b5c3fefb8de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4925f6b0fe6947cead094ad19d072073":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1dbc8440dd34915857687d04636a11c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67a630662e0a4c7d9ce1d28c729da259","IPY_MODEL_2e8e558d029e40449667f802fc5291d3","IPY_MODEL_a83f5b85530649d6ae41c66a75ab1951"],"layout":"IPY_MODEL_cd8f9d5cdf924d819866bead78299e5c"}},"67a630662e0a4c7d9ce1d28c729da259":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e7de8f9a2934b35b5287541432014f1","placeholder":"​","style":"IPY_MODEL_a423f1ea74dd42b780e63440521fd4ee","value":"train loss: 0.021692332562389394: 100%"}},"2e8e558d029e40449667f802fc5291d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dd8406ab91d4ce98149fb9a6c74686e","max":247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45f1c9669b3145379eaf18038a05132a","value":247}},"a83f5b85530649d6ae41c66a75ab1951":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddd425401fc94716aa7dca7bc64fa97b","placeholder":"​","style":"IPY_MODEL_1c6f7cf3e0174c28b92bcb6e36761dc7","value":" 247/247 [02:51&lt;00:00,  1.50it/s]"}},"cd8f9d5cdf924d819866bead78299e5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e7de8f9a2934b35b5287541432014f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a423f1ea74dd42b780e63440521fd4ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5dd8406ab91d4ce98149fb9a6c74686e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45f1c9669b3145379eaf18038a05132a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ddd425401fc94716aa7dca7bc64fa97b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c6f7cf3e0174c28b92bcb6e36761dc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e57ca7fe56b4b68aad9b10a4056fb34":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0af2b17d0fc446a6b2f45c7c19601beb","IPY_MODEL_d658462c434347eab67c7ce7f115c2d8","IPY_MODEL_a6d3918a80a8498aac6f049f53df074e"],"layout":"IPY_MODEL_87bb9796df8d466c965d8ae915363f7a"}},"0af2b17d0fc446a6b2f45c7c19601beb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ca603a2bd8d4c8e8cb1503d39882b7d","placeholder":"​","style":"IPY_MODEL_15a94cb4557a4f319e3ab51069f1920c","value":"train loss: 0.019420275213865353: 100%"}},"d658462c434347eab67c7ce7f115c2d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9caf54d1dad4c47ba3f1326113acf58","max":247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_071d6ffc0ca048ee9b9981965dfe15ff","value":247}},"a6d3918a80a8498aac6f049f53df074e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b37a1b340a96439e8d2a1108e6a802d7","placeholder":"​","style":"IPY_MODEL_a9e4a1d9065c480cafdab9aadb367da8","value":" 247/247 [02:52&lt;00:00,  1.49it/s]"}},"87bb9796df8d466c965d8ae915363f7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ca603a2bd8d4c8e8cb1503d39882b7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15a94cb4557a4f319e3ab51069f1920c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9caf54d1dad4c47ba3f1326113acf58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"071d6ffc0ca048ee9b9981965dfe15ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b37a1b340a96439e8d2a1108e6a802d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9e4a1d9065c480cafdab9aadb367da8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ffce7554eca4486a9337167f3df89c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2cfe663e5e17471c9dbce4dfe3851884","IPY_MODEL_313b57a647724c6db41d3db3ffc221f8","IPY_MODEL_fd4078c0962a488e9727c80fc830fedd"],"layout":"IPY_MODEL_3479f20b5dfe4e109a21208e722f64ee"}},"2cfe663e5e17471c9dbce4dfe3851884":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97fb5774bc2a4c6a8250330f5b035ac5","placeholder":"​","style":"IPY_MODEL_648afef31dda473fa93485142fea7ee7","value":"train loss: 0.017557300516650522: 100%"}},"313b57a647724c6db41d3db3ffc221f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab742ad6c7d048048fa490767681dd62","max":247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd1c449efe8d47a29da356c3dd2c7c97","value":247}},"fd4078c0962a488e9727c80fc830fedd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6931f0c87be14d7db57fc0270c89019a","placeholder":"​","style":"IPY_MODEL_61868b94255044029ad9cf15013dfcba","value":" 247/247 [02:52&lt;00:00,  1.49it/s]"}},"3479f20b5dfe4e109a21208e722f64ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97fb5774bc2a4c6a8250330f5b035ac5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"648afef31dda473fa93485142fea7ee7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab742ad6c7d048048fa490767681dd62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd1c449efe8d47a29da356c3dd2c7c97":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6931f0c87be14d7db57fc0270c89019a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61868b94255044029ad9cf15013dfcba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba078e942c0940a49616f2c0d3b974f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1717111de5a54043a0ab6623b728f370","IPY_MODEL_4a8b3f994e25492c9e4b1e111442b8b4","IPY_MODEL_381a3719c69040b3bf874c2e1f2b1dfe"],"layout":"IPY_MODEL_9c00c16e41ab43a2b822e364cbf3d2a7"}},"1717111de5a54043a0ab6623b728f370":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2be381021e7e46b99c9f9331b148974f","placeholder":"​","style":"IPY_MODEL_5709f1c6f60c47c29a4fd3c47177e596","value":"train loss: 0.015888237542972816: 100%"}},"4a8b3f994e25492c9e4b1e111442b8b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c835f65c2ff43ee8dd1b0791ef366c7","max":247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_397aa7d787f745f3b791d3495eb4c3db","value":247}},"381a3719c69040b3bf874c2e1f2b1dfe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_340cbbd3251445448fa583d9e1575499","placeholder":"​","style":"IPY_MODEL_835a6949f96c4487ae5497b5d2ef63d4","value":" 247/247 [02:52&lt;00:00,  1.49it/s]"}},"9c00c16e41ab43a2b822e364cbf3d2a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2be381021e7e46b99c9f9331b148974f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5709f1c6f60c47c29a4fd3c47177e596":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c835f65c2ff43ee8dd1b0791ef366c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"397aa7d787f745f3b791d3495eb4c3db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"340cbbd3251445448fa583d9e1575499":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"835a6949f96c4487ae5497b5d2ef63d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"450cf948ddd042c28fa2ba09163f4b17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f07ddae4a4d4e6892ce83ebdd695fe3","IPY_MODEL_7e2fea16ee3c4006a28cea4cea5aa768","IPY_MODEL_5009f576f3e5499a81c7fac71067ce17"],"layout":"IPY_MODEL_b384d368afd74d19bdab6d874bc03763"}},"9f07ddae4a4d4e6892ce83ebdd695fe3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d688b4f9e20453b9372eea0f30a7bc8","placeholder":"​","style":"IPY_MODEL_7401ba2fcee84cc992a069a5158aad5c","value":"train loss: 0.014436327439991415: 100%"}},"7e2fea16ee3c4006a28cea4cea5aa768":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a191040c8a640d98c98b2cf97d22c64","max":247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a67bf6f3ea54d1aa366de9977964aa0","value":247}},"5009f576f3e5499a81c7fac71067ce17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ef0ad6a430d4ddb929485e5afde2cd0","placeholder":"​","style":"IPY_MODEL_f991d0f194eb4d08899acee37cf042a6","value":" 247/247 [02:52&lt;00:00,  1.49it/s]"}},"b384d368afd74d19bdab6d874bc03763":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d688b4f9e20453b9372eea0f30a7bc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7401ba2fcee84cc992a069a5158aad5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a191040c8a640d98c98b2cf97d22c64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a67bf6f3ea54d1aa366de9977964aa0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ef0ad6a430d4ddb929485e5afde2cd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f991d0f194eb4d08899acee37cf042a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"425b9b76d217450e91d071f9dc0c75dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c26c56b225904dfe8bbaa848ed62bcaf","IPY_MODEL_a43c3cb6879741568319c2b111fcf549","IPY_MODEL_ac325c5ab4224a9881359b049d2a0611"],"layout":"IPY_MODEL_7b7d797534614b6cacd61b885f4ca7cf"}},"c26c56b225904dfe8bbaa848ed62bcaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efd9cd89ea4743738d335bb2617c0a9b","placeholder":"​","style":"IPY_MODEL_c99731f820564c2b9f41b6fc74f4fff7","value":"train loss: 0.013253225518222602: 100%"}},"a43c3cb6879741568319c2b111fcf549":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f2d73acf6844613800e2381e2470c4c","max":247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5813410990574b8e8d24b3f7af642e4d","value":247}},"ac325c5ab4224a9881359b049d2a0611":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d8e65a52df5419e9132b53f96739c5c","placeholder":"​","style":"IPY_MODEL_01b8c265725a463fae4fc14c4684af71","value":" 247/247 [02:51&lt;00:00,  1.50it/s]"}},"7b7d797534614b6cacd61b885f4ca7cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efd9cd89ea4743738d335bb2617c0a9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c99731f820564c2b9f41b6fc74f4fff7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f2d73acf6844613800e2381e2470c4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5813410990574b8e8d24b3f7af642e4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d8e65a52df5419e9132b53f96739c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01b8c265725a463fae4fc14c4684af71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c80eed0966d4794989b50391a61b52d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8143bbf69e6451cae1f599e33cccf30","IPY_MODEL_134cdcd04ac04a30919dee9325cb4de2","IPY_MODEL_88a06841cc9c461d8b72f02eb0eecdb5"],"layout":"IPY_MODEL_605e4f1a1e6043aabff4263fafcf1d63"}},"f8143bbf69e6451cae1f599e33cccf30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04f725c6e815494eab9e950242f6c89b","placeholder":"​","style":"IPY_MODEL_3d5ddac0519d406c882be60ce038a7cd","value":"Convert 1175 of 1176 example to features: 100%"}},"134cdcd04ac04a30919dee9325cb4de2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_975893d6c4eb4d3d9203a2cc53517e61","max":1176,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f024e07b76e64b168e49f45bad20b5d3","value":1176}},"88a06841cc9c461d8b72f02eb0eecdb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2edb6662b52046d3af5cddb0170ea8a5","placeholder":"​","style":"IPY_MODEL_efc0e584479d4556b8b2e36b21feb4c5","value":" 1176/1176 [00:05&lt;00:00, 190.85it/s]"}},"605e4f1a1e6043aabff4263fafcf1d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04f725c6e815494eab9e950242f6c89b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d5ddac0519d406c882be60ce038a7cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"975893d6c4eb4d3d9203a2cc53517e61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f024e07b76e64b168e49f45bad20b5d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2edb6662b52046d3af5cddb0170ea8a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc0e584479d4556b8b2e36b21feb4c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8baa15ba0cf545fab6e43a82299c8706":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82dd5d6df5f74a4e95eea20310cf089b","IPY_MODEL_1373da9782094c43b21e438c6ba5ac44","IPY_MODEL_139ddd0036c94003bae52c554023be15"],"layout":"IPY_MODEL_3807c05b29d948dbb35ceb5d3783d79f"}},"82dd5d6df5f74a4e95eea20310cf089b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cefe10b11cdc4cdca8b262a742b7f95a","placeholder":"​","style":"IPY_MODEL_05cff7601f4b404f88a76c3122729ece","value":"Evaluating: 100%"}},"1373da9782094c43b21e438c6ba5ac44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bb8f49c87834ace8be98ad5862d237f","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6901f761a3814241a15fa7df74cdc36d","value":74}},"139ddd0036c94003bae52c554023be15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce7fd709dcbb4efea07a6d491bdbd96e","placeholder":"​","style":"IPY_MODEL_18318480508341c7858262b6c8bb5aea","value":" 74/74 [00:08&lt;00:00,  8.39it/s]"}},"3807c05b29d948dbb35ceb5d3783d79f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cefe10b11cdc4cdca8b262a742b7f95a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05cff7601f4b404f88a76c3122729ece":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bb8f49c87834ace8be98ad5862d237f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6901f761a3814241a15fa7df74cdc36d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce7fd709dcbb4efea07a6d491bdbd96e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18318480508341c7858262b6c8bb5aea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dc2eb8c92e448e3becd29c2e29e16d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80c3841463e342dd99ffff5bbcb0299b","IPY_MODEL_6a2b02cfe101449c9932bf47eaed359b","IPY_MODEL_a041ca8bd46348248e466a09a4c5036b"],"layout":"IPY_MODEL_e716cc86540e496bb7221b9aa13aa163"}},"80c3841463e342dd99ffff5bbcb0299b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08c38b434ae14247948b35a984f27b03","placeholder":"​","style":"IPY_MODEL_e32de9755ba94fa3bc2e07548651b4c8","value":"Evaluating: 100%"}},"6a2b02cfe101449c9932bf47eaed359b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cb299e0b8484655b6316c47486b2387","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a66e06043e5248aab5b803efd7744d7b","value":74}},"a041ca8bd46348248e466a09a4c5036b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44ea5fa45507415fadc8c6de5647c1a4","placeholder":"​","style":"IPY_MODEL_7b37d5118260455a832a7b4573952559","value":" 74/74 [00:08&lt;00:00,  8.41it/s]"}},"e716cc86540e496bb7221b9aa13aa163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08c38b434ae14247948b35a984f27b03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e32de9755ba94fa3bc2e07548651b4c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cb299e0b8484655b6316c47486b2387":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a66e06043e5248aab5b803efd7744d7b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44ea5fa45507415fadc8c6de5647c1a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b37d5118260455a832a7b4573952559":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01abf26250d64fe79ff2d9297c3a40e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08356ad962984c0fafaff384d35a933a","IPY_MODEL_8008b1a9694c42aa88f51878ba60cd7c","IPY_MODEL_7bf551a2890c4550a61bb56a9e5ce875"],"layout":"IPY_MODEL_19d3dec988bc4bc4af25dd6686b97f1e"}},"08356ad962984c0fafaff384d35a933a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_249988992c964e789ef1746336bec4fb","placeholder":"​","style":"IPY_MODEL_0c42924a2a2347688778a0acf3042c00","value":"Evaluating: 100%"}},"8008b1a9694c42aa88f51878ba60cd7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cda783093d84138b79b54f84592c9b5","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0a5b3dc19d294b458f643f86063cc07d","value":74}},"7bf551a2890c4550a61bb56a9e5ce875":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc6f63b8f94647cba0fe7e200a60244f","placeholder":"​","style":"IPY_MODEL_26c84e44ac0d4b16ae4b0823f62bda50","value":" 74/74 [00:08&lt;00:00,  8.44it/s]"}},"19d3dec988bc4bc4af25dd6686b97f1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"249988992c964e789ef1746336bec4fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c42924a2a2347688778a0acf3042c00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cda783093d84138b79b54f84592c9b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a5b3dc19d294b458f643f86063cc07d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc6f63b8f94647cba0fe7e200a60244f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26c84e44ac0d4b16ae4b0823f62bda50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d07d39d4c8d449b0969ffd16149eb3fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cee9b3536fb4ddf9fe8baa84a1c6b60","IPY_MODEL_2fd2b4f82bb44ffeb3680280fdea167d","IPY_MODEL_fbadf3a1b157412489db20f2af4e1d1e"],"layout":"IPY_MODEL_a16a0f7a106c49a8bd00c39d19457255"}},"3cee9b3536fb4ddf9fe8baa84a1c6b60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7b088fcb5c54935b6f6d83fffaf41b3","placeholder":"​","style":"IPY_MODEL_1eef994556944cbe8a7677a1dd0e2db7","value":"Evaluating: 100%"}},"2fd2b4f82bb44ffeb3680280fdea167d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5988a14a29084476a6beacd775fc896e","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba23219429414214b474f5380deffd24","value":74}},"fbadf3a1b157412489db20f2af4e1d1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa8a7afd08f2409d8f1f2710c1cf26ed","placeholder":"​","style":"IPY_MODEL_72ae85f489784c83bc1dd530d1fb7d59","value":" 74/74 [00:08&lt;00:00,  8.36it/s]"}},"a16a0f7a106c49a8bd00c39d19457255":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7b088fcb5c54935b6f6d83fffaf41b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1eef994556944cbe8a7677a1dd0e2db7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5988a14a29084476a6beacd775fc896e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba23219429414214b474f5380deffd24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa8a7afd08f2409d8f1f2710c1cf26ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72ae85f489784c83bc1dd530d1fb7d59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34a3702cd6d34932a7a0ab9daf62bdf2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0349aa8db23e41ffbcc5468f8ac98410","IPY_MODEL_af1ecf6b9768477585479b8f5bc35d1c","IPY_MODEL_07879b75fccc4dd99e820ad23d880629"],"layout":"IPY_MODEL_867a620953f1461db3a34723b1d31484"}},"0349aa8db23e41ffbcc5468f8ac98410":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_968896e31fca4e4d8dafdddacb9b92a8","placeholder":"​","style":"IPY_MODEL_1fe347ba1b034df78d32de6feeb91e85","value":"Evaluating: 100%"}},"af1ecf6b9768477585479b8f5bc35d1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63f1708b2c344ecc953193bf32eada3a","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0572092fb1d34afdab0f21f167a9e292","value":74}},"07879b75fccc4dd99e820ad23d880629":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_343250b2f34c4bb1b7433bc6c69c4287","placeholder":"​","style":"IPY_MODEL_f5476d626b564950b1ce406cadc91ba8","value":" 74/74 [00:08&lt;00:00,  8.36it/s]"}},"867a620953f1461db3a34723b1d31484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"968896e31fca4e4d8dafdddacb9b92a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fe347ba1b034df78d32de6feeb91e85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63f1708b2c344ecc953193bf32eada3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0572092fb1d34afdab0f21f167a9e292":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"343250b2f34c4bb1b7433bc6c69c4287":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5476d626b564950b1ce406cadc91ba8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"896bed3df9214b46b4795f386ff92d05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9b4e9899f4b49ff9733cf6cae1aa67d","IPY_MODEL_0d6f0ad81079404a868237d0c20e2a81","IPY_MODEL_8a4e0f3573814693b014306362af7697"],"layout":"IPY_MODEL_6c5aac6c62574a3c90472a00f2a1398b"}},"e9b4e9899f4b49ff9733cf6cae1aa67d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b339924bfa784391969d00686927f194","placeholder":"​","style":"IPY_MODEL_7f5f49f9cc6c4bb5928435fee3ee92bc","value":"Evaluating: 100%"}},"0d6f0ad81079404a868237d0c20e2a81":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61682430c75f4ee6bef48720d42f8204","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f03a9f5f78f64b45ab50ff6e8adbd47c","value":74}},"8a4e0f3573814693b014306362af7697":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8395d586272c4ea29e8331b58af97a7a","placeholder":"​","style":"IPY_MODEL_6064c1fe859e41eeb8d0b797fcb484a1","value":" 74/74 [00:08&lt;00:00,  8.44it/s]"}},"6c5aac6c62574a3c90472a00f2a1398b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b339924bfa784391969d00686927f194":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f5f49f9cc6c4bb5928435fee3ee92bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61682430c75f4ee6bef48720d42f8204":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f03a9f5f78f64b45ab50ff6e8adbd47c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8395d586272c4ea29e8331b58af97a7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6064c1fe859e41eeb8d0b797fcb484a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb6466d993464f6bba820a6de5cd66e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8202a28f65ca42f6b7a88870f2655ea5","IPY_MODEL_1c390b3b808440d58b80b7b48dc943b4","IPY_MODEL_3767f64327254cd7ac412ac30d156717"],"layout":"IPY_MODEL_29f60c6386b2410fb97f420fbf07b878"}},"8202a28f65ca42f6b7a88870f2655ea5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_195cd0f856a54c829a8bcaffa278e68d","placeholder":"​","style":"IPY_MODEL_67b22addb20141969da6fc3c5925b744","value":"Evaluating: 100%"}},"1c390b3b808440d58b80b7b48dc943b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ae17a63b96a499286863754856c3fa7","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6fba296f215438487e6a91cf8eb93a3","value":74}},"3767f64327254cd7ac412ac30d156717":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_837fd13cbc1541c18eaa13f2cbd0628c","placeholder":"​","style":"IPY_MODEL_2b423cbad2834b4eaa335b588fc212a8","value":" 74/74 [00:08&lt;00:00,  8.42it/s]"}},"29f60c6386b2410fb97f420fbf07b878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"195cd0f856a54c829a8bcaffa278e68d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67b22addb20141969da6fc3c5925b744":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ae17a63b96a499286863754856c3fa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6fba296f215438487e6a91cf8eb93a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"837fd13cbc1541c18eaa13f2cbd0628c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b423cbad2834b4eaa335b588fc212a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf92019fdb2841b190c60e9dbe4650ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b1156fb4ee944b59e26a74b38a71d53","IPY_MODEL_b96b8096c4d9438dadb8163d6d819169","IPY_MODEL_63189285da6c4bf6869e579bd8bfcc09"],"layout":"IPY_MODEL_6ea846a6c8694c4bac9321647f450ae6"}},"3b1156fb4ee944b59e26a74b38a71d53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d879fd988cc54888bd0ec059cce87890","placeholder":"​","style":"IPY_MODEL_242fffc5b9734d78a0758033a0cedcbf","value":"Evaluating: 100%"}},"b96b8096c4d9438dadb8163d6d819169":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e84fbfb80d154949b30db0616041616a","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99bd83b85c4b4204b50287ba5b75f1d8","value":74}},"63189285da6c4bf6869e579bd8bfcc09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89b25f3fd64e4848847bd40bb73f0456","placeholder":"​","style":"IPY_MODEL_f0533260297942ba967364b0fa7244d9","value":" 74/74 [00:08&lt;00:00,  8.40it/s]"}},"6ea846a6c8694c4bac9321647f450ae6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d879fd988cc54888bd0ec059cce87890":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"242fffc5b9734d78a0758033a0cedcbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e84fbfb80d154949b30db0616041616a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99bd83b85c4b4204b50287ba5b75f1d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89b25f3fd64e4848847bd40bb73f0456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0533260297942ba967364b0fa7244d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5f53751180042d1b5ac47459ef4d4a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b59242ab233b4869af1fd313ced13080","IPY_MODEL_f053acff192d4d629f956105b3dc9eaf","IPY_MODEL_c7d54c93a5d64e90a3282c86294312d0"],"layout":"IPY_MODEL_0bffc4fd9f3d4b2eba8724ea7263cfbd"}},"b59242ab233b4869af1fd313ced13080":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46a0c35a93f94380b813925376b7936a","placeholder":"​","style":"IPY_MODEL_a67f57e63abe438cb9345d556ee144f9","value":"Evaluating: 100%"}},"f053acff192d4d629f956105b3dc9eaf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75c8ab3783514be9890e3dc5f1879e6f","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b779da19f542465783533f0e2072c14c","value":74}},"c7d54c93a5d64e90a3282c86294312d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f560fbe78744124addc19f209fdf838","placeholder":"​","style":"IPY_MODEL_02540b99a49c4679b5e85c08cc153855","value":" 74/74 [00:08&lt;00:00,  8.42it/s]"}},"0bffc4fd9f3d4b2eba8724ea7263cfbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46a0c35a93f94380b813925376b7936a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a67f57e63abe438cb9345d556ee144f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75c8ab3783514be9890e3dc5f1879e6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b779da19f542465783533f0e2072c14c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f560fbe78744124addc19f209fdf838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02540b99a49c4679b5e85c08cc153855":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53b06e56d91441f6be1b6b1fd5a0699d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4eda7d5a5ef243bc9dccca667e8f2c30","IPY_MODEL_a124873171f94e3ea50d169326ff38de","IPY_MODEL_b14e4e35b23943bc83faca273beab283"],"layout":"IPY_MODEL_c7e0eb8f87c24b6ca765d734d9b3869f"}},"4eda7d5a5ef243bc9dccca667e8f2c30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7d9ca411f4d43ecac5233ceec1a0fd8","placeholder":"​","style":"IPY_MODEL_52aca8b93ef54669890a50f6a5d6f3b6","value":"Evaluating: 100%"}},"a124873171f94e3ea50d169326ff38de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30059b896d17420d909b0cd4293792f6","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be3e33c912404e6796a22006c3f831c9","value":74}},"b14e4e35b23943bc83faca273beab283":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd636612b7c04ae389767fc37e2aa112","placeholder":"​","style":"IPY_MODEL_b006b0867c5b4cec9db420d3ff8b87c0","value":" 74/74 [00:08&lt;00:00,  8.42it/s]"}},"c7e0eb8f87c24b6ca765d734d9b3869f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7d9ca411f4d43ecac5233ceec1a0fd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52aca8b93ef54669890a50f6a5d6f3b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30059b896d17420d909b0cd4293792f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be3e33c912404e6796a22006c3f831c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd636612b7c04ae389767fc37e2aa112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b006b0867c5b4cec9db420d3ff8b87c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b34ab1d6399c481dbb887d01daf287b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5367f8cbbbbc42cdbed06d664f5a2743","IPY_MODEL_0596886531ea4f9e930cb390eba4e5a7","IPY_MODEL_e22a2b4eb1154defa72bb09601f26068"],"layout":"IPY_MODEL_689b0512bf974476befa139653d97d5b"}},"5367f8cbbbbc42cdbed06d664f5a2743":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a1f4277409246ae9ef7f3d6455ac1c7","placeholder":"​","style":"IPY_MODEL_bfd0cc7e44c749ab989e6c567b67c6d1","value":"Evaluating: 100%"}},"0596886531ea4f9e930cb390eba4e5a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf4b94ebc83e41c883884e35df0e0ac6","max":74,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37d14731a7e4472d847fa83268e023e9","value":74}},"e22a2b4eb1154defa72bb09601f26068":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c983090923f4bd7882122d3f1589384","placeholder":"​","style":"IPY_MODEL_2f38343fdafc46c4b9d575693839a526","value":" 74/74 [00:08&lt;00:00,  8.44it/s]"}},"689b0512bf974476befa139653d97d5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a1f4277409246ae9ef7f3d6455ac1c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfd0cc7e44c749ab989e6c567b67c6d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf4b94ebc83e41c883884e35df0e0ac6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37d14731a7e4472d847fa83268e023e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c983090923f4bd7882122d3f1589384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f38343fdafc46c4b9d575693839a526":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"670efc5c8b3b494db3e157e545cfa700":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8075783e2cb541c49090de03a5d65b20","IPY_MODEL_7b2a187931e546eab9fca7b824ba4640","IPY_MODEL_cc64e78c62a84374bfe1648d5d0e620f"],"layout":"IPY_MODEL_b796409c6c204693b1004d9f365f6561"}},"8075783e2cb541c49090de03a5d65b20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e6f830de4284e69a8f636eecada8f6f","placeholder":"​","style":"IPY_MODEL_2ffed6afbb214283809799c730b303ed","value":"Evaluating: 100%"}},"7b2a187931e546eab9fca7b824ba4640":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57db4da18e1e42edbf7fdc324b225998","max":129,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c82ddf29cd4c47c1965ba9569a6e34e6","value":129}},"cc64e78c62a84374bfe1648d5d0e620f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fd9b7e09f174041a8031d8454f39297","placeholder":"​","style":"IPY_MODEL_ef0ef7576d0b42e094dda77fb40f2e60","value":" 129/129 [00:15&lt;00:00,  8.50it/s]"}},"b796409c6c204693b1004d9f365f6561":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e6f830de4284e69a8f636eecada8f6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ffed6afbb214283809799c730b303ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57db4da18e1e42edbf7fdc324b225998":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c82ddf29cd4c47c1965ba9569a6e34e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fd9b7e09f174041a8031d8454f39297":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef0ef7576d0b42e094dda77fb40f2e60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}